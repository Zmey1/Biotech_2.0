{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, matthews_corrcoef\n",
    "from sklearn.metrics import log_loss, balanced_accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('num_df_train.csv')\n",
    "X = df.drop('Cls', axis=1)\n",
    "y = df['Cls']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "df_test = pd.read_csv('num_df_test.csv')\n",
    "X_test_external = df_test.drop('Cls', axis=1)\n",
    "y_test_external= df_test['Cls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RandomForest parameters: {'max_depth': None, 'n_estimators': 20}\n",
      "Best RandomForest ROC AUC score: 0.8701519079260441\n",
      "0:\tlearn: 0.6833833\ttotal: 369ms\tremaining: 1.48s\n",
      "1:\tlearn: 0.6733789\ttotal: 570ms\tremaining: 855ms\n",
      "2:\tlearn: 0.6645712\ttotal: 754ms\tremaining: 503ms\n",
      "3:\tlearn: 0.6553312\ttotal: 924ms\tremaining: 231ms\n",
      "4:\tlearn: 0.6464896\ttotal: 1.08s\tremaining: 0us\n",
      "0:\tlearn: 0.6832630\ttotal: 218ms\tremaining: 873ms\n",
      "1:\tlearn: 0.6717534\ttotal: 394ms\tremaining: 591ms\n",
      "2:\tlearn: 0.6636778\ttotal: 571ms\tremaining: 381ms\n",
      "3:\tlearn: 0.6559599\ttotal: 752ms\tremaining: 188ms\n",
      "4:\tlearn: 0.6471268\ttotal: 938ms\tremaining: 0us\n",
      "0:\tlearn: 0.6857017\ttotal: 206ms\tremaining: 826ms\n",
      "1:\tlearn: 0.6740592\ttotal: 402ms\tremaining: 602ms\n",
      "2:\tlearn: 0.6652960\ttotal: 582ms\tremaining: 388ms\n",
      "3:\tlearn: 0.6548289\ttotal: 764ms\tremaining: 191ms\n",
      "4:\tlearn: 0.6459701\ttotal: 962ms\tremaining: 0us\n",
      "0:\tlearn: 0.6831351\ttotal: 185ms\tremaining: 742ms\n",
      "1:\tlearn: 0.6722638\ttotal: 352ms\tremaining: 528ms\n",
      "2:\tlearn: 0.6617923\ttotal: 516ms\tremaining: 344ms\n",
      "3:\tlearn: 0.6523439\ttotal: 665ms\tremaining: 166ms\n",
      "4:\tlearn: 0.6425569\ttotal: 819ms\tremaining: 0us\n",
      "0:\tlearn: 0.6834966\ttotal: 202ms\tremaining: 809ms\n",
      "1:\tlearn: 0.6717733\ttotal: 357ms\tremaining: 536ms\n",
      "2:\tlearn: 0.6619372\ttotal: 527ms\tremaining: 351ms\n",
      "3:\tlearn: 0.6530592\ttotal: 682ms\tremaining: 171ms\n",
      "4:\tlearn: 0.6456218\ttotal: 852ms\tremaining: 0us\n",
      "0:\tlearn: 0.6742902\ttotal: 178ms\tremaining: 711ms\n",
      "1:\tlearn: 0.6561216\ttotal: 328ms\tremaining: 492ms\n",
      "2:\tlearn: 0.6407894\ttotal: 493ms\tremaining: 329ms\n",
      "3:\tlearn: 0.6295727\ttotal: 672ms\tremaining: 168ms\n",
      "4:\tlearn: 0.6150806\ttotal: 868ms\tremaining: 0us\n",
      "0:\tlearn: 0.6739732\ttotal: 237ms\tremaining: 947ms\n",
      "1:\tlearn: 0.6525296\ttotal: 418ms\tremaining: 628ms\n",
      "2:\tlearn: 0.6375332\ttotal: 609ms\tremaining: 406ms\n",
      "3:\tlearn: 0.6219289\ttotal: 804ms\tremaining: 201ms\n",
      "4:\tlearn: 0.6076129\ttotal: 989ms\tremaining: 0us\n",
      "0:\tlearn: 0.6786833\ttotal: 198ms\tremaining: 791ms\n",
      "1:\tlearn: 0.6570816\ttotal: 393ms\tremaining: 589ms\n",
      "2:\tlearn: 0.6422473\ttotal: 589ms\tremaining: 393ms\n",
      "3:\tlearn: 0.6268263\ttotal: 771ms\tremaining: 193ms\n",
      "4:\tlearn: 0.6098549\ttotal: 958ms\tremaining: 0us\n",
      "0:\tlearn: 0.6737108\ttotal: 210ms\tremaining: 842ms\n",
      "1:\tlearn: 0.6552873\ttotal: 376ms\tremaining: 564ms\n",
      "2:\tlearn: 0.6366435\ttotal: 587ms\tremaining: 391ms\n",
      "3:\tlearn: 0.6195750\ttotal: 762ms\tremaining: 190ms\n",
      "4:\tlearn: 0.6069613\ttotal: 926ms\tremaining: 0us\n",
      "0:\tlearn: 0.6744285\ttotal: 198ms\tremaining: 791ms\n",
      "1:\tlearn: 0.6545355\ttotal: 485ms\tremaining: 727ms\n",
      "2:\tlearn: 0.6423077\ttotal: 683ms\tremaining: 455ms\n",
      "3:\tlearn: 0.6268971\ttotal: 862ms\tremaining: 215ms\n",
      "4:\tlearn: 0.6086838\ttotal: 1.02s\tremaining: 0us\n",
      "0:\tlearn: 0.6833833\ttotal: 207ms\tremaining: 3.93s\n",
      "1:\tlearn: 0.6733789\ttotal: 374ms\tremaining: 3.37s\n",
      "2:\tlearn: 0.6645712\ttotal: 566ms\tremaining: 3.21s\n",
      "3:\tlearn: 0.6553312\ttotal: 742ms\tremaining: 2.97s\n",
      "4:\tlearn: 0.6464896\ttotal: 927ms\tremaining: 2.78s\n",
      "5:\tlearn: 0.6378115\ttotal: 1.1s\tremaining: 2.56s\n",
      "6:\tlearn: 0.6306419\ttotal: 1.27s\tremaining: 2.37s\n",
      "7:\tlearn: 0.6235139\ttotal: 1.44s\tremaining: 2.16s\n",
      "8:\tlearn: 0.6177310\ttotal: 1.6s\tremaining: 1.96s\n",
      "9:\tlearn: 0.6107975\ttotal: 1.78s\tremaining: 1.78s\n",
      "10:\tlearn: 0.6043409\ttotal: 1.96s\tremaining: 1.61s\n",
      "11:\tlearn: 0.5971637\ttotal: 2.14s\tremaining: 1.43s\n",
      "12:\tlearn: 0.5913341\ttotal: 2.32s\tremaining: 1.25s\n",
      "13:\tlearn: 0.5851259\ttotal: 2.48s\tremaining: 1.06s\n",
      "14:\tlearn: 0.5797428\ttotal: 2.64s\tremaining: 881ms\n",
      "15:\tlearn: 0.5746301\ttotal: 2.79s\tremaining: 699ms\n",
      "16:\tlearn: 0.5683595\ttotal: 2.97s\tremaining: 524ms\n",
      "17:\tlearn: 0.5634128\ttotal: 3.13s\tremaining: 348ms\n",
      "18:\tlearn: 0.5578693\ttotal: 3.29s\tremaining: 173ms\n",
      "19:\tlearn: 0.5526762\ttotal: 3.45s\tremaining: 0us\n",
      "0:\tlearn: 0.6832630\ttotal: 200ms\tremaining: 3.79s\n",
      "1:\tlearn: 0.6717534\ttotal: 369ms\tremaining: 3.32s\n",
      "2:\tlearn: 0.6636778\ttotal: 530ms\tremaining: 3s\n",
      "3:\tlearn: 0.6559599\ttotal: 687ms\tremaining: 2.75s\n",
      "4:\tlearn: 0.6471268\ttotal: 848ms\tremaining: 2.54s\n",
      "5:\tlearn: 0.6396381\ttotal: 1s\tremaining: 2.35s\n",
      "6:\tlearn: 0.6334152\ttotal: 1.16s\tremaining: 2.16s\n",
      "7:\tlearn: 0.6236759\ttotal: 1.34s\tremaining: 2.02s\n",
      "8:\tlearn: 0.6162823\ttotal: 1.52s\tremaining: 1.86s\n",
      "9:\tlearn: 0.6088335\ttotal: 1.69s\tremaining: 1.69s\n",
      "10:\tlearn: 0.6024108\ttotal: 1.84s\tremaining: 1.5s\n",
      "11:\tlearn: 0.5967694\ttotal: 2.02s\tremaining: 1.34s\n",
      "12:\tlearn: 0.5893509\ttotal: 2.21s\tremaining: 1.19s\n",
      "13:\tlearn: 0.5827041\ttotal: 2.4s\tremaining: 1.03s\n",
      "14:\tlearn: 0.5778032\ttotal: 2.54s\tremaining: 847ms\n",
      "15:\tlearn: 0.5720588\ttotal: 2.69s\tremaining: 672ms\n",
      "16:\tlearn: 0.5669784\ttotal: 2.85s\tremaining: 502ms\n",
      "17:\tlearn: 0.5612232\ttotal: 3s\tremaining: 334ms\n",
      "18:\tlearn: 0.5559560\ttotal: 3.15s\tremaining: 166ms\n",
      "19:\tlearn: 0.5511210\ttotal: 3.31s\tremaining: 0us\n",
      "0:\tlearn: 0.6857017\ttotal: 167ms\tremaining: 3.18s\n",
      "1:\tlearn: 0.6740592\ttotal: 320ms\tremaining: 2.88s\n",
      "2:\tlearn: 0.6652960\ttotal: 473ms\tremaining: 2.68s\n",
      "3:\tlearn: 0.6548289\ttotal: 623ms\tremaining: 2.49s\n",
      "4:\tlearn: 0.6459701\ttotal: 775ms\tremaining: 2.32s\n",
      "5:\tlearn: 0.6377436\ttotal: 925ms\tremaining: 2.16s\n",
      "6:\tlearn: 0.6319645\ttotal: 1.08s\tremaining: 2.01s\n",
      "7:\tlearn: 0.6244736\ttotal: 1.25s\tremaining: 1.87s\n",
      "8:\tlearn: 0.6178332\ttotal: 1.41s\tremaining: 1.73s\n",
      "9:\tlearn: 0.6107093\ttotal: 1.58s\tremaining: 1.58s\n",
      "10:\tlearn: 0.6059290\ttotal: 1.75s\tremaining: 1.43s\n",
      "11:\tlearn: 0.5997134\ttotal: 1.92s\tremaining: 1.28s\n",
      "12:\tlearn: 0.5938140\ttotal: 2.07s\tremaining: 1.11s\n",
      "13:\tlearn: 0.5869533\ttotal: 2.22s\tremaining: 950ms\n",
      "14:\tlearn: 0.5813385\ttotal: 2.37s\tremaining: 789ms\n",
      "15:\tlearn: 0.5769632\ttotal: 2.58s\tremaining: 646ms\n",
      "16:\tlearn: 0.5710569\ttotal: 2.75s\tremaining: 486ms\n",
      "17:\tlearn: 0.5646409\ttotal: 2.9s\tremaining: 323ms\n",
      "18:\tlearn: 0.5596040\ttotal: 3.05s\tremaining: 161ms\n",
      "19:\tlearn: 0.5552541\ttotal: 3.22s\tremaining: 0us\n",
      "0:\tlearn: 0.6831351\ttotal: 202ms\tremaining: 3.83s\n",
      "1:\tlearn: 0.6722638\ttotal: 361ms\tremaining: 3.25s\n",
      "2:\tlearn: 0.6617923\ttotal: 525ms\tremaining: 2.97s\n",
      "3:\tlearn: 0.6523439\ttotal: 669ms\tremaining: 2.67s\n",
      "4:\tlearn: 0.6425569\ttotal: 820ms\tremaining: 2.46s\n",
      "5:\tlearn: 0.6335811\ttotal: 980ms\tremaining: 2.29s\n",
      "6:\tlearn: 0.6275487\ttotal: 1.13s\tremaining: 2.1s\n",
      "7:\tlearn: 0.6206112\ttotal: 1.27s\tremaining: 1.91s\n",
      "8:\tlearn: 0.6137077\ttotal: 1.43s\tremaining: 1.74s\n",
      "9:\tlearn: 0.6072269\ttotal: 1.6s\tremaining: 1.6s\n",
      "10:\tlearn: 0.5996764\ttotal: 1.75s\tremaining: 1.43s\n",
      "11:\tlearn: 0.5939357\ttotal: 1.9s\tremaining: 1.27s\n",
      "12:\tlearn: 0.5882755\ttotal: 2.06s\tremaining: 1.11s\n",
      "13:\tlearn: 0.5826812\ttotal: 2.21s\tremaining: 947ms\n",
      "14:\tlearn: 0.5781900\ttotal: 2.39s\tremaining: 796ms\n",
      "15:\tlearn: 0.5723982\ttotal: 2.57s\tremaining: 643ms\n",
      "16:\tlearn: 0.5649254\ttotal: 2.72s\tremaining: 481ms\n",
      "17:\tlearn: 0.5569710\ttotal: 2.88s\tremaining: 320ms\n",
      "18:\tlearn: 0.5510047\ttotal: 3.11s\tremaining: 164ms\n",
      "19:\tlearn: 0.5474049\ttotal: 3.26s\tremaining: 0us\n",
      "0:\tlearn: 0.6834966\ttotal: 174ms\tremaining: 3.3s\n",
      "1:\tlearn: 0.6717733\ttotal: 312ms\tremaining: 2.81s\n",
      "2:\tlearn: 0.6619372\ttotal: 445ms\tremaining: 2.52s\n",
      "3:\tlearn: 0.6530592\ttotal: 579ms\tremaining: 2.32s\n",
      "4:\tlearn: 0.6456218\ttotal: 708ms\tremaining: 2.12s\n",
      "5:\tlearn: 0.6386447\ttotal: 846ms\tremaining: 1.97s\n",
      "6:\tlearn: 0.6316756\ttotal: 982ms\tremaining: 1.82s\n",
      "7:\tlearn: 0.6225059\ttotal: 1.14s\tremaining: 1.7s\n",
      "8:\tlearn: 0.6136762\ttotal: 1.28s\tremaining: 1.57s\n",
      "9:\tlearn: 0.6046955\ttotal: 1.43s\tremaining: 1.43s\n",
      "10:\tlearn: 0.5980472\ttotal: 1.58s\tremaining: 1.29s\n",
      "11:\tlearn: 0.5912460\ttotal: 1.75s\tremaining: 1.16s\n",
      "12:\tlearn: 0.5847639\ttotal: 1.93s\tremaining: 1.04s\n",
      "13:\tlearn: 0.5801247\ttotal: 2.12s\tremaining: 909ms\n",
      "14:\tlearn: 0.5746898\ttotal: 2.3s\tremaining: 768ms\n",
      "15:\tlearn: 0.5702911\ttotal: 2.48s\tremaining: 621ms\n",
      "16:\tlearn: 0.5628704\ttotal: 2.66s\tremaining: 469ms\n",
      "17:\tlearn: 0.5579591\ttotal: 2.84s\tremaining: 315ms\n",
      "18:\tlearn: 0.5525806\ttotal: 3.01s\tremaining: 159ms\n",
      "19:\tlearn: 0.5474560\ttotal: 3.22s\tremaining: 0us\n",
      "0:\tlearn: 0.6742902\ttotal: 202ms\tremaining: 3.83s\n",
      "1:\tlearn: 0.6561216\ttotal: 370ms\tremaining: 3.33s\n",
      "2:\tlearn: 0.6407894\ttotal: 533ms\tremaining: 3.02s\n",
      "3:\tlearn: 0.6295727\ttotal: 675ms\tremaining: 2.7s\n",
      "4:\tlearn: 0.6150806\ttotal: 816ms\tremaining: 2.45s\n",
      "5:\tlearn: 0.6022830\ttotal: 950ms\tremaining: 2.22s\n",
      "6:\tlearn: 0.5924916\ttotal: 1.1s\tremaining: 2.04s\n",
      "7:\tlearn: 0.5820022\ttotal: 1.25s\tremaining: 1.87s\n",
      "8:\tlearn: 0.5750403\ttotal: 1.4s\tremaining: 1.71s\n",
      "9:\tlearn: 0.5660934\ttotal: 1.56s\tremaining: 1.56s\n",
      "10:\tlearn: 0.5596810\ttotal: 1.71s\tremaining: 1.4s\n",
      "11:\tlearn: 0.5502515\ttotal: 1.86s\tremaining: 1.24s\n",
      "12:\tlearn: 0.5403360\ttotal: 2.01s\tremaining: 1.08s\n",
      "13:\tlearn: 0.5290322\ttotal: 2.17s\tremaining: 928ms\n",
      "14:\tlearn: 0.5233968\ttotal: 2.32s\tremaining: 774ms\n",
      "15:\tlearn: 0.5152690\ttotal: 2.48s\tremaining: 620ms\n",
      "16:\tlearn: 0.5071663\ttotal: 2.64s\tremaining: 466ms\n",
      "17:\tlearn: 0.4998090\ttotal: 2.79s\tremaining: 310ms\n",
      "18:\tlearn: 0.4935302\ttotal: 2.94s\tremaining: 155ms\n",
      "19:\tlearn: 0.4877212\ttotal: 3.1s\tremaining: 0us\n",
      "0:\tlearn: 0.6739732\ttotal: 188ms\tremaining: 3.57s\n",
      "1:\tlearn: 0.6525296\ttotal: 337ms\tremaining: 3.03s\n",
      "2:\tlearn: 0.6375332\ttotal: 490ms\tremaining: 2.77s\n",
      "3:\tlearn: 0.6219289\ttotal: 646ms\tremaining: 2.58s\n",
      "4:\tlearn: 0.6076129\ttotal: 801ms\tremaining: 2.4s\n",
      "5:\tlearn: 0.5926895\ttotal: 957ms\tremaining: 2.23s\n",
      "6:\tlearn: 0.5823217\ttotal: 1.11s\tremaining: 2.07s\n",
      "7:\tlearn: 0.5664262\ttotal: 1.27s\tremaining: 1.9s\n",
      "8:\tlearn: 0.5567436\ttotal: 1.43s\tremaining: 1.74s\n",
      "9:\tlearn: 0.5449251\ttotal: 1.58s\tremaining: 1.58s\n",
      "10:\tlearn: 0.5375370\ttotal: 1.73s\tremaining: 1.42s\n",
      "11:\tlearn: 0.5296022\ttotal: 1.89s\tremaining: 1.26s\n",
      "12:\tlearn: 0.5199018\ttotal: 2.05s\tremaining: 1.1s\n",
      "13:\tlearn: 0.5123828\ttotal: 2.21s\tremaining: 947ms\n",
      "14:\tlearn: 0.5045789\ttotal: 2.37s\tremaining: 791ms\n",
      "15:\tlearn: 0.4958997\ttotal: 2.53s\tremaining: 633ms\n",
      "16:\tlearn: 0.4901324\ttotal: 2.69s\tremaining: 475ms\n",
      "17:\tlearn: 0.4840485\ttotal: 2.85s\tremaining: 317ms\n",
      "18:\tlearn: 0.4747961\ttotal: 3.05s\tremaining: 160ms\n",
      "19:\tlearn: 0.4688125\ttotal: 3.22s\tremaining: 0us\n",
      "0:\tlearn: 0.6786833\ttotal: 185ms\tremaining: 3.51s\n",
      "1:\tlearn: 0.6570816\ttotal: 343ms\tremaining: 3.08s\n",
      "2:\tlearn: 0.6422473\ttotal: 518ms\tremaining: 2.94s\n",
      "3:\tlearn: 0.6268263\ttotal: 673ms\tremaining: 2.69s\n",
      "4:\tlearn: 0.6098549\ttotal: 835ms\tremaining: 2.51s\n",
      "5:\tlearn: 0.5952851\ttotal: 999ms\tremaining: 2.33s\n",
      "6:\tlearn: 0.5872004\ttotal: 1.17s\tremaining: 2.16s\n",
      "7:\tlearn: 0.5748982\ttotal: 1.32s\tremaining: 1.98s\n",
      "8:\tlearn: 0.5639229\ttotal: 1.47s\tremaining: 1.8s\n",
      "9:\tlearn: 0.5553352\ttotal: 1.63s\tremaining: 1.63s\n",
      "10:\tlearn: 0.5472249\ttotal: 1.79s\tremaining: 1.46s\n",
      "11:\tlearn: 0.5396024\ttotal: 1.95s\tremaining: 1.3s\n",
      "12:\tlearn: 0.5286655\ttotal: 2.11s\tremaining: 1.14s\n",
      "13:\tlearn: 0.5189371\ttotal: 2.27s\tremaining: 973ms\n",
      "14:\tlearn: 0.5131750\ttotal: 2.42s\tremaining: 808ms\n",
      "15:\tlearn: 0.5082702\ttotal: 2.58s\tremaining: 645ms\n",
      "16:\tlearn: 0.5007151\ttotal: 2.74s\tremaining: 483ms\n",
      "17:\tlearn: 0.4943298\ttotal: 2.9s\tremaining: 323ms\n",
      "18:\tlearn: 0.4904198\ttotal: 3.06s\tremaining: 161ms\n",
      "19:\tlearn: 0.4848372\ttotal: 3.22s\tremaining: 0us\n",
      "0:\tlearn: 0.6737108\ttotal: 176ms\tremaining: 3.34s\n",
      "1:\tlearn: 0.6552873\ttotal: 333ms\tremaining: 3s\n",
      "2:\tlearn: 0.6366435\ttotal: 489ms\tremaining: 2.77s\n",
      "3:\tlearn: 0.6195750\ttotal: 650ms\tremaining: 2.6s\n",
      "4:\tlearn: 0.6069613\ttotal: 811ms\tremaining: 2.43s\n",
      "5:\tlearn: 0.5930261\ttotal: 976ms\tremaining: 2.28s\n",
      "6:\tlearn: 0.5821988\ttotal: 1.13s\tremaining: 2.1s\n",
      "7:\tlearn: 0.5702991\ttotal: 1.28s\tremaining: 1.92s\n",
      "8:\tlearn: 0.5578704\ttotal: 1.44s\tremaining: 1.76s\n",
      "9:\tlearn: 0.5486455\ttotal: 1.6s\tremaining: 1.6s\n",
      "10:\tlearn: 0.5408087\ttotal: 1.76s\tremaining: 1.44s\n",
      "11:\tlearn: 0.5324481\ttotal: 1.92s\tremaining: 1.28s\n",
      "12:\tlearn: 0.5237968\ttotal: 2.08s\tremaining: 1.12s\n",
      "13:\tlearn: 0.5163382\ttotal: 2.24s\tremaining: 960ms\n",
      "14:\tlearn: 0.5087628\ttotal: 2.39s\tremaining: 798ms\n",
      "15:\tlearn: 0.4986510\ttotal: 2.55s\tremaining: 638ms\n",
      "16:\tlearn: 0.4910815\ttotal: 2.71s\tremaining: 478ms\n",
      "17:\tlearn: 0.4822461\ttotal: 2.87s\tremaining: 319ms\n",
      "18:\tlearn: 0.4770944\ttotal: 3.02s\tremaining: 159ms\n",
      "19:\tlearn: 0.4715382\ttotal: 3.21s\tremaining: 0us\n",
      "0:\tlearn: 0.6744285\ttotal: 206ms\tremaining: 3.92s\n",
      "1:\tlearn: 0.6545355\ttotal: 376ms\tremaining: 3.38s\n",
      "2:\tlearn: 0.6423077\ttotal: 545ms\tremaining: 3.09s\n",
      "3:\tlearn: 0.6268971\ttotal: 700ms\tremaining: 2.8s\n",
      "4:\tlearn: 0.6086838\ttotal: 853ms\tremaining: 2.56s\n",
      "5:\tlearn: 0.5949466\ttotal: 1s\tremaining: 2.35s\n",
      "6:\tlearn: 0.5820412\ttotal: 1.18s\tremaining: 2.2s\n",
      "7:\tlearn: 0.5682789\ttotal: 1.34s\tremaining: 2s\n",
      "8:\tlearn: 0.5582438\ttotal: 1.49s\tremaining: 1.82s\n",
      "9:\tlearn: 0.5458835\ttotal: 1.65s\tremaining: 1.65s\n",
      "10:\tlearn: 0.5384765\ttotal: 1.8s\tremaining: 1.48s\n",
      "11:\tlearn: 0.5318285\ttotal: 1.96s\tremaining: 1.31s\n",
      "12:\tlearn: 0.5230219\ttotal: 2.12s\tremaining: 1.14s\n",
      "13:\tlearn: 0.5172011\ttotal: 2.27s\tremaining: 974ms\n",
      "14:\tlearn: 0.5102847\ttotal: 2.43s\tremaining: 810ms\n",
      "15:\tlearn: 0.5040428\ttotal: 2.58s\tremaining: 646ms\n",
      "16:\tlearn: 0.4970297\ttotal: 2.74s\tremaining: 483ms\n",
      "17:\tlearn: 0.4897827\ttotal: 2.92s\tremaining: 324ms\n",
      "18:\tlearn: 0.4833585\ttotal: 3.08s\tremaining: 162ms\n",
      "19:\tlearn: 0.4754488\ttotal: 3.27s\tremaining: 0us\n",
      "0:\tlearn: 0.6732511\ttotal: 195ms\tremaining: 3.7s\n",
      "1:\tlearn: 0.6551383\ttotal: 354ms\tremaining: 3.18s\n",
      "2:\tlearn: 0.6403560\ttotal: 518ms\tremaining: 2.94s\n",
      "3:\tlearn: 0.6254719\ttotal: 669ms\tremaining: 2.68s\n",
      "4:\tlearn: 0.6119497\ttotal: 827ms\tremaining: 2.48s\n",
      "5:\tlearn: 0.5969480\ttotal: 992ms\tremaining: 2.31s\n",
      "6:\tlearn: 0.5849833\ttotal: 1.15s\tremaining: 2.13s\n",
      "7:\tlearn: 0.5745274\ttotal: 1.3s\tremaining: 1.95s\n",
      "8:\tlearn: 0.5669773\ttotal: 1.47s\tremaining: 1.79s\n",
      "9:\tlearn: 0.5554440\ttotal: 1.62s\tremaining: 1.62s\n",
      "10:\tlearn: 0.5455725\ttotal: 1.78s\tremaining: 1.46s\n",
      "11:\tlearn: 0.5383158\ttotal: 1.94s\tremaining: 1.29s\n",
      "12:\tlearn: 0.5310007\ttotal: 2.1s\tremaining: 1.13s\n",
      "13:\tlearn: 0.5220835\ttotal: 2.25s\tremaining: 963ms\n",
      "14:\tlearn: 0.5143807\ttotal: 2.41s\tremaining: 803ms\n",
      "15:\tlearn: 0.5079314\ttotal: 2.57s\tremaining: 643ms\n",
      "16:\tlearn: 0.5004666\ttotal: 2.72s\tremaining: 481ms\n",
      "17:\tlearn: 0.4944614\ttotal: 2.89s\tremaining: 321ms\n",
      "18:\tlearn: 0.4893735\ttotal: 3.04s\tremaining: 160ms\n",
      "19:\tlearn: 0.4841643\ttotal: 3.2s\tremaining: 0us\n",
      "Best CatBoost parameters: {'iterations': 20, 'learning_rate': 0.1}\n",
      "Best CatBoost ROC AUC score: 0.8355022156792486\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1080\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281310\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509314 -> initscore=0.037260\n",
      "[LightGBM] [Info] Start training from score 0.037260\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281163\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508860 -> initscore=0.035442\n",
      "[LightGBM] [Info] Start training from score 0.035442\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281363\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281403\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281192\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1080\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281310\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509314 -> initscore=0.037260\n",
      "[LightGBM] [Info] Start training from score 0.037260\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281163\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508860 -> initscore=0.035442\n",
      "[LightGBM] [Info] Start training from score 0.035442\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281363\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281403\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281192\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1080\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281310\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509314 -> initscore=0.037260\n",
      "[LightGBM] [Info] Start training from score 0.037260\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281163\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508860 -> initscore=0.035442\n",
      "[LightGBM] [Info] Start training from score 0.035442\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281363\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281403\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281192\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1080\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281310\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509314 -> initscore=0.037260\n",
      "[LightGBM] [Info] Start training from score 0.037260\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281163\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508860 -> initscore=0.035442\n",
      "[LightGBM] [Info] Start training from score 0.035442\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281363\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281403\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281192\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1080\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281310\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509314 -> initscore=0.037260\n",
      "[LightGBM] [Info] Start training from score 0.037260\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281163\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508860 -> initscore=0.035442\n",
      "[LightGBM] [Info] Start training from score 0.035442\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281363\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281403\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281192\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1080\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281310\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509314 -> initscore=0.037260\n",
      "[LightGBM] [Info] Start training from score 0.037260\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281163\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508860 -> initscore=0.035442\n",
      "[LightGBM] [Info] Start training from score 0.035442\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281363\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281403\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281192\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1080\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281310\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509314 -> initscore=0.037260\n",
      "[LightGBM] [Info] Start training from score 0.037260\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281163\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508860 -> initscore=0.035442\n",
      "[LightGBM] [Info] Start training from score 0.035442\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281363\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281403\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281192\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1080\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281310\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509314 -> initscore=0.037260\n",
      "[LightGBM] [Info] Start training from score 0.037260\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281163\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508860 -> initscore=0.035442\n",
      "[LightGBM] [Info] Start training from score 0.035442\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281363\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281403\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281192\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1401, number of negative: 1351\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 283594\n",
      "[LightGBM] [Info] Number of data points in the train set: 2752, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509084 -> initscore=0.036341\n",
      "[LightGBM] [Info] Start training from score 0.036341\n",
      "Best LightGBM parameters: {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 20}\n",
      "Best LightGBM ROC AUC score: 0.8858240473414731\n",
      "Best XGBoost parameters: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 20}\n",
      "Best XGBoost ROC AUC score: 0.8857237803559193\n",
      "Best GradientBoosting parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 20}\n",
      "Best GradientBoosting ROC AUC score: 0.8741955767846104\n",
      "0:\tlearn: 0.6732511\ttotal: 188ms\tremaining: 3.56s\n",
      "1:\tlearn: 0.6551383\ttotal: 331ms\tremaining: 2.98s\n",
      "2:\tlearn: 0.6403560\ttotal: 483ms\tremaining: 2.74s\n",
      "3:\tlearn: 0.6254719\ttotal: 631ms\tremaining: 2.52s\n",
      "4:\tlearn: 0.6119497\ttotal: 784ms\tremaining: 2.35s\n",
      "5:\tlearn: 0.5969480\ttotal: 932ms\tremaining: 2.17s\n",
      "6:\tlearn: 0.5849833\ttotal: 1.08s\tremaining: 2.01s\n",
      "7:\tlearn: 0.5745274\ttotal: 1.23s\tremaining: 1.84s\n",
      "8:\tlearn: 0.5669773\ttotal: 1.39s\tremaining: 1.7s\n",
      "9:\tlearn: 0.5554440\ttotal: 1.53s\tremaining: 1.53s\n",
      "10:\tlearn: 0.5455725\ttotal: 1.69s\tremaining: 1.38s\n",
      "11:\tlearn: 0.5383158\ttotal: 1.84s\tremaining: 1.23s\n",
      "12:\tlearn: 0.5310007\ttotal: 1.99s\tremaining: 1.07s\n",
      "13:\tlearn: 0.5220835\ttotal: 2.13s\tremaining: 914ms\n",
      "14:\tlearn: 0.5143807\ttotal: 2.29s\tremaining: 762ms\n",
      "15:\tlearn: 0.5079314\ttotal: 2.43s\tremaining: 608ms\n",
      "16:\tlearn: 0.5004666\ttotal: 2.58s\tremaining: 455ms\n",
      "17:\tlearn: 0.4944614\ttotal: 2.73s\tremaining: 303ms\n",
      "18:\tlearn: 0.4893735\ttotal: 2.88s\tremaining: 152ms\n",
      "19:\tlearn: 0.4841643\ttotal: 3.03s\tremaining: 0us\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1401, number of negative: 1351\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 283594\n",
      "[LightGBM] [Info] Number of data points in the train set: 2752, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509084 -> initscore=0.036341\n",
      "[LightGBM] [Info] Start training from score 0.036341\n",
      "0:\tlearn: 0.6742902\ttotal: 167ms\tremaining: 3.17s\n",
      "1:\tlearn: 0.6561216\ttotal: 313ms\tremaining: 2.82s\n",
      "2:\tlearn: 0.6407894\ttotal: 478ms\tremaining: 2.71s\n",
      "3:\tlearn: 0.6295727\ttotal: 624ms\tremaining: 2.49s\n",
      "4:\tlearn: 0.6150806\ttotal: 771ms\tremaining: 2.31s\n",
      "5:\tlearn: 0.6022830\ttotal: 927ms\tremaining: 2.16s\n",
      "6:\tlearn: 0.5924916\ttotal: 1.08s\tremaining: 2s\n",
      "7:\tlearn: 0.5820022\ttotal: 1.22s\tremaining: 1.83s\n",
      "8:\tlearn: 0.5750403\ttotal: 1.37s\tremaining: 1.68s\n",
      "9:\tlearn: 0.5660934\ttotal: 1.52s\tremaining: 1.52s\n",
      "10:\tlearn: 0.5596810\ttotal: 1.67s\tremaining: 1.37s\n",
      "11:\tlearn: 0.5502515\ttotal: 1.81s\tremaining: 1.21s\n",
      "12:\tlearn: 0.5403360\ttotal: 1.97s\tremaining: 1.06s\n",
      "13:\tlearn: 0.5290322\ttotal: 2.12s\tremaining: 908ms\n",
      "14:\tlearn: 0.5233968\ttotal: 2.3s\tremaining: 766ms\n",
      "15:\tlearn: 0.5152690\ttotal: 2.44s\tremaining: 611ms\n",
      "16:\tlearn: 0.5071663\ttotal: 2.6s\tremaining: 458ms\n",
      "17:\tlearn: 0.4998090\ttotal: 2.75s\tremaining: 306ms\n",
      "18:\tlearn: 0.4935302\ttotal: 2.9s\tremaining: 153ms\n",
      "19:\tlearn: 0.4877212\ttotal: 3.05s\tremaining: 0us\n",
      "0:\tlearn: 0.6739732\ttotal: 180ms\tremaining: 3.42s\n",
      "1:\tlearn: 0.6525296\ttotal: 329ms\tremaining: 2.96s\n",
      "2:\tlearn: 0.6375332\ttotal: 480ms\tremaining: 2.72s\n",
      "3:\tlearn: 0.6219289\ttotal: 627ms\tremaining: 2.51s\n",
      "4:\tlearn: 0.6076129\ttotal: 774ms\tremaining: 2.32s\n",
      "5:\tlearn: 0.5926895\ttotal: 919ms\tremaining: 2.15s\n",
      "6:\tlearn: 0.5823217\ttotal: 1.08s\tremaining: 2s\n",
      "7:\tlearn: 0.5664262\ttotal: 1.24s\tremaining: 1.85s\n",
      "8:\tlearn: 0.5567436\ttotal: 1.4s\tremaining: 1.72s\n",
      "9:\tlearn: 0.5449251\ttotal: 1.55s\tremaining: 1.55s\n",
      "10:\tlearn: 0.5375370\ttotal: 1.72s\tremaining: 1.4s\n",
      "11:\tlearn: 0.5296022\ttotal: 1.87s\tremaining: 1.25s\n",
      "12:\tlearn: 0.5199018\ttotal: 2.02s\tremaining: 1.09s\n",
      "13:\tlearn: 0.5123828\ttotal: 2.17s\tremaining: 930ms\n",
      "14:\tlearn: 0.5045789\ttotal: 2.32s\tremaining: 775ms\n",
      "15:\tlearn: 0.4958997\ttotal: 2.48s\tremaining: 619ms\n",
      "16:\tlearn: 0.4901324\ttotal: 2.63s\tremaining: 463ms\n",
      "17:\tlearn: 0.4840485\ttotal: 2.77s\tremaining: 308ms\n",
      "18:\tlearn: 0.4747961\ttotal: 2.93s\tremaining: 154ms\n",
      "19:\tlearn: 0.4688125\ttotal: 3.08s\tremaining: 0us\n",
      "0:\tlearn: 0.6786833\ttotal: 177ms\tremaining: 3.36s\n",
      "1:\tlearn: 0.6570816\ttotal: 327ms\tremaining: 2.94s\n",
      "2:\tlearn: 0.6422473\ttotal: 491ms\tremaining: 2.78s\n",
      "3:\tlearn: 0.6268263\ttotal: 733ms\tremaining: 2.93s\n",
      "4:\tlearn: 0.6098549\ttotal: 888ms\tremaining: 2.66s\n",
      "5:\tlearn: 0.5952851\ttotal: 1.04s\tremaining: 2.42s\n",
      "6:\tlearn: 0.5872004\ttotal: 1.19s\tremaining: 2.2s\n",
      "7:\tlearn: 0.5748982\ttotal: 1.34s\tremaining: 2.01s\n",
      "8:\tlearn: 0.5639229\ttotal: 1.49s\tremaining: 1.82s\n",
      "9:\tlearn: 0.5553352\ttotal: 1.64s\tremaining: 1.64s\n",
      "10:\tlearn: 0.5472249\ttotal: 1.8s\tremaining: 1.47s\n",
      "11:\tlearn: 0.5396024\ttotal: 1.96s\tremaining: 1.31s\n",
      "12:\tlearn: 0.5286655\ttotal: 2.11s\tremaining: 1.14s\n",
      "13:\tlearn: 0.5189371\ttotal: 2.27s\tremaining: 973ms\n",
      "14:\tlearn: 0.5131750\ttotal: 2.42s\tremaining: 807ms\n",
      "15:\tlearn: 0.5082702\ttotal: 2.57s\tremaining: 642ms\n",
      "16:\tlearn: 0.5007151\ttotal: 2.72s\tremaining: 480ms\n",
      "17:\tlearn: 0.4943298\ttotal: 2.87s\tremaining: 319ms\n",
      "18:\tlearn: 0.4904198\ttotal: 3.04s\tremaining: 160ms\n",
      "19:\tlearn: 0.4848372\ttotal: 3.2s\tremaining: 0us\n",
      "0:\tlearn: 0.6737108\ttotal: 180ms\tremaining: 3.41s\n",
      "1:\tlearn: 0.6552873\ttotal: 329ms\tremaining: 2.96s\n",
      "2:\tlearn: 0.6366435\ttotal: 485ms\tremaining: 2.75s\n",
      "3:\tlearn: 0.6195750\ttotal: 628ms\tremaining: 2.51s\n",
      "4:\tlearn: 0.6069613\ttotal: 781ms\tremaining: 2.34s\n",
      "5:\tlearn: 0.5930261\ttotal: 928ms\tremaining: 2.17s\n",
      "6:\tlearn: 0.5821988\ttotal: 1.07s\tremaining: 1.99s\n",
      "7:\tlearn: 0.5702991\ttotal: 1.22s\tremaining: 1.84s\n",
      "8:\tlearn: 0.5578704\ttotal: 1.38s\tremaining: 1.69s\n",
      "9:\tlearn: 0.5486455\ttotal: 1.53s\tremaining: 1.53s\n",
      "10:\tlearn: 0.5408087\ttotal: 1.69s\tremaining: 1.38s\n",
      "11:\tlearn: 0.5324481\ttotal: 1.84s\tremaining: 1.23s\n",
      "12:\tlearn: 0.5237968\ttotal: 2s\tremaining: 1.08s\n",
      "13:\tlearn: 0.5163382\ttotal: 2.16s\tremaining: 927ms\n",
      "14:\tlearn: 0.5087628\ttotal: 2.31s\tremaining: 772ms\n",
      "15:\tlearn: 0.4986510\ttotal: 2.48s\tremaining: 619ms\n",
      "16:\tlearn: 0.4910815\ttotal: 2.63s\tremaining: 464ms\n",
      "17:\tlearn: 0.4822461\ttotal: 2.78s\tremaining: 309ms\n",
      "18:\tlearn: 0.4770944\ttotal: 2.93s\tremaining: 154ms\n",
      "19:\tlearn: 0.4715382\ttotal: 3.08s\tremaining: 0us\n",
      "0:\tlearn: 0.6744285\ttotal: 193ms\tremaining: 3.66s\n",
      "1:\tlearn: 0.6545355\ttotal: 345ms\tremaining: 3.1s\n",
      "2:\tlearn: 0.6423077\ttotal: 508ms\tremaining: 2.88s\n",
      "3:\tlearn: 0.6268971\ttotal: 666ms\tremaining: 2.66s\n",
      "4:\tlearn: 0.6086838\ttotal: 838ms\tremaining: 2.51s\n",
      "5:\tlearn: 0.5949466\ttotal: 988ms\tremaining: 2.31s\n",
      "6:\tlearn: 0.5820412\ttotal: 1.15s\tremaining: 2.13s\n",
      "7:\tlearn: 0.5682789\ttotal: 1.29s\tremaining: 1.94s\n",
      "8:\tlearn: 0.5582438\ttotal: 1.45s\tremaining: 1.77s\n",
      "9:\tlearn: 0.5458835\ttotal: 1.6s\tremaining: 1.6s\n",
      "10:\tlearn: 0.5384765\ttotal: 1.75s\tremaining: 1.43s\n",
      "11:\tlearn: 0.5318285\ttotal: 1.9s\tremaining: 1.26s\n",
      "12:\tlearn: 0.5230219\ttotal: 2.06s\tremaining: 1.11s\n",
      "13:\tlearn: 0.5172011\ttotal: 2.21s\tremaining: 946ms\n",
      "14:\tlearn: 0.5102847\ttotal: 2.36s\tremaining: 787ms\n",
      "15:\tlearn: 0.5040428\ttotal: 2.51s\tremaining: 628ms\n",
      "16:\tlearn: 0.4970297\ttotal: 2.66s\tremaining: 469ms\n",
      "17:\tlearn: 0.4897827\ttotal: 2.82s\tremaining: 313ms\n",
      "18:\tlearn: 0.4833585\ttotal: 2.99s\tremaining: 157ms\n",
      "19:\tlearn: 0.4754488\ttotal: 3.14s\tremaining: 0us\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1080\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281310\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509314 -> initscore=0.037260\n",
      "[LightGBM] [Info] Start training from score 0.037260\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281163\n",
      "[LightGBM] [Info] Number of data points in the train set: 2201, number of used features: 1320\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508860 -> initscore=0.035442\n",
      "[LightGBM] [Info] Start training from score 0.035442\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281363\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281403\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1323\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 1121, number of negative: 1081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281192\n",
      "[LightGBM] [Info] Number of data points in the train set: 2202, number of used features: 1322\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509083 -> initscore=0.036335\n",
      "[LightGBM] [Info] Start training from score 0.036335\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Stacking ensemble model saved as 'stacking_ensemble_model1.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Define individual model classes and their parameter grids for grid search\n",
    "models = {\n",
    "    'RandomForest': (RandomForestClassifier(), {\n",
    "        'n_estimators': [5, 20],\n",
    "        'max_depth': [None, 5, 10]\n",
    "    }),\n",
    "    'CatBoost': (CatBoostClassifier(), {\n",
    "        'iterations': [5, 20],\n",
    "        'learning_rate': [0.05, 0.1]\n",
    "    }),\n",
    "    'LightGBM': (LGBMClassifier(), {\n",
    "        'n_estimators': [5, 20],\n",
    "        'max_depth': [5, 20],\n",
    "        'learning_rate': [0.05, 0.1]\n",
    "    }),\n",
    "    'XGBoost': (XGBClassifier(), {\n",
    "        'n_estimators': [5, 20],\n",
    "        'max_depth': [5, 10],\n",
    "        'learning_rate': [0.05, 0.1]\n",
    "    }),\n",
    "    'GradientBoosting': (GradientBoostingClassifier(), {\n",
    "        'n_estimators': [5, 20],\n",
    "        'max_depth': [5, 10],\n",
    "        'learning_rate': [0.05, 0.1]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Perform grid search for each model\n",
    "best_models = {}\n",
    "for name, (model, param_grid) in models.items():\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='roc_auc', cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "    print(f\"Best {name} parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best {name} ROC AUC score: {grid_search.best_score_}\")\n",
    "\n",
    "# Define the stacking ensemble with the best models\n",
    "estimators = [(name, model) for name, model in best_models.items()]\n",
    "stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "# Train the stacking ensemble on training dataset\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Define the filename for saving the model\n",
    "model_filename = \"stacking_ensemble_model1.pkl\"\n",
    "\n",
    "# Save the stacking ensemble model to a .pkl file\n",
    "joblib.dump(stacking_model, model_filename)\n",
    "\n",
    "print(f\"Stacking ensemble model saved as '{model_filename}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Final Stacking Ensemble ROC AUC on Test Data: 0.9377230935640887\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final stacking ensemble on the external test dataset\n",
    "y_pred_stacking = stacking_model.predict_proba(X_test_external)[:, 1]\n",
    "auc_stacking = roc_auc_score(y_test_external, y_pred_stacking)\n",
    "print(f\"Final Stacking Ensemble ROC AUC on Test Data: {auc_stacking}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "still working on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_external\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_stacking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ayush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ayush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Ayush\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:94\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     96\u001b[0m             type_true, type_pred\n\u001b[0;32m     97\u001b[0m         )\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    101\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test_external, y_pred_stacking) #giving error ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test_external, y_pred_stacking))\n",
    "print('Confusion Matrix:')\n",
    "cm = confusion_matrix(y_test_external, y_pred_stacking)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzde3yO9f/A8dd97z7s3tnMHMecChEmRY5FVPimYoRIB3KIlBIlUinJqZBSzomR/IREyrkiLIecz2dmmB3ve7s/vz9mt93bve2+Z9u92fv5eHjYdd2f67reu68d3vtc78/no1FKKYQQQgghhCiCtO4OQAghhBBCiNySZFYIIYQQQhRZkswKIYQQQogiS5JZIYQQQghRZEkyK4QQQgghiixJZoUQQgghRJElyawQQgghhCiyJJkVQgghhBBFliSzQgghhBCiyJJkVgghsqHRaBg9enSenOvkyZNoNBrmzJmTJ+cTsGHDBjQaDRs2bHB3KEIIN5FkVhRrc+bMQaPR2P7pdDrKly/PCy+8wLlz5xweo5Ri/vz5NG/enICAALy8vKhTpw5jxowhLi4uy2v99NNPPPHEEwQFBWEwGChXrhzh4eH8/vvvTsWamJjIpEmTeOihh/D398fT05N77rmHgQMHcvjw4Vx9/kXJCy+8gI+Pj7vDcMrChQuZPHlyvl4jLTFO+6fVagkMDOSJJ57gzz//zNdrC+elJdvO/MsL//33H6NHj+bkyZNOtR89erRdDF5eXlSsWJEOHTowe/ZskpKSch3L6tWr8+wPQSGyo3N3AEIUBmPGjKFy5cokJiby119/MWfOHLZs2cK+ffvw9PS0tUtJSaFbt25ERETQrFkzRo8ejZeXF5s3b+aDDz5gyZIl/Pbbb5QuXdp2jFKKF198kTlz5lC/fn3eeOMNypQpw4ULF/jpp59o1aoVW7du5eGHH84yvqioKB5//HF27txJ+/bt6datGz4+Phw6dIhFixbxzTffYDab8/U9Kq4SEhLQ6Vz7Ublw4UL27dvH66+/bre/UqVKJCQkoNfr8yy+5557jieffJKUlBQOHz7M9OnTeeSRR9ixYwd16tTJs+sUVs2bNychIQGDweDuUByqWbMm8+fPt9s3fPhwfHx8ePfdd/P8ev/99x8ffPABLVu2JDQ01OnjvvrqK3x8fEhKSuLcuXP8+uuvvPjii0yePJmVK1cSEhLiciyrV69m2rRpktCK/KeEKMZmz56tALVjxw67/cOGDVOAWrx4sd3+sWPHKkANHTo007lWrFihtFqtevzxx+32jx8/XgHq9ddfV1arNdNx8+bNU3///Xe2cbZr105ptVq1dOnSTK8lJiaqN998M9vjnWWxWFRSUlKenCuv9erVS3l7e7s7DKe0a9dOVapUKV+vceLECQWo8ePH2+3/5ZdfFKD69euXr9d3JDY2tsCvWRTdd999qkWLFvly7iVLlihA/fHHH061HzVqlALUlStXMr22YMECpdVq1UMPPZSrWAYMGKAkzRAFQb7KRLGWVTK7cuVKBaixY8fa9sXHx6sSJUqoe+65R1ksFofn6927twLUn3/+aTsmMDBQ1ahRQyUnJ+cqxr/++ksB6pVXXnGqfYsWLRz+ouzVq5ddgpU+GZo0aZKqUqWK0mq16q+//lIeHh5q9OjRmc5x8OBBBagvv/zStu/atWtq8ODBqkKFCspgMKiqVauqTz/9VKWkpLj8uWbH2WQ2IiJChYWFKU9PT1WyZEnVvXt3dfbsWYftatasqYxGo7rvvvvUsmXLMr1HSikFqFGjRtm2Y2Ji1ODBg1WlSpWUwWBQpUqVUq1bt1Y7d+5USqW+/4Ddv7Rzpr3ns2fPtrvGgQMHVOfOnVVQUJDy9PRU99xzjxoxYkS2n2dWyWxsbKwCVJs2bez2O3ufoqKiVI8ePZSvr6/y9/dXPXv2VJGRkZniTrsfR48eVU888YTy8fFRTz31lFJKqZSUFDVp0iRVq1YtZTQaVXBwsOrTp4+Kjo62u9aOHTtUmzZtVMmSJZWnp6cKDQ1VvXv3tmvzww8/qLCwMOXj46N8fX1V7dq11eTJk22v//HHHw6TN2e+DtI+h7Nnz6qnnnpKeXt7q6CgIPXmm2/m+vvVGY6SWWfvT3bvR9rPs4z/sktss0tmlVKqT58+ClBr16617du0aZPq1KmTCgkJUQaDQVWoUEG9/vrrKj4+3tamV69eDmNJM378eNW4cWMVGBioPD09VVhYmFqyZImzb6EQdqTMQAgH0urNSpQoYdu3ZcsWrl27xuDBg7N87NyzZ09mz57NypUradSoEVu2bCE6OprXX38dDw+PXMWyYsUKAJ5//vlcHZ+T2bNnk5iYSJ8+fTAajZQtW5YWLVoQERHBqFGj7NouXrwYDw8POnfuDEB8fDwtWrTg3Llz9O3bl4oVK7Jt2zaGDx/OhQsX8r1uNKM5c+bQu3dvGjZsyCeffMKlS5eYMmUKW7duZffu3QQEBACwatUqunTpQp06dfjkk0+4du0aL730EuXLl8/xGq+++ipLly5l4MCB1KpVi6tXr7JlyxYOHDhAWFgY7777Ljdu3ODs2bNMmjQJINta3z179tCsWTP0ej19+vQhNDSUY8eO8fPPP/Pxxx+7/B44+tp19j5ZrVY6dOjA9u3b6devHzVq1OD//u//6NWrl8NrJScn07ZtW5o2bcrnn3+Ol5cXAH379rXdi0GDBnHixAmmTp3K7t272bp1K3q9nsuXL9OmTRtKlSrFO++8Q0BAACdPnmTZsmW2869bt47nnnuOVq1aMW7cOAAOHDjA1q1bGTx4cJbvgbNfB5BaOtS2bVseeughPv/8c3777TcmTJhA1apV6devn8vvf244e39yej+aN2/OoEGD+OKLLxgxYgQ1a9YEsP2fG88//zzffPMNa9eu5bHHHgNgyZIlxMfH069fP0qWLMn27dv58ssvOXv2LEuWLAFSvwbOnz/PunXrMpVZAEyZMoX//e9/dO/eHbPZzKJFi+jcuTMrV66kXbt2uY5XFFPuzqaFcKe0nozffvtNXblyRZ05c0YtXbpUlSpVShmNRnXmzBlb28mTJytA/fTTT1meLzo6WgHqmWeeUUopNWXKlByPycnTTz+tAHXt2jWn2rvaM+vn56cuX75s1/brr79WgNq7d6/d/lq1aqlHH33Utv3hhx8qb29vdfjwYbt277zzjvLw8FCnT592KmZn5NQzazabVXBwsKpdu7ZKSEiw7U/rZX///fdt++rUqaMqVKigbt68adu3YcMGu17UNGTomfX391cDBgzINtasygwc9cw2b95c+fr6qlOnTtm1dVSS4uhcH3zwgbpy5Yq6ePGi2rx5s2rYsKEC7Hq5nL1PP/74owLsej5TUlLUo48+6rBnFlDvvPOO3Tk3b96sAPX999/b7V+zZo3d/p9++snhU5H0Bg8erPz8/LLtJc3YM+vK10Ha5zBmzBi7c9avX181aNAgy2veqYw9s87eH2fej7wsM1AqtccYUE8//bRtX/oe2DSffPKJ0mg0dl/H2ZUZZDyH2WxWtWvXtvv5IoSzZDYDIYDWrVtTqlQpQkJC6NSpE97e3qxYsYIKFSrY2ty8eRMAX1/fLM+T9lpMTIzd/9kdk5O8OEd2nn32WUqVKmW375lnnkGn07F48WLbvn379vHff//RpUsX274lS5bQrFkzSpQoQVRUlO1f69atSUlJYdOmTfkSsyP//PMPly9fpn///naD9tq1a0eNGjVYtWoVAOfPn2fv3r307NnTrse0RYsWTg2YCggI4O+//+b8+fN3HPOVK1fYtGkTL774IhUrVrR7zdnR7aNGjaJUqVKUKVOGZs2aceDAASZMmECnTp1sbZy9T2vWrEGv1/PKK6/YjtVqtQwYMCDL62fsvVyyZAn+/v489thjdtdq0KABPj4+/PHHHwC23tGVK1disVgcnjsgIIC4uDjWrVvn1HsBzn8dpPfqq6/abTdr1ozjx487fc075ez9yc37cafSvkfSfv4BmEwm28dxcXFERUXx8MMPo5Ri9+7dTp03/TmuXbvGjRs3aNasGbt27cqjyEVxImUGQgDTpk3jnnvu4caNG8yaNYtNmzZhNBrt2qQlk+l/qGeUMeH18/PL8ZicpD9H+sejeaVy5cqZ9gUFBdGqVSsiIiL48MMPgdQSA51OxzPPPGNrd+TIEfbs2ZMpGU5z+fLlLK9748YNEhISbNsGg4HAwMDcfhqcOnUKgHvvvTfTazVq1GDLli127apVq5apXbVq1XL8ZfrZZ5/Rq1cvQkJCaNCgAU8++SQ9e/akSpUqLsecljDVrl3b5WPT9OnTh86dO5OYmMjvv//OF198QUpKil0bZ+/TqVOnKFu2rK1cII2j9wpAp9PZ/cGXdq0bN24QHByc7bVatGjBs88+ywcffMCkSZNo2bIlHTt2pFu3brbvvf79+xMREcETTzxB+fLladOmDeHh4Tz++ONZvh/Ofh2k8fT0zPS+lChRgmvXrmV5Dcjbr19n709u3o87FRsbC9j/MX369Gnef/99VqxYkel9unHjhlPnXblyJR999BGRkZF203/l1RRloniRZFYI4MEHH+SBBx4AoGPHjjRt2pRu3bpx6NAhW89EWt3Znj176Nixo8Pz7NmzB4BatWoBqb88Afbu3ZvlMTlJf45mzZrl2F6j0aCUyrQ/Y4KTJn0PSXpdu3ald+/eREZGUq9ePSIiImjVqhVBQUG2Nlarlccee4y3337b4TnuueeeLOMcPHgwc+fOtW23aNGiSEx8Hx4eTrNmzfjpp59Yu3Yt48ePZ9y4cSxbtownnniiwOOpXr06rVu3BqB9+/Z4eHjwzjvv8Mgjj9i+pu/kPmXHaDSi1do/4LNarQQHB/P99987PCYtYdNoNCxdupS//vqLn3/+2TYV1IQJE/jrr7/w8fEhODiYyMhIfv31V3755Rd++eUXZs+eTc+ePe2+du5EbmvZ8/Lr19n7UxDvR0b79u0Dbv9Bk5KSwmOPPUZ0dDTDhg2jRo0aeHt7c+7cOV544QWsVmuO59y8eTP/+9//aN68OdOnT6ds2bLo9Xpmz57NwoUL8+XzEHc3SWaFyMDDw4NPPvmERx55hKlTp/LOO+8A0LRpUwICAli4cCHvvvuuw1+C8+bNA1KTirRjSpQowQ8//MCIESNy9YuzQ4cOfPLJJyxYsMCpZLZEiRIOH5Gm9Vg5q2PHjvTt29dWanD48GGGDx9u16Zq1arExsbakilXvP322/To0cMu7jtRqVIlAA4dOsSjjz5q99qhQ4dsr6f9f/To0UzncLTPkbJly9K/f3/69+/P5cuXCQsL4+OPP7Yls872LqX15qYlDHnh3XffZebMmbz33nusWbMGcP4+VapUiT/++IP4+Hi73lln35e0a/322280adIkyz+U0mvUqBGNGjXi448/ZuHChXTv3p1Fixbx8ssvA6k9nh06dKBDhw5YrVb69+/P119/zciRIx32GDv7dXCn8vLr15Xvo5zej7zu2UwbvNW2bVsg9Y/qw4cPM3fuXHr27Glr56j0IatYfvzxRzw9Pfn111/tnoDNnj07L0MXxYjUzArhQMuWLXnwwQeZPHkyiYmJAHh5eTF06FAOHTrkcLLzVatWMWfOHNq2bUujRo1sxwwbNowDBw4wbNgwhz2mCxYsYPv27VnG0rhxYx5//HG+/fZbli9fnul1s9nM0KFDbdtVq1bl4MGDXLlyxbbv33//ZevWrU5//pBan9e2bVsiIiJYtGgRBoMhU+9yeHg4f/75J7/++mum469fv05ycnKW569VqxatW7e2/WvQoIFL8WX0wAMPEBwczIwZM+weW/7yyy8cOHDANkK6XLly1K5dm3nz5tkeoQJs3LiRvXv3ZnuNlJSUTI9Rg4ODKVeunN01vb29nXrcWqpUKZo3b86sWbM4ffq03WuOvlacERAQQN++ffn111+JjIwEnL9Pbdu2xWKxMHPmTNvrVquVadOmOX398PBwUlJSbOUp6SUnJ3P9+nUgtU4y4+dYr149ANt7efXqVbvXtVot999/v12bjJz9OrhTefn16+z9ceb98Pb2th13pxYuXMi3335L48aNadWqFXC7Jzv9vVNKMWXKlEzHZxWLh4cHGo3G7mnRyZMnHf58E8IZ0jMrRBbeeustOnfuzJw5c2wDRN555x12797NuHHj+PPPP3n22WcxmUxs2bKFBQsWULNmzUyP+9566y3279/PhAkT+OOPP+jUqRNlypTh4sWLLF++nO3bt7Nt27ZsY5k3bx5t2rThmWeeoUOHDrRq1Qpvb2+OHDnCokWLuHDhAp9//jkAL774IhMnTqRt27a89NJLXL58mRkzZnDffffZBpM5q0uXLvTo0YPp06fTtm3bTDW7b731FitWrKB9+/a88MILNGjQgLi4OPbu3cvSpUs5efKkXVnCnbJYLHz00UeZ9gcGBtK/f3/GjRtH7969adGiBc8995xtSqbQ0FCGDBliaz927FieeuopmjRpQu/evbl27RpTp06ldu3adgluRjdv3qRChQp06tSJunXr4uPjw2+//caOHTuYMGGCrV2DBg1YvHgxb7zxBg0bNsTHx4cOHTo4POcXX3xB06ZNCQsLo0+fPlSuXJmTJ0+yatUqWzLqqsGDBzN58mQ+/fRTFi1a5PR96tixIw8++CBvvvkmR48epUaNGqxYsYLo6GjAuR7nFi1a0LdvXz755BMiIyNp06YNer2eI0eOsGTJEqZMmUKnTp2YO3cu06dP5+mnn6Zq1arcvHmTmTNn4ufnx5NPPgnAyy+/THR0NI8++igVKlTg1KlTfPnll9SrVy/L6ab0er3TXweFhbP3x5n3o169enh4eDBu3Dhu3LiB0Wjk0UcfzbKGOc3SpUvx8fHBbDbbVgDbunUrdevWtU23BallT1WrVmXo0KGcO3cOPz8/fvzxR4c1xmkJ/qBBg2jbti0eHh507dqVdu3aMXHiRB5//HG6devG5cuXmTZtGtWqVbOVagnhEjfOpCCE22W1aIJSqVMSVa1aVVWtWtVuKpyUlBQ1e/Zs1aRJE+Xn56c8PT3Vfffdpz744INsV0BaunSpatOmjQoMDFQ6nU6VLVtWdenSRW3YsMGpWOPj49Xnn3+uGjZsqHx8fJTBYFDVq1dXr732mjp69Khd2wULFqgqVaoog8Gg6tWrp3799ddsF03ISkxMjDKZTApQCxYscNjm5s2bavjw4apatWrKYDCooKAg9fDDD6vPP/9cmc1mpz43Z2Q1CTugqlatamu3ePFiVb9+fWU0GlVgYGCWiyYsWrRI1ahRQxmNRlW7dm21YsUK9eyzz6oaNWrYtSPd1FxJSUnqrbfeUnXr1lW+vr7K29tb1a1bV02fPt3umNjYWNWtWzcVEBDg1KIJ+/btU08//bQKCAhQnp6e6t5771UjR47M9v3I6f698MILysPDw/a14ex9unLliurWrZtt0YQXXnhBbd26VQFq0aJFdvcju6nSvvnmG9WgQQNlMpmUr6+vqlOnjnr77bfV+fPnlVJK7dq1Sz333HOqYsWKtoUV2rdvr/755x/bOdK+Z4KDg5XBYFAVK1ZUffv2VRcuXLC1yWrRBGe+DrL6HNKmq8ovjhZNcOb+OPN+KKXUzJkzVZUqVZSHh4fTiyak/fP09FQVKlRQ7du3V7NmzVKJiYmZjvnvv/9U69atlY+PjwoKClKvvPKK+vfffzN9bScnJ6vXXntNlSpVSmk0Grv39LvvvlPVq1dXRqNR1ahRQ82ePTvf33dx99IolctnWUIIcZepV68epUqVKtCpj4qC5cuX8/TTT7NlyxaaNGni7nCEEMKO1MwKIYodi8WSqZ53w4YN/Pvvv7Rs2dI9QRUS6aebgtQ64S+//BI/Pz/CwsLcFJUQQmRNamaFEMXOuXPnaN26NT169KBcuXIcPHiQGTNmUKZMmUwT6Bc3r732GgkJCTRu3JikpCSWLVvGtm3bGDt2rFOzEwghREGTMgMhRLFz48YN+vTpw9atW7ly5Qre3t60atWKTz/9lKpVq7o7PLdauHAhEyZM4OjRoyQmJlKtWjX69evHwIED3R2aEEI4JMmsEEIIIYQosqRmVgghhBBCFFmSzAohhBBCiCKr2A0As1qtnD9/Hl9f3zxf9k8IIYQQQtw5pRQ3b96kXLlyaLXZ970Wu2T2/PnzhISEuDsMIYQQQgiRgzNnzlChQoVs2xS7ZNbX1xdIfXP8/Pzy/XoWi4W1a9falnQURY/cw6JP7mHRJ/ewaJP7V/QV9D2MiYkhJCTElrdlp9gls2mlBX5+fgWWzHp5eeHn5yffwEWU3MOiT+5h0Sf3sGiT+1f0ueseOlMSKgPAhBBCCCFEkSXJrBBCCCGEKLIkmRVCCCGEEEWWJLNCCCGEEKLIkmRWCCGEEEIUWZLMCiGEEEKIIkuSWSGEEEIIUWRJMiuEEEIIIYosSWaFEEIIIUSRJcmsEEIIIYQosiSZFUIIIYQQRZYks0IIIYQQosiSZFYIIYQQQhRZkswKIYQQQogiy63J7KZNm+jQoQPlypVDo9GwfPnyHI/ZsGEDYWFhGI1GqlWrxpw5c/I9TiGEEEIIUTi5NZmNi4ujbt26TJs2zan2J06coF27djzyyCNERkby+uuv8/LLL/Prr7/mc6RCCCGEEKIw0rnz4k888QRPPPGE0+1nzJhB5cqVmTBhAgA1a9Zky5YtTJo0ibZt2+ZXmEIIIYoBpRQJyQnuDuOulJycjFmZSUhOwIIlX6+llCI+Pt5un5eXFxqNBoCkpCSSk5MdHpdstmIymdBqU/v6zGYzFkvW8Zo8PdFazbbzmuNis2zraTTi4eFx+7wOYnDU1mKxYM4mBqPBgE6nc9jWalUkJCYTm5RMXHIylmQdiSkKq1KkpCRjMWd9Xp1ebztvSkoycfFxnDoTTdO4REoG6LM8zh3cmsy66s8//6R169Z2+9q2bcvrr7+e5TFJSUkkJSXZtmNiYoDUG57dF2heSbtGQVxL5A+5h0Xf3XQPlVIkpiS6O4wCZ7FYMCszMQkx6JPz/hepUoqXfnuJQ9cO5epYZVaZX9CA1nD7Aag1yZr1SfKrLaA15rKt2QoOPq1ctTVo0VkNjP3hU6wWK8qadWMPo8ft8+bQVmvQpiapSqGPt6JSFP9NOEL8Wfs/SsI+q43eN/Xr5sQPZ7i8KSrLc37Q7XtK+pYB4Kc/v2b9nogs277b+TvKBoYCsOqfufyyc16Wbd96ehqVgmsA8FvkYpb//U2WbQd1mMA95eoBsHHfcpZs/TLLtq8+/jG1KzUC4K9Da1iwYXyWbV9s/T5hVVsAsOvYRmb9NibLtj1avkWjex9HKcXSrVPZuH85n73wf5xqcgK/2jWzPC6vuPLzukglsxcvXqR06dJ2+0qXLk1MTAwJCQmYTKZMx3zyySd88MEHmfavXbsWLy+vfIs1o3Xr1hXYtUT+kHtY9OXVPVRK5XvvksProvg29lsupFwo8GtnisWqUJZsshcP0Oq0ed529JLRzp9XC1r9rbZZJZy5aZsumVRKcWzUMRJPZ/4Dw+d+H0LfCLVtH3jtQJbn9brXiyrDq9i2Dw09RMrNFIdtTZVNVB1V1bZ9ZMQRLFcdfz0ayxmpPra6bfvYB8dIOp/ksK2+pJ57J9xr2z7xyQkSTjjuqfbw9aDml7cSGgWnJpwm7pDjXkmtQcv7A2YTFF8BgK9+GcH+0387bAswte9628ffrfuA3cc3Zdl2wosrMepTf/fP/2Mcfx9e67Bd530f4GsKAGBx1BQusyLLc4rbEs3x/LB5EjuP/g7A5v9WUGp3E86cPpHv187Yu56dIpXM5sbw4cN54403bNsxMTGEhITQpk0b/Pz88v36FouFdevW8dhjj6HXF65ueeEcuYdFn6N7mNsezjvpwSuKMiZ2ab1xcYfiODnuZJbHlQ4vTaknSwGQcDKB42OOZ9m21FOlKP10akdF0oUkjr57NMu2QY8HUaZraq+Z5aqFw28dzrJt4KOBlOtZDoCUmykcHHQwy7YBTQKo8EoF7i1xL180/oLyweWzbPvU008x7/vUHri4uDjK9S7nsN3DZR9mSfgS23bZ/mWJNzv+BR0WHMaq8FW27SpDq3D15lWHbWuUqMGG8A2gFFjiqTPyQU5fPeuwbWW/SmzteDvBe+jTlhw87/g9K+tVms3/W0PyzdQE9rGJzxDJXodtA/R+/PHITygF62ZfZFTMQI7yr8O2OqvBlsgWlAolqzHkqcm2bYPO0/bxMw/3o2OjPg6P84k9x0O7x5HWN/ywsmK5t3aW1/HcOxntrfKFh5WV/g+3JqLDS6DJ3PaKXs9VberTYf9qrXn+6UeyPG+MXs+uW229qzfn+Q4P272u12nxMegweeoI8DaBpwe+Rh3tn/4fzw7vgLdRj49Ri5feA2+jB/pbfwCmL0l4Nvk53jc/m2UMh48c5dXBr3H8xEk8PDx487X+PFC/Lo93fBZPB52HeS3tSbozilQyW6ZMGS5dumS379KlS/j5+TnslQUwGo0YjcZM+/V6fYEmJgV9PZH35B4WXjnVOiZrUuv1kjW3a9R6/dqLg9FZJzeFWY3AGsx9fG6+nT+t5lApxWOPPMaef/cAEFIxhCFvDuHFl1/kz63beGLck1me47X7X2VI54EA7Ny5m+Zj2mTZ9pX7XuDdzm8D8N9/B2n4brMs2z5XvROfdv4QgFOnTlPrrQZZtu1U7Skmdf4MgCtXoggdlPWj0Xahbfmm81RMHp459gjpNRr8btUzpnWK1Kt7P5t/X2ury1RKoVI0eKYrizx3LOskXavVYkrX9uhex0mkra1FwfyOcGk/e7orlApy2FajicY0oa5t+6+OWbeFJH5+fR0xpooA9Gw4jucfyLosYfHY07aP+z/5CUplX8Lgc/MMYZGTaGRKISWbBNFr0xDbx4301mzbmrYNt73nLUokUe7NUqABL/0NNJoXs43HER1JaKpn06D0fdBjOWjSZat6k227nslEe42DTLYIUUoxY8YMhgwZQlJSEiEhISxatIiGDRuyevVqPE2mAvld6Mo1NEqpbJ6lFByNRsNPP/1Ex44ds2wzbNgwVq9ezd503+TdunUjOjqaNWvWOHWdmJgY/P39uXHjRoH1zK5evZonn3xSEqEiSu5h4ZQ+ge21puAT0/xMKB0NYEkvwDvA9rVosVgwm80ZTwCW1OONRqOtJyY5OdluDEFGhlu9Nk0feYxtf/7lsE2Thxuzef2vWGc9TuLZrBMuvQcYPFJ/qadYFYlZj3Wxa2tVioRsKjhcaavTglF3O7mMz6O2Hlrw1N1OWOLMCi896RJZWBY9louW/K8rLCzSElVNNimF1mp21GF5R+JDKnPmvU/w9dTj7eeNr8mAr6cOH6MOX08deo88nrRJ72WfyN6Fjhw5wn333YfFYqFDhw7Mnj2bkiVLFvjvQlfyNbf2zMbGxnL06O2/VE+cOEFkZCSBgYFUrFiR4cOHc+7cOebNS32c8+qrrzJ16lTefvttXnzxRX7//XciIiJYtWpVVpcQQhRBzowqz4sEtkbAPcxtPSNXv5xMHp7Z/uJ2lVIKq9WKVqvNNpkEWPnTUto9+TgA389bQO9XXs2ybUQnE53vS/3F89N+C+FLs35fZz/lSY/79YwITeaz8x5sOpVas1mvjJbNvb3RAF76fWg+rYAH4G1w7n3z0GrwNjjVFK0mf9pq8qktZH4fkpWxSCeyPjfPoH22GlHJEB1rJirezNVYM9FxZm4kmHH0ZZ/sbYAnhmXa723U4ePtS6CPgeSb16geWh4/kwEfT71d0unjqcPPqMfHU2fb70wiqjGZaHCXJ5cFrXr16kycOBGLxcLrr79u+yOtMHNrMvvPP//wyCO3a0bSalt79erFnDlzuHDhAqdP336MUblyZVatWsWQIUOYMmUKFSpU4Ntvv5VpuYQoYnJKVnOTqNYoUYO5raZnTkyVQs3riOby/kzHmNRpNLuruXSd1FMqFLd74swpCovjsToAeOpSE7qs2iqg2ew4JrX1pEmIB90CLJz113D6RhbJcsTzEHmrZyTS7LhNLum0Gtrdo6dl6O1fD+l7He2UqQO91zj1x0DatEe5ZbFY+O239bRu3arQPyGxmK3w7i4Aen8cht6QN72DSilUYoaedZ3n7fdfKU699DLmQ3dWz30goBxv/T0gw33VAp6g88RDqyHIx0ApXyPBvp6U8jFSytd4a/v2x6V8jXgZbk8Zldqr16DQ37/iRinF1KlTadasGfXq1QNg4MCB7g3KRW5NZlu2bEl2VQ6OVvdq2bIlu3fvzseohBD5yaqsdFnZJU/KAmw9q4Bpfkc0428npukfFadPxpKSFcm3cipHD/JNemwDOrJLPBc8beK+4NS6ybGbk/hgY9ZJ5faXvWlYPrXtlL/MvP2b40f9n201s6SziQEPGnihXta/8I3pfnJ3r6Oncy0HbUvfB88vx+jpCbfKDJ5OTib2m9RrO0ouDQYDlluJRvqOySwrBPRegCbbKZnSrvXThF1Encl6Dk7nBDH7d8eDjAorD62Hbb7QO6IUJ3s8T9KBAzlf89b/x/zLMbTZgJxuj42vp44gHyP+Ab508DfZktSMCWqglwGttvD31omcXbt2jZdeeomffvqJ6tWrs3v3bry9vd0dlsuK1AAwIUTRlL4nNnxlOKdiTuV4TI2Ae5jb6itY8DRcytyrCo57VpVSxFlSE87Ii6nJ2uWhPuiDKuE9cBNvvDmM6V/PzPK6Jw7tJzS0EgDvvvMun0+a4rDdZzefYvrHk1J/8Kd8DBs/yfqT6b0aHrg1UGnCZPjtPYfNrpUMw2vUetBoyOrXSVoSmr6k0+ET8Vu1fQqwzV7lAQYvnzxMLkV2/G8c41jjAXleJ5qTtCQ20cOAzkObudfUx0gpP89MyaqnPg+SblFk/P3333Tp0oVTp05hMBgYNGhQgU5ZmpckmRVC5JlM5QO3BiL1+u1VDl63nw6okm8IEW1vDaC6NSo7vdREtbrtvI4G5MRj3+uaWPI+Gn8XR+St0fdpLAN2sy1yH08afMAjh0ecBi8w3Eols2l75NgJvAJKgUbDiJGjeeudd7Ns6+npCbd65wa/+Rb9B73usF36VYrSpO9BLepJaFCID0+/GeZUDZ5SCpVw+2vJkmzht/Xrad2qFXrdHTymzqNH8c7IjwFPaYmqn0lP0K1kNMjHQJC3kSBfI6V8DQSVDOD//DwJ9jXib9JLL6qwo5Ri4sSJvPPOOyQnJ1O1alUWL15MgwZZzwxS2EkyK4RwLN2IeMcvKxLSz9OqlMOk1ZEaSWYWn9iKdk/O9apKKRrOsbLzdJzD12OjL9keiz3f/QUi/11qe61evXps3rwZg8EA/6YmyxMnTuSzzz7L8nrpp/n7+OOPGT16tMN26RNPg8GQeg0nuNJWKcWy8bu4ePyGU+1d5UpymRd0aas1pZMxab210+Ej9XuBM6Pfz5NY8roPMqZCZX5+cTRRsWauxCVxJSaJq3FJJGezelVGBg8tQT5GSvoaKXWrJjXI20gpPyNB3gaCfIzULeXPv36eGHXSiypcFxsby3PPPcfKlSsBCA8PZ+bMmQUyu1N+kmRWiOIsq4RVKZj9OFx0PPWSAnqWLU2kZ+Y5nLNSI8nM3Aup80SblMrcY3VrMJHi9sov3t7exMfFsXNM6YytbzN423pS05LatCTW29sbjUZjtyxiVnNPOzy1C4lnRnc64AnAkpTiMJHNqyTUUXKZkcNkM5dUQobyWhfqQPOasWZNQhfMzzR4zWpVXI03c+lGIhdjErl8M4mLNxK5FJPIpZgkLsUkcjEmgUSL/b1N8jDAniv2F9EaQAslvPS3B0ule9Qf7GdM96jfEz+TrkiMHBdFl5eXF0lJSRiNRqZMmUKfPn3uiq85SWaFuJtl17uaQ8Lq8BAgQaMhQaPJMpFNn7QCtoFIJp0p+x+aei8U0LRpU7Zt23YrRIW3wZtOnTpx9OhRNm/enOkc6Wu8vv76a6ZNm+bwcX1Byo8e1d6fNUV/a816Z5LQtDiyS0QzJZeZT+C2ZBPsE06LxcKva9fStk2bXI+GNydbuRKbmpAeS4Lfd13iwq2k9eKNRFvSmnNvqh50qUlqGX8TZfyMt/73tEtQU0sAjBh0eTzXqRAusFqtWCwWjEYjWq2W+fPnc/HiRerWrZvzwUWEJLNC3K2sVvimucNkNS0pBbKfVulWIopGk2UZwYanV2PS3X40b/LwtE+0XJhkPC421pbIpjd//nyMRmOOCZwrva75KdlszdNEtmxVf0y+ervVpaw5rVvu5kTUFVn1kmpMt/8A0losKIMBrZcXWgfJbLw5OTUhvZWYXriVnKbfvhqX5HCO1Iw0Ggj2NdoS1bL+Jsr4e1LGz5My/p6U9fektJ+nDJgShd7ly5fp2bMnFStW5JtvvgGgdOnSlC6dzdOuIkiSWSHuRko5TGTTktheZUtz0OjM4/MYWPpolq/WD65PoG+FPOkFVUrRrNntZUzTL13t6enp6JBCI2NJgSXp9nxe6XtUcyutJ1YphYqPL/AkNatkM6+kT1ozUkoRk5DMmas3OXBNQ+w/Z7kca+FSjH3CeiO7pcDSMXhoKe1vvJWYmmyJaVl/T1vCWsrXmPcrRwlRwDZu3Mhzzz3HhQsXMJlMDB8+nMqVK7s7rHwhyawQdyNLPFzcm5q8BlaBl9YCOD1AKzvpl3HNsXTABfHx8URGRgKpNa+lSpXKk/Pmt5xKCvRGD5eSWUelASohdX9ukti8SESzSzbvhNWqiIpL4tK5GC7cSLB73J/+8X+CbbJfDzj4X5bn8zJ4pEtKbyWq/p6UvdWjWsbfU+ZIFXe9lJQUxo4dy+jRo7FardSsWZOIiIi7NpEFSWaFuGvYTYtliQdbD2yyw97V9EmpK/Iygc2Ko9rYwiq7koKyVf3RubD6k1KKU926k+DEwjDOJqn5lYjmxJJivTVoKl0P6o1ELqRLWC/fTMSS4txo/xJeekyYqV6hFOUCvCiTrjc1LWn1NcoAKlG8Xbx4kR49erB+/XoAXnjhBaZOnVokF0JwhSSzQhRV6QZ3KaXo+VsfIqPSlRWEhjg8LC2JzeukVCllm4UgTfofoAkJCVitWY/u9/Dw4MknnwRApysaP5qUUtmWFGQ3UMtRD6w1ISHHRDYtidW4cZBbgjmFizGJqb2pGepS05LXqFgX61Nt9aimTI/9y/h74oH11nKoYbIcqhAOWK1WWrduzf79+/Hy8uKrr76iZ8+e7g6rQBSN3xhCCFvyauuBTbfQQIJGQ2SlCg4Pq1GiBnOfuN0Dmx9JbFxcHM2aNbOVCQAEBQVx5crtqYqeeOIJNm7c6PAcXl5exMXFsWrVqjyLK78pqyLikx12Cxg4U1LgbN1r9a1b0Kab8zZNfva0KqWISUy+lZgm2PWqpk9Una1P1Xto0iWmt0f9p69TdbY+1WK5s2nOhLjbabVaxo0bx4gRI1i8eDE1atRwd0gFRpJZIYoCpWBWW9SZv2/P72rCYe/rhlNnMSmVOhNB718xGbzzNflJP5XW3SS7eWKVUkSM3cGNy7d7Vh2VFGTqfXWy7tUUFoZHYGC+3LcUq+L89QSOR8Vx4kosJ6LiOB4Vx7lrCVywq0/NnpfBw/aIv4yfiTL+txJVqU8VosCcP3+eo0eP0rx5cwDatWtH27Zti8zTrbxSvD5bIQqhTEvAOmKJh7PbSdBqs12ooH7Q/QR2/TM1CXJhSqyc4stYPgCpS8hqNBrMZrNtX9piBY6SsF9++SXbMoP8pJTCmnxrlgFrzr2Ariwb6x9sInxEQ1uPrG3KLCcSV2empMoNpRRX48yciIrjxJXUZPVEVGrievJqPObk7O9DgJferiY1bTBVmXT/pD5VCPf69ddfef7557FYLERGRlKpUiWg6JRp5aXi9xkLUQCcSlBv6bWmFwejD+bcMEMv7IanV2PyDLRLhO60hEApRUJCgm0hAqUUDzzwALt27crUtlKlSpw8eZIdO3YQF5e61Gx2ixWYHDwyT9/7mb72NC8ppVj2+W6unvVl9rq87UEOKu9FpyF10FjNqHjnZxvIq7rXuKTk1IQ13b+0HteYxOQsjzN4aAkN8qJykDeVg3yoEuRNhUAT5W7NpyrzpwpReCUnJzNy5Eg+/fRTILUTITk56+/34kCSWSHymFKKnr/0JPJKZL5dIy/md83Y45o2z6vZbGb//tRa3Pj4eIeJbEY5jZR19Mjeld5Pd0lbNhbgdO8XSfz3X7vXtVYzh7/P/hyOel9d6Xm1pFg5Ex2fIVlN/fhiTGKWx2k0UD7AROUgb6oEeacmrqVSE9dyASY85PG/EEXOmTNneO6559i6dSsA/fv3Z8KECYV+Lu78JsmsEHksITnB5US2RsA9zG09I3NZgFLwXRu4diJ1u/R98OJaTPo769HLqdY1Li4Ob29vvL29qVWrFgaDIVP5gLPXz4+lXXND75tCj1HNXBoJnzYbgTU+HsvuHTjTX5kxeXUmcVVKcSkmieO3SgHSktUTUXGcjo7PdnnVQG9DumQ1LXH1oVJJL+lhFeIusmrVKnr27El0dDR+fn58++23dO7c2d1hFQqSzAqRh5RS9FrTy7a9odPvmNLNOpAVkzqNZne17E8eWBX6bAbtna9MlJCQwLlz5xy+FhYWZiszANixYwemdAmZq6UBlqSUbBPZtN7P/Ky/tFgsrP3t19TZBu4wwctqloE02SWvNxIst5LU2HS1rKn/4s1Zv5cmvUeGZPX2vwAvZ1ZyE0IUdatWrSI6OpoHHniAxYsXU6VKFXeHVGhIMitEHkqwxNvqX2sEVCfwuzZooo/f+YnL1IE+m+4okU1ISLCNeN20aRMnT5601bqml7Hu1WQy2ZLXOy0NcLS0a3ZzseYZrTXHsXCO5n1NY023X2syoU2X7GeUlJzCqavxHLf1rsbaEtaoWHOWx3loNVQM9LJLVKvcSmBL+3rKrABCFHMTJ04kNDSUwYMHYzRmPRC4OJJkVog7pJQiwRIPlngS5j+VOmUWMDfydzRps8YHVoW+m3I/u0AuZyZIn6zGxcXxzz//ANhmFciu1jVtQYC8qmstW9Ufk6++UI6Ad2XlLUhdhvXc9YTMA6+iYjl7LSHbxQJK+xntBl6l9biGlPDCoLvzXnchxN1h+fLlLFiwgMWLF+Ph4YGnpydvv/22u8MqlCSZFeIOWJWVLj934eC1W7MROHr6nAe9qtnJOJArfYIaGhpKVFSUS+dKNltz7IHNTWlAgfTA5pKKj3cqkT1f4R5en7GDE9HZT2/la9RRpZS3LWlNKw8IDfLGxyg/doUQWUtKSuLtt9/miy++AOC7776jT58+bo6qcJOfqkLkQtrUW+ErwzkVcyrT6/WD7sfU9c/U3tQ8mO9VKUVSUpLdiNW4uDjbDATpV95q0aIFv/zyi8OpsACaNGliVxNru4aDFa3SZExeC3Ni6oz0JQXx5mROd+pE2mcz/60ZHLmZwqmrcZlWukryMMDl1PfH4KGlUkmvTAOvKgd5E+RjKNLvjxDCPY4dO0aXLl3YuXMnAEOHDqV3795ujqrwk2RWCBc5mnqrksVCxLmLMHgPeJW849kGMl6vadOmBAQE2C33Ghwc7HAxg+TkZFvSe/LkyUyvpyWy6QdvOVrRCm4nsXqjR5FOzpJTrFyJV2z49zRnriVy79ihBF44aXs97TM75l+OhYdv3vrjQ4tGb6ScvyldL2taLasP5UvI9FZCiLyzZMkSXn75ZWJiYggMDGTevHm0a9fO3WEVCZLMCuGijFNv1Ugys/j8RbRl6oB/SJ6supVefHy8bQqttCmzMqpbtx5/rN+ARqPBy8vLNmDLoMs892BOdbBpK1ppNJpC0QOb3cCsrNxMshB55ga7T11j1+nr7D17jQ9//5IKN85TIYtjzpcKYcPAcbwV7GsbeBVa0lumtxJC5LtPPvmEESNGAKlPz3744QdCQjIvVy4ck2RWCCeklRVYsNit7LXh6dUETqyd2rPXe02uEtm0mte0Av80aYO30g/isiSlYNGl9qieO3MBpRQrvojk5sVkFr67M3efXDpBIT6ED2+IppD0OLo6MCu9YKDtrX+OJFSqCl98TaWS3pTwMlDDZKJVEe59FkIUXe3bt+ejjz5i8ODBjBkzplguSXsn5N0SIgdWZWV67HRGRozM9JpJZ7I9os5tIpu2eEGnTp1YsmSJ7TUfH59M7We9tRmjPnMtbG56Tx0N4ipsPbHWhIRcJbJZMdSoQeXvF4BG49IqXEIIkdcOHz7MPffcA0CdOnU4evQoZcuWdXNURZMks0Jkw6qsPLPyGS6kXMj0Wv2g+zGlZD2iPSvpZx+Ii4vLchWujKqUqe2wbADuntkFsuuJ3fjpPP65mEjkmWvcTLJfh9xDq6FmWT/qVwygQcUShFUsQSnf2/MwWiwWfl27lsefegqtQRYZEEK4T0JCAoMHD2b27Nls3ryZRo0aAUgiewckmRUiC1Zl5X/L/8fpm6cBqOhbkSXtI2D+U3D2H0wnTqPZsTLbc6RPXHU6HQaDIctlZL/++mu77djY2zWtlqQUFgzfgUajcd/CA7ngar1rVj2x+wND+fTPS7d6vz3w9jIQVqkED1QK5IHQEtQLCcA7mymvtBYLyiAzDAgh3OvAgQOEh4ezb98+NBoN27dvtyWzIvckmRXCAaUUXVZ2sU27VVJbkmXtl2EkGc7syHxASKPUKbgynCN94tqrVy9mz57N2rVr+eyzzxgzZoytbZMmTShRooTd8ekHell0KbZETG/0yJTMFia2BFYpTvZ4nqQDB3J1nq5PjCLRI7UXtUQJP9pXDqRhaCANKpWgRhlfdB6ywIAQouiYO3cu/fv3Jz4+ntKlS/P999/TqlUrd4d1V5BkVhR7aYO70ktITrAtS1vRtyIva19Gq9FC+pWdhh4Fw60ENt1csmm9sY5KCDQaDd7e3rz99tt2K7k4mi4rvaz2FzZ3MmArveNlqtK+WS0aVi7JA6ElKB8g9a1CiKIpLi6OAQMGMHfuXABatWrFggULKFOmjJsju3tIMiuKnYzJa681vWyJqyMLH1/IhnUb0g6+/YLBCwyZp8mKiooiODjYbt+lS5fw9/e3bWecXkspxbLxu7h4/IYLn0nhoxyUCVgqV2Pdq2PYdfoGe89dJynDyllGnZY6FQJoUDGAsIolqBsSQI1AP9pJ8iqEuAssWrSIuXPnotVq+eCDDxg+fDgeHoX36VpRJMmsKFasykqXlV2yTV7Tqx9cH5OHJx4pSWCOhe8yPxJKSkrijTfeAGDixImZXm/SpAmlSpXKtmcx2Wx1KpEtW9UfnaFwPl5XSnH22u0/Et7rOZ590ebUVbP+PH9rr55AfwMPVCrBA6EleCA0kNrl/DHoCufnJIQQd+rFF19k+/btdOvWjRYtWrg7nLuSJLOi2Egb0OVo+dkagTWY+/jcTPtNHp6oWW1pf3Y77Lm9X5WuTbxZgSWOuLg4pk+fDsBnn31GUFCQ3eAtL6/sVwNTStmVETga4JWmMAz0SquJTU6xcvhSLDtPX2PX6WvsOnWNmOs3WXSr3b5oM0k6I1WCvGlQqQQNQ1MHa1UO8nb75yCEEPnl5s2bfPjhh4wcORJfX180Gk2mAb4ib0kyK4qFjAO6KvlVIqJ9hO11ky6LmkxzHJqz2+3PVbo2TecrtvX3zdTckpRCss5qN4VW2mpcWcWVcTWuwjrAKzbRQuThC+jfeBW/sycA8AAevPUvoy+61qdBjXIE+RgdvCqEEHeff//9l/DwcA4fPsylS5dsdbIif0kyK+5KGeti0w/oquRXiRUdV6QO6MrpPFYryVYjSiluvLgVL79AzErHtv4lMrWtUqa2bfqs3HJXGYGjKbQu30xi16lr7Dx9jchT1+gd8QlVb5zP4gz2TGFhtGkQKj2wQohiQSnF119/zeuvv05SUhIVKlSgT58+7g6r2JBkVtxV0pLY7AZ1RbSPcDqRXfbuj5yPXchnP/bj7Ef30ur+cJ5q9AofdPsesyWREj7BtoTNoPPMdfKWtuiB3uhRYAmg3RRa3XuQdDDz+1X51r9OGfbHV6yK14xvqR7si9bB0reyupYQori4ceMGffr0ISIi9Wlf+/btmTNnDiVLlnRzZMWHJLPiruBMEgu3BnTpMi8Hm3aOtJIAq9VKzJXLnLpeik9/fIErN84BYE5ORKvRUtK3TK5W3cpKQdTCpu99TbSkcPy57ngcP+LSOYw1axK6YD6aHOqAhRCiONi/fz9PPfUUx44dQ6fTMW7cOIYMGSI/HwuYJLOiyFNK0fOXnkReibTb72hQl6PaWKvVyo1rN1nxRSTXzyei89BzIfokHy95ya5dtarVWP3nDxiNqTWghWEwlrOUUux/tgse/+217ctYlXs8oDwRz79HWMUS1K9Ugroh/vga9XZtpMdVCCFuSxvwW6lSJRYvXsxDDz3k7pCKJUlmRZGV1hubkJxgl8imJbFZDupKx2q1UqtKfQ6dSp2q4IkGPWn3QK9M7SqHhrJv/z5bIluUxCUlM275bp5Ll8imuVK6EsdGTiSsYgkeqxJMO13hG3gmhBCFSUJCAiZT6hO+0qVLs3r1aipXrpxpFUdRcCSZFUVSVr2xG8I3EOgZaJfEpq3IpdfrMRhSl0dNSUkhMTGR69ExtkQWwMvPwCthE1BntjN0WBAAOk0SfzzwKVpt4Z4L1dEgrl2nrzF82V4uX7nOc7f2HZweQf17yhJSwkQNLy+aS0+rEEI45e+//6ZLly58+umndO3aFYCwsDA3RyUkmRVFUsbeWEith01LZNMSWKUUzZo1IzIyks8++4y33noLgF27dvHgg/YTSp04cJiypUwYvrwPPCBtdixrhUZYPQp3j6yyWjnxbCeSDhyw2+8NfJGh7VONqqK9tXyuEEKInCmlmDRpEsOGDSM5OZlx48YRHh5e6Ds5igtJZkWhlXF6rfTS798QvgGTzmQrK1BK0bRpU7Zt22Z3TFxcXJbXqlKmNuW+fxiDh/n2zqFHweBFCnr45Zc7+2TykVLKYSLriCksDI3J8QA4IYQQmV29epUXXniBlStXAtC5c2dmzpwpiWwhIsmsKJRcWXbWpDPhpb/d0xgfH58pka1Xrx4jRoywbYfVr0/s5EaYLxxj9pXZt6bVeu72ASGNwDsINBqwWO78E8pHKiHBlsjGB5fjhcYDMacoSnobGNXhPh6rVdrWVgZwCSGE87Zt20bXrl05c+YMRqORyZMn07dvX/k5WshIMivczlEPbPjKcIfLzmaU3VRbAGdPn8fb2zt1SVmlSV02VimIu4r+6nF+ujkRo/7W8W8dvV1boPdKTWQLqfT1sdZ0dbLdHxxAosbAY/eX5pNn6sjqW0IIkUsnTpygRYsWJCcnU716dSIiIqhXr567wxIOSDIr3MaZuWEzLjubUcYZC5RSeGj0rP31NzYvPsyyD/eh1WY1Qv8H20dBIT7ofHwLdQKbJqv6WAAfo46PnqnLs2HlpedACCHuQOXKlRk8eDAXLlxgxowZ+PpmXsJcFA6SzIoCk7EHNqcFDmoE1mBx+8VOrdYFkJSUxMtPv0VSDDSt2Z7S+nudOi6ogg/hwxsWuuTP0ewEKMWJZ57FfCpzr/XpctVZPrQ1FUrI4C4hhMiNjRs3UrlyZSpWrAjAuHHj0GqLzpzixZUksyLfuJK8OrvAQVasVisPNnyIPXv/BaDRvW3x8NBlXqUrKRY+r5768eC94F0SXQEuIeus7Hpf05z3LcWAFq9j0Gl5s8299GhxLx4eMiBBCCFclZKSwtixYxk9ejQPPfQQGzduRK/X4+Ehc28XBZLMinyR1TywGbmywEFW17EkpfDDJ1ttiWyFktXoO7E1Bk+d/SpdVit8/Qhok1K3fX3AkP/fAg57WLM/IMve1zTH/MvxWsvXuT+kBBPC61Et2CcPIhVCiOLn0qVLdO/enfXr1wNwzz33YLFY0Ov1ORwpCgtJZkW+cDQPLGTugXUliVVKkWy22m3/NGEXl07dID4pxrb/09dn4eVnsD+vUvBNc4g+lrpdpk7qIK98YktgleJkj+edmjbLEUOlSlRe9iNoNGw8fJn3lu8nKjaJFL2RIa3voX/LquikN1YIIXLl999/p1u3bly6dAkvLy+mT59Or16ZV4EUhZsksyLfpc0DC64lr+kpqyLikx1EnYnN9NqBMzuYseZd2/ZTr9fPfA1LPFy8tZxrYFXosynfBnsppTjVrTsJu3ff0XmMNWtS+celxFmsfLTyPxbtOANA9XIlmRhejzoV/PMiXCGEKHZSUlIYM2YMH374IUopateuzeLFi6lVq5a7QxO5IMmsyHcZ54F1lVKZE1mlFObkRHRaPX6lPG37mzRpgre3d/Yn7LsJ8nGya5WQkCmRNdasSeiC+S4l0BqTie0nonlzyb+cvZaARgMvN63Mm23uxVMvdVxCCJFbFouF5cuXo5Ti5ZdfZsqUKXjJyohFliSzotBLNlttiaxfKU/aDa7Fo60f4d9/I/n2m+/46IXXeP+rvqAUXnrQWOIzn8Scbl8e9MhmVwebft7X6lu3oDWZXF6sINGSwoTVB/h2ywmUggolTHzeuS6NqpS849iFEKK48/T0JCIigp07d9KtWzd3hyPukCSzIs9ZlZXwleEuH5exJjaNJSmFFGsKySlmJvz8Bj0/+tf2WqI5Ab1ej16ng1lt4czfdxR7NsFhjY/Hqte7VAerNZnQuvjX/r5zNxiyOJIjl1MT+K4NQ3ivfS18jPLtKoQQuZGcnMzIkSPx9vbmvffeA+Dee+/l3nudm8JRFG7y21HkmbSpuNKv3lUjsEamFbocJa1pg7kc1cQC/HtiC7N+G2O3r169evTp0yd1wxLvXCIb0sjlgV9KKUK+msHxd4a7dJwpLAyNKevVyTJKTrEyfcMxvlh/hGSrIsjHyLhn69CqZumcDxZCCOHQmTNneO6559i6dStarZYuXbpQvXp1d4cl8pAksyJPWJWVLiu72M0jW8mvEovbL7Y9Xk+bRstR0ppWA+uIbbnZW+rVq8fmzZvx9va+/eheqdsNhh4FQxYJqxPL1GYsIUiJicHkYJqsnOpgXSktOHYlljci/uXfM9cBeLJOGT7qWIdAb4NTxwshhMhs1apV9OzZk+joaPz8/Jg5c6YksnchSWbFHVNKZUpkM67epZRi2fhdXDx+w+HxE5a/xsnLmR/bN2jwAG++MZTJ495misdbaDQavLy8Mk+7Nfvx29sGLzDkMAgsi89DxcdnW0KQVgMLriWrWbFaFXP/PMmnvxwkKdmKn6eODzvW5n91yxW6hRyEEKKosFgsjBgxgs8//xyABg0asHjxYqpWrermyER+kGRW3LGE5ARbIlvJrxIR7SMyTcGVbLbaElmlFL5ldPxvUD08PT1JSkpi2ibgcuZz79z5D9Omf0nX58JTz6dUaklBeuZ0027lcv5YZ6bT8qxfH4/AwDxLMs9dT+CtJf+y7dhVAJpVD+KzTvdT1t/50gQhhBD2lFK0bduWP/74A4BBgwbx2WefYTQa3RyZyC+SzIo8FdE+wjYNV/raWEtSiq2UYO6Od1NX6xoDK1eupF27dgwb9jZTpkxh8+bNmXpdbTMUpPXApiWujvRek+mxvzMrcFkzTKeVvoTAYrHw69q1PP7UU3mSyCql+HHXOT5YsZ+bScmY9B6MaFeTHg9VlN5YIYS4QxqNhi5durB7925mzZrF008/7e6QRD6TZFbckbRBXxn3xcXG8fPkvUSfS30tOcXC5z8N5OzVow7P0717d3r16pW5fMCVGQpCGqH0Xqj4dD23uViBq/rWLXY9sFqLBWUw5EmiGRWbxIhle1n73yUAwioGMCG8HpWDXC+LEEIIkSopKYmzZ8/aygj69OlDx44dKV1aBtAWB5LMilxJS2J7renFgasHUObUAVixsbE0ebQJkZGRDOowgXvK1QPgj70/2iWyaYO4PD1TFzxwuAZ2VjMUlKmDeuEXVGKS/X6dJyef7ZTrpWMhdQaCvCwlSO/X/RcZsWwvV+PM6D00DHnsHvo2r4qHVnpjhRAit44fP054eDhRUVHs3r2bEiVKoNFoJJEtRiSZFS5LP3OBUorjHx4n4XhqD2zpvrd/eJgtifgHmwgf0ZCUr/fzf39nMRNBVtLNUKDePIJKubVql86Tk8/1dClpdXYFrrwY1JVRTKKFD1b8x4+7zgJQo4wvE8PrUaucX55eRwghipulS5fy0ksvERMTQ2BgIIcPH+ahhx5yd1iigEkyK1ySNnPBgasHQIGyKFKiUjK1q1CyGo0aNKP76EZotBr69X+Vl15+MfNMBFldJyUFNbUZJGtAwcnnXyHp4GGnYnSUuOZHkuqMbUejGLrkX87fSESjgb7NqzLkseoYdbIcrRBC5FZiYiJvvvkm06dPB1KXMv/hhx8ICQlxc2TCHSSZFU5JKytISE7gwNUDnPj4BPVfqc/aIWuZen0qP/zwA693mMTVc3EAGHSePPdeYzS3HqHr9XpbKUGOA7KsVk4+0YikKylA2Vs7MyeyWfW2uitxTS/BnMK4NQeZs+0kABUDvZgQXpeGoYFujUsIIYq6I0eOEB4eTmRkJADvvPMOY8aMcVyuJooFSWZFjpRS9PylJ5FXIlO3zYr4o/EE/x2MMisGDx5MRXMLrp6Nsy1wULaqP3pj5t5HZ6bAykrG5LUwJK2ORJ65zhsRkRy/kprYd3+oIiOerIm3LEcrhBB37P333ycyMpKgoCDmz5/P448/nvNB4q4mv11FjhKSE24nskphTUqdbuunZT/BPNAoD66eTU3c0mpk9UYPh4mmyjAFVnaMARZCf9kGRh+g8CavaSwpVr78/SjT/jhKilUR7GtkXKf7eeTeYHeHJoQQd42pU6ei0WgYP3485cuXd3c4ohCQZFY4TSmF99febP9ru92+nybssm2Hj2iIwdO5L6v0q2nZMcfD59XQeCg03t5ZL01biBy5dJMhEZHsOxcDwP/qlmPMU/cR4CXL0QohxJ04cOAAixYtYvTo0Wg0GkqWLMnChQvdHZYoRCSZFdmyKivhK8NBgTZBZ5fIPtz4YTQpeqLOxAIQFOLjsLQgjVIKa7paWa3JhNbLK2MjsMaBTlEUWK2KWVtP8NmvhzAnWwnw0vPhU7XpULecu0MTQogib968efTr14/4+HiqVq1Kz5493R2SKIQkmRVZSpu54NSNU3TcP5gS0WV5k/YAfNJzKT6eAcwZttXW/uk3w7IsA3CqVtZqhW+aZ7/CVyFyJjqeoUv+5e8T0QC0vLcU4569n9J+nm6OTAghira4uDgGDhzInDlzAHj00Udp06aNe4MShZYksyJLCckJHIw+iM5qoMzNKiRrLTzRIPWvYpPBxy5xzWrAV5qMtbKmsDA06UsMlMqcyIY0An3hKzFQShHxzxnG/PwfceYUvAwejGxfi64NQwp1Ta8QQhQF+/btIzw8nAMHDqDVahk9ejQjRozAw0OmNBSOSTIrHEq/TK2yKi5EnwQg4revMZoyT3+iM2iz7ZVNX16QcblYIHW1r7RENrAq9N0EBu8cFzkoaJdvJjL8x72sP3gZgIahJZjQuR4VSxa+pFsIIYqaH374gZdeeomEhATKli3LwoULadmypbvDEoWcJLMik4xTcVktVj5e8hIAQ2d0wsfo/GN0R+UF2pxmJei7yTaDQWHyy76LjPr5ANfiLRg8tAxtew8vNa0iy9EKIUQeCQ4OJjExkTZt2jB//nyCg2U2GJEzSWZFJumn4kJB+OE32YvrRfdKKVKio7MvL3CkkPXG3kiwMO+Ilp1/7gGgVlk/JnWpx71lfN0cmRBCFH1xcXF4e3sD0KpVKzZu3EiTJk3QarVujkwUFfKVIuwopei1ppdte13H9XjF3F61Smdw7ktGWa2ceOZZjjRpattXfesWKn2/wHGvrCp8sxcopVi55zxPfLGVnVFatBp47dFqLB/QRBJZIYS4Q0opZsyYQeXKlTl69Khtf7NmzSSRFS6RnllhJ23QF0CNEjXYOPWk3evODHBSSnHi2U4kHThg22cKC8tcJ5vGaoWvm99R3HntTHQ8I/9vHxsOXQEg2FMxtedDPFillJsjE0KIoi8mJoZXXnmFiIgIAL7++mvGjx/v5qhEUeX2P32mTZtGaGgonp6ePPTQQ2zfvj3b9pMnT+bee+/FZDIREhLCkCFDSExMLKBo724Ze2W/fXQWUWdjnT7WGh+PNT6elOhoWyJrqFSJe3f+Y98jqxSY41L/JcXC1Acg+ljqa2XquHUGA0uKlRkbj/HYpI1sOHQFg4eWQY9WZVjdFOqHBLgtLiGEuFvs3LmTsLAwIiIi0Ol0fP7554wbN87dYYkizK09s4sXL+aNN95gxowZPPTQQ0yePJm2bdty6NAhh0XfCxcu5J133mHWrFk8/PDDHD58mBdeeAGNRsPEiRPd8BncPZRSRCdG2/XK6lJyXr1KKYWKj+dkj+ftemLTVF72I9pbtVC3DoBZbeHM35lPFlgV+mxyW83szlPXePenvRy8eBOAxlVK8tHTtakYYGT16kNuiUkIIe4WSimmTZvGsGHDMJvNVKpUiUWLFtGoUSN3hyaKOLcmsxMnTuSVV16hd+/eAMyYMYNVq1Yxa9Ys3nnnnUztt23bRpMmTejWrRsAoaGhPPfcc/z9t4PESDjNqqx0WdnFlsiiIPzAW8xZvTXb43JaCMEUFoYm4wpflnjHiWyZOqmJrBvqpG4kWBj/60G+//s0SkEJLz3vtavFM2Hl0Wg0WCyWAo9JCCHuNr///jtffvklAB07dmTWrFmUKFHCzVGJu4Hbklmz2czOnTsZPny4bZ9Wq6V169b8+eefDo95+OGHWbBgAdu3b+fBBx/k+PHjrF69mueffz7L6yQlJZGUlGTbjomJAcBisRRIkpJ2jcKaECml6LamG4eu3e55DAt8gEt/3sScnFq+UaF6KYYMGcLff/+NXq+3fS7W+Hi7RNZQowYV5s6xbWtMJpKTk+0vaLGQNkut5fUDt0sK9F6QkpL6r4Aopfhl3yU+Wn2QK7FmAJ6pX45hbe8h0Ntgi72w30ORM7mHRZ/cw6LNYrHQvHlzdu7cSadOnRgwYIB0FhQxBf096Mp1NEq5Zxj5+fPnKV++PNu2baNx48a2/W+//TYbN27Msrf1iy++YOjQoSilSE5O5tVXX+Wrr77K8jqjR4/mgw8+yLR/4cKFeGXsNSyGzMrMmBtjACipLUl/3/5ozTqG9B/G2aupo0u//vprAgMD0el0qXWvSqGxWNCazVT98CMAjo18jxTvnBc58EhJov2eVwBYef9MUjyM+fjZZe1qIiw5oeXA9dSe4GBPRXgVK9X9C9+sCkIIURQppdi0aRNNmjRBp0vtO7NarTJTgXBKfHw83bp148aNG/j5+WXbtkjNZrBhwwbGjh3L9OnTeeihhzh69CiDBw/mww8/ZOTIkQ6PGT58OG+88YZtOyYmhpCQENq0aZPjm5MXLBYL69at47HHHkOvz7xylrvFW+IZsyQ1mY1oH4EePQ82fNCWyAI88sgjhIaGAqk/nM717EViZKTdeR5r3x5tTn8cKAXxUZA6XStt27ZJXeWrAFlSrMzedoov/zlGosWK3kNDvxZV6NOsMkad4x+whf0eipzJPSz65B4WLdHR0bz00kusWrUKnU7H6NGjWbduHW3btpX7V0QV9Pdg2pN0Z7gtmQ0KCsLDw4NLly7Z7b906RJlypRxeMzIkSN5/vnnefnllwGoU6cOcXFx9OnTh3fffdfhX3tGoxGjMXPvn16vL9BvqIK+Xk7Slqvt/mt3276RI0byzYxvbNul/Mtz6Nh+/Ev42t5ba3x8pkTWFBaGwc8v+2m7rFb4pvntJWtJfU8owPckqwFeVUs5t9pYYbuHwnVyD4s+uYeF37Zt2+jatStnzpzBYDBQuXJl2z2T+1f0FdQ9dOUabktmDQYDDRo0YP369XTs2BFIffywfv16Bg4c6PCY+Pj4TAmrh4cHkJqcCedkXK4WoEZgDTw0HrbtCiWr8dng+QQEZkhS073P1bduSV2aNqflaa1W++m3AEIaFdgUXDkN8BJCCHHnrFYr48eP59133yUlJYXq1asTERFBvXr1pDZW5Cu3lhm88cYb9OrViwceeIAHH3yQyZMnExcXZ5vdoGfPnpQvX55PPvkEgA4dOjBx4kTq169vKzMYOXIkHTp0sCW1Imd2y9WSmsgubr+Y+BaJVEtqB0CpciXo+u5DaDSa1Om3EhJAKU4886ztOK3J5FxpwTfNbyeygVWh76bU8oJ8TiSVUqzae4EPfv6PKzdTBwF2alCBEU/WJNA752nHhBBCOOfKlSv06tWLX375BYDnnnuOr7/+Gl9fWS1R5D+3JrNdunThypUrvP/++1y8eJF69eqxZs0aSpcuDcDp06ftemLfe+89NBoN7733HufOnaNUqVJ06NCBjz/+2F2fQpGTcWGEDeEbCDAEcPrUaQw6Tww6TzQaDV3efRCNVpO6LG2G1bwAjDVrojGZcr6gJf52aUFgVRj4T4FMv5VxBa8qpbz5uGMdGlctme/XFkKI4iY6OppNmzbh6enJl19+yUsvvSRPvkSBcfsAsIEDB2ZZVrBhwwa7bZ1Ox6hRoxg1alQBRHZ3sluuNrAGJYwlaNCgAZG36mAnvLgSo95k65HNKpGt/OPSnH9QKQXm+NvbffN/HllLipVvN59gyvrDJFqsGDy0DHikGq+2rIJRJ733QgiRH+69916+//57qlSpQp06ddwdjihm3J7MioJjVVbCV4bbtuc+Ppf4+HhbIlu3bj0MOk/b6yohwW5Z2srLfgSNJuca2bTlamc/bjfgK7/LCu50gJcQQgjnXLp0iV69ejFixAiaN28OwFNPPeXmqERxJclsMaGUosvKLpyKOQWk9spqkjWEhYXZ2qxdvZ4lYyKB1FkLNFaz7bVMy9JmfSHHy9Xm44AvGeAlhBAFZ/369XTv3p1Lly5x/PhxDhw4IONWhFtJMnsXUkoRHx9v+zghOYGE5AT+u/AfAKFBoSxuv5gu4V04cuRI6r5y9xDxwW5b8nekSVM80iWzTveqZlyutkwd6L0mXwZ8KaVYuecCY1bKAC8hhMhvKSkpjBkzhg8//BClFPfddx8RERGSyAq3k2T2LqOUomnTpmzbti3LNhuubUCr0eJ9q6e1bt16vPTQeFsi63/jGNp0iawpLMy5wV4Za2SHHgXvoHwpLzgTHc97y/ex8bAM8BJCiPx2/vx5unfvbhvL8tJLL/HFF1/ISpqiUJBk9i6TlJREuXLlsm1j0qUmpl9//TXTpk1D72Fk5uubAHjk1FQ4cQANLswjCw4XRcDgleeJrAzwEkKIgnXmzBkaNGjAlStX8Pb25uuvv6Z79+45HyhEAZFk9i5jMBjw7O1Jrcdq2faF+IYw/4n5QGoim9Yjm7Y6mjkx2dbWeuoYHqTOWOARGOhczWnaXLLpE9l8qJGVAV5CCFHwKlSowCOPPMKhQ4eIiIjgnnvucXdIQtiRZPYuYrVaqR9WH+sQK1pj6hRYaQsiaDVZT4mlEhLstp2eeitNxrlk83hRhBsJFj5bc5CF22WAlxBCFISzZ8/i4+NDQEAAGo2Gb7/9Fp1Oh8mZkjMhCpgks3cBpRRxcXGEhYVx5MgRSq8uTclWJdn0/CYCPZ3oXU23RG3V9evwLFMq90li301gzJueUhngJYQQBW/VqlX06tWLli1bsmTJEjQajazkJQq1/F+KSeQrq9VKWFgYvr6+tpkJbvx1A41Bg0mXda2rUgprfDzWuDhOdrtd+6T1dKI+NvPJbn+cRz2lZ6LjeWH2Dl77YTdXbiZRpZQ3P7zSiM8715VEVggh8oHFYuGtt96iffv2XL16lRMnTnDjxg13hyVEjqRntghTStmt3gVwf937SRmckm1Cmn6JWgXsaPCO7TWnZi2wDyJ1cYQ8IgO8hBCi4J06dYquXbvy119/AfDaa68xfvx4jEajmyMTImeSzBZhaTMXREZGUqNGDXbs2IHGoKHRD42yPCbjErVWrYFY3xAAgir4oDe6mDCmr5ctU+eOBn3JAC8hhCh4y5cvp3fv3ly/fh1/f39mzZrFM8884+6whHCaJLNFmKenJ6tWrSIuLg4vLy80Gg3xlvgs2yulSImOtluitsIPEWwc8Q8ATw8Nu7MBVb3X5KrMQAZ4CSGEeyQkJDBo0CCuX7/Ogw8+yKJFi6hcubK7wxLCJZLM3gW8nVhmVinFqW7dSdi927av8rIfSdF52rbvOHHMxfH/nrnOy/P+kQFeQgjhBiaTiR9++IGffvqJsWPHYjDIz15R9EgyW0TFxcURHBwMwKVLl2xTcSUkJzhsrxIS7BJZU1gYGi8vMFvvLJD0g79cdC3OTL8FO20DvGQFLyGEyH9Lly4lKSnJtvBBkyZNaNKkiZujEiL3JJktwuLjU0sKXln7Cvtu7nP6uOpbtzi/IEJ27mDwl9WqeHPJv5y/kUjlIG/+b0ATfD31dxaPEEKILCUmJvLmm28yffp0TCYTDRs2lAUQxF1Bktm7wJ6oPbae2TT1g+vblq1VSmFNtzCC1pnlaZ1xB4O/vt1ynN8PXsag0zK1W31JZIUQIh8dOXKELl26sPvWE7pBgwZJbay4a0gyexfZEL7BlsCmzTHrqFY2TygF5nSDzVwY/LXzVDTj1hwCYFSHWtxXzj9vYxNCCGGzaNEiXnnlFWJjYwkKCmLevHk88cQT7g5LiDwjyWwRpJQi+mZ0pv0mnQmvDL2jDmtl080lq3JT86oUzGoLZ/6+vc/JRPZanJnXFu4mxaroULcc3R6s6Pr1hRBC5EgpRf/+/ZkxYwYAzZo144cffqB8+fJujkyIvCUrgBUxSil6/tKTGi1r2O1PX1aQlepbt1Dp+wW2EgOlFD9N2OV6EJZ4+0Q2pJFTJQYZ62THPl1bpt4SQoh8otFoCAoKQqPR8N577/H7779LIivuStIzW8QkJCcQeSXStl2yZkm2v7AdL71XjolhxlrZZLOVqDOxAASF+KAzOPm3Tfre3KFHwTvIqZ5ZqZMVQoj8Fxsbi49P6mIzo0aN4sknn6Rx48ZujkqI/CM9s0VEXFwcpUqVolK5SliTrIS+GcqpK6e4vO8y3gZvl3s4lVJYklJs20+/6eSCCVYrfN389rbBy6lEVupkhRAif8XFxfHiiy/SsmVLkpJS5+7W6XSSyIq7nvTMFiFRUVEABBOM1qAlyD8Irdb1v0eUUiwbv4uLx2/Y9uWYyCoF5rjURDb6WOo+J2cwkDpZIYTIX/v37yc8PJz//vsPrVbLhg0baNu2rbvDEqJASDJbRGQcqFUjsEaONbK3Dsy0K9lstUtky1b1z77EwNGAr8Cq0GdTjr2yUicrhBD5RynF7NmzGThwIAkJCZQtW5aFCxfSsmVLd4cmRIGRZLaISL+yV4hvCIvbL84xKVRKcbLH89m26f1ZU0y++tvnUip1gFd65gwDvsrUSU1knegVljpZIYTIHzdv3qRfv358//33ALRp04b58+fbVocUoriQZLaISEi36MH8J+aj1eScSKqEBJIOHADAWLOm3ZRcafRGD/tENmMPbEYuDPiSOlkhhMg/ffv25YcffsDDw4MPP/yQYcOG5ar0TIiiTpLZIuLpDk/f0fGhC+bn/Hg/45RbGYU0cjqRlTpZIYTIXx999BF79uxhxowZNG3a1N3hCOE2kswWAUoprMoKgFd1L7y8nF821iarBDRtYBfYr+g19GjqTAXp6Z2buUDqZIUQIu/FxMSwZs0awsPDAahSpQp79uyR3lhR7EkyW8ilLZJgftVMLVULjUGTt4nhvKfg/JbM+w1eYPDO1SmlTlYIIfLWrl27CA8P59ixY/j7+9tmKpBEVgiZZ7bQS1skQWvQojVqCSsd5twsBtlJP8PB2R2ZX3dyRS9HpE5WCCHyjlKKqVOn0rhxY44dO0bFihXx95efq0KkJz2zhVx8fDyH3kxNDo8dOkaFwAp31jOrVGpvLG/a709fVuBkOUFGUicrhBB55/r167z00kssW7YMgP/973/Mnj2bwMBAN0cmROEiyWwhp5TCctUCgKeHp2uJrIM5ZjHHoc7+Y7/PhYFdWZE6WSGEyDs7duygS5cunDhxAr1ez/jx4xk0aJD8XBXCAUlm71IO55hVCjXrcX6K/vj2vreOgo/vHSWyIHWyQgiRlw4cOMCJEyeoXLkyixcvpmHDhu4OSYhCS5LZu5TDOWbNcSRfOExUchUAgir4oMuDRFbqZIUQ4s4ppWw9rz179iQuLo7nnnuOgIAA9wYmRCEnA8AKMauy8vzq7FfwckbogvloAGY/brf/6aFhd/zISupkhRDizm3bto0mTZoQFRVl29evXz9JZIVwgiSzhZRVWenwUwc2Dt9o25frWQw0mtQFES7uRaFJt/vOElmpkxVCiDtjtVr57LPPaN68OX/++Sfvvfeeu0MSosiRMoNCSClFl5VdOBl1EpWcOogrLCwMb+/czft6+7zY18veIamTFUKI3Lty5Qq9evXil19+AaBr16589tlnbo5KiKJHemYLoYTkBA5GH0Rr1NJ6amtibsbwzz//3HGvZ7Iy3q6XDfFBZ8j97Zc6WSGEyL1NmzZRr149fvnlFzw9Pfnmm29YuHAhfn5+7g5NiCJHemYLuYj2EXi5sICBUgqVkIA1IeH2PqsVy804LMrTtu/pN3NfLyt1skIIkXvLly/n2WefxWq1cu+99xIREcH999/v7rCEKLIkmS1klFIkJCfk3DCLY091607C7t239wHL3/+Ri/EhwBzb/twmslInK4QQd+aRRx4hNDSUJk2aMH36dHx8fNwdkhBFmiSzhYhSip6/9CTySiQA1iQrD9R9AI1Gw44dO/Dyyr6HViUk2CWyAIb6DW4lsreVreqf6xIDqZMVQgjX7dmzhzp16qDRaPD392f79u0EBgZKZ4AQeUCS2UIkITnBlsgC3F/qfhYdWASkJrquqL51CxpPTxITzPBeaoLbe1RN9CVKoTN65OoHqNTJCiGEa1JSUvjwww8ZM2YMU6dOpX///gCULFnSzZEJcfeQZLaQ2hC+AWOKkUUscuk4BVi1BlK0BpZP3k/UmVjba3ofb/SeubvlUicrhBCuuXDhAt27d+ePP/4AYN++fW6OSIi7kySzhZRJZ0JZXeuNVVbFjgbvEOsbwsbhO+xeK6s/gM7wYK5ikTpZIYRwzbp16+jRoweXL1/G29ubGTNm0KNHD3eHJcRdSZLZu4RSiqWT9hLra18fG1Tei6ctT6HXJKLRvJCrc0udrBBCOCc5OZnRo0czduxYlFLcf//9LF68mBo1arg7NCHuWpLM3iWSzVaizsUDYIq/RPcp7dF6eaFT8Wg+Tcz1eaVOVgghnLdnzx4+/fRTlFL07duXSZMmYTLlcvVGIYRTJJm9CzXcOQ698Sm0eg1MbZHr81yPlzpZIYRwRVhYGOPHj6dcuXJ06dLF3eEIUSxIMluIaTQaKlWqZPs4K0opLEkpt49TCpLi4NumEH0sdWeZOuDi4gsjftordbJCCJENi8XCqFGjeP7556lZsyYAQ4YMcXNUQhQvkswWYl5eXpw8eTLbNkoplo3fxcXjN+xfmFAddLcGkAVWhT6bwIVkdHnkOVbvvYhOq2FK13pSJyuEEBmcPn2arl278ueff/Lzzz+za9cu9Hr5WSlEQcvdzPmiQCilSEjIfjWwZLPVLpH1v3EMrdV8u0GZOjDwH9A6f6vPX0/g/f/bD8CgVtW5v0KAS3ELIcTdbsWKFdSrV48///wTf39/Ro8eLYmsEG4iPbOFlFKKpk2bYjab2bFjR84HAL3u/ZTTX5/B1v869Ch4B7nUI2u1KoYu+ZebicnUCwmgf8uqrgcvhBB3KbPZzLBhw5g8eTIADRs2ZPHixVSuXNm9gQlRjEkyW0jFx8ezbds2AOLi4vD29nbc0Gq1faiP+hcNgakb5Ru6nMgCzNl2km3HrmLSezAxvC46D+m8F0IIgCtXrtCuXTtbB8OQIUP49NNPMRgMbo5MiOJNMpWiTCmY1cbxaz2Xu5zIHrl0k0/XHARgRLuaVCnlc4cBCiHE3aNEiRJ4enpSokQJ/u///o+JEydKIitEISA9s0WZJR4u7b+9PWgP/Ngy9WMXE1lzspUhEZGYk620uKcUPR6SabiEECIpKQmNRoPBYECn0/HDDz+QnJxsm2lGCOF+0jN7NzE4P/VWRl/+foR952II8NLzWaf7ZRouIUSxd/ToURo3bsywYcNs+8qXLy+JrBCFjCSzgp2nrjHtj6MAfNyxDqX9PN0ckRBCuNfixYsJCwtj9+7dLFiwgKioKHeHJITIgiSzxVy8OZk3IyKxKuhYrxzt7i/r7pCEEMJtEhIS6Nu3L127duXmzZs0a9aM3bt3ExQU5O7QhBBZkJrZQizHH55K3fE1Pl51gJNX4ynr78kHT9W+4/MJIURRdfDgQcLDw9m7dy8ajYYRI0YwevRodDr5VSlEYSbfoYWUt7c3V65cybqBUjD78Tu6xh+HLvP936cB+LxzXfxNMuG3EKJ4SkpKonXr1pw7d47g4GAWLFjAY4895u6whBBOuKMyg8TExLyKQ7hCKYiLgot7UeRuoFZ0nJm3l+4BoHeTUJpUk0doQojiy2g0MmnSJB555BEiIyMlkRWiCHE5mbVarXz44YeUL18eHx8fjh8/DsDIkSP57rvv8jxAkYFSMKstfF4NpTREXJ2Qi1Mo3lu+lys3k6gW7MOwx2vkQ6BCCFG47d+/n02bNtm2O3fuzPr16ylbVsYOCFGUuJzMfvTRR8yZM4fPPvvMbrLo2rVr8+233+ZpcMVZQkICLVu2pGXLliQkJNx+wRKPOv03Zqsn30dN5UZKOQCCQnzQ6Z3rpV0eeY7Vey+i02qY3KUennqP/PgUhBCiUFJKMXv2bBo2bEinTp24cOGC7TWZllCIosflmtl58+bxzTff0KpVK1599VXb/rp163Lw4ME8Da44s1qtbNy40fZxGqUUy6LHctFS07bPP9hE53ce4GSnTjme99z1BN7/v9SFFga3qk7t8v55HLkQQhResbGx9O/fn/nz5wPQtGlTPDzkD3ohijKXe2bPnTtHtWrVMu23Wq1YLJY8CUpkLTkpxS6RDQrxofvoRpCUSNKBAwAYa9ZEYzJlOtZqVQyN+JebicnUrxhAv5ZVCyxuIYRwtz179vDAAw8wf/58tFotH3/8MWvWrCE4ONjdoQkh7oDLPbO1atVi8+bNmVZAWbp0KfXr18+zwIQDSsH8jsBIAHp/HIYp0B+NRkP6SbpCF8x3+Khs9raT/Hn8Kia9B5PC66HzkGmGhRB3P6UUM2fOZPDgwSQmJlK+fHl++OEHmjVr5u7QhBB5wOVk9v3336dXr16cO3cOq9XKsmXLOHToEPPmzWPlypX5EaNIY4mHS/ttm3pvH8f1XQ72Hbl0k3FrUstA3m1Xk9Ag73wLUwghChONRsPWrVtJTEzkiSeeYN68ebIIghB3EZe75p566il+/vlnfvvtN7y9vXn//fc5cOAAP//8s0xlUtCcHKhgTrby+uJIzMlWWt5biu4PVcznwIQQwv1UuoVlpk2bxowZM1i5cqUkskLcZXK1aEKzZs1Yt25dXsci8skX64+w/3wMAV56Pnv2fhmtK4S4qymlmD59Or///jtLlixBq9Xi4+ND37593R2aECIfuNwzW6VKFa5evZpp//Xr16lSpUqeBCVSeXl54eXldUfn2HnqGtM3HAVg7NN1CPbzzIvQhBCiULp+/Trh4eEMHDiQZcuW8dNPP7k7JCFEPnO5Z/bkyZOkpKRk2p+UlMS5c+fyJCiRupxtXFzcHZ0jLimZNyMisSp4un55nqwjE4ELIe5eO3bsoEuXLpw4cQK9Xs9nn33GM8884+6whBD5zOlkdsWKFbaPf/31V/z9b89PmpKSwvr16wkNDc3T4MSd+Xj1AU5ejaecvyej/3efu8MRQoh8oZRiypQpvP3221gsFkJDQ4mIiKBhw4buDk0IUQCcTmY7duwIpI4K7dWrl91rer2e0NBQJkxwfWlVkUopRa81vXJu6KQ/Dl5m4d+nAfi8c138Tfo8O7cQQhQmgwYNYurUqQA888wzfPfddwQEBLg3KCFEgXG6ZtZqtWK1WqlYsSKXL1+2bVutVpKSkjh06BDt27fPz1jvagnJCRyMTp06q0ZgDTTJGtq1a0e7du1ITEx06VzX4s28/eMeAF5sUpmHq8nIXSHE3atnz574+PgwdepUli5dKomsEMWMyzWzJ06cyI84RDpzH5+L1Wxl9erVAA5rlLMzesV+rtxMonqwD28/fm9+hCiEEG5jtVrZs2cP9erVA6Bhw4acOnWKwMBA9wYmhHCLXC0BFRcXx+rVq5kxYwZffPGF3T9XTZs2jdDQUDw9PXnooYfYvn17tu2vX7/OgAEDKFu2LEajkXvuuceW9BUHipyn1Vr73yV0Wg2TutTDUy9rjgsh7h5RUVF06NCBRo0aERkZadsviawQxZfLPbO7d+/mySefJD4+nri4OAIDA4mKisLLy4vg4GAGDRrk9LkWL17MG2+8wYwZM3jooYeYPHkybdu25dChQw7XyjabzTz22GMEBwezdOlSypcvz6lTp4rNIyWlFD9Ff+xU29dbV6d2ef+cGwohRBGxf/9+BgwYwLlz5zAajRw6dMjWOyuEKL5c7pkdMmQIHTp04Nq1a5hMJv766y9OnTpFgwYN+Pzzz10618SJE3nllVfo3bs3tWrVYsaMGXh5eTFr1iyH7WfNmkV0dDTLly+nSZMmhIaG0qJFC+rWrevqp1GkKKWwJKWQEJtMVHLqXL5B5b3QGW7fPqv19ko39UICeLVF1QKPUwgh8oPVauXTTz9l5MiRnDt3jnvuuYft27fTpUsXd4cmhCgEXO6ZjYyM5Ouvv0ar1eLh4UFSUhJVqlThs88+o1evXk7P6Wc2m9m5cyfDhw+37dNqtbRu3Zo///zT4TErVqygcePGDBgwgP/7v/+jVKlSdOvWjWHDhuHh4fhxelJSEklJSbbtmJgYACwWCxaLxdlPO9fSrpHTtZKTk+0+tlqstu3lk3Zz45z98R0GVLc75rf9Fwi99fFH/6uFsqZgsbpWayscc/YeisJL7mHRdfnyZXr37m1bdbJr165Mnz4dHx8fuZ9FiHwPFn0FfQ9duY7Lyaxer0erTe0RDA4O5vTp09SsWRN/f3/OnDnj9HmioqJISUmhdOnSdvtLly7NwYMHHR5z/Phxfv/9d7p3787q1as5evQo/fv3x2KxMGrUKIfHfPLJJ3zwwQeZ9q9du/aOV9dyRU7L/5qV2fbxr7/+ijXpdjJ7+WQMRr3Jtl1Wf4D1f0Rh1Rlt+1YfTeb1Wx8f+Gcz/+0x5Enc4jZZwrnok3tY9Pzf//0f69atw2Aw0LdvXx599FE2bdrk7rBELsn3YNFXUPcwPj7e6bYuJ7P169dnx44dVK9enRYtWvD+++8TFRXF/PnzqV27tqunc4nVaiU4OJhvvvkGDw8PGjRowLlz5xg/fnyWyezw4cN54403bNsxMTGEhITQpk0b/Pz88jVeSP3LYt26dTz22GPo9VnP9ZqQnMCYiDEAtG3b1i6ZTfP86NqYptdGp0ki+fFTYPC2vbZs5lbbx23btEFbgIn63c7ZeygKL7mHRdfjjz+O0WjkpZde4ty5c3IPiyj5Hiz6Cvoepj1Jd4bLyezYsWO5efMmAB9//DE9e/akX79+VK9ene+++87p8wQFBeHh4cGlS5fs9l+6dIkyZco4PKZs2bLo9Xq7koKaNWty8eJFzGYzBkPm3kij0YjRaMy0X6/XF+g3VE7Xs3C7O12n0+Fl8rLVyn4zeCMAph+7oNcm2c7HrfMppTh08abdtbTywyLPFfTXjMh7cg8LvwsXLjBmzBgmTpyIyZT6ROqrr77CYrFw7tw5uYdFnNy/oq+g7qEr13A5mX3ggQdsHwcHB7NmzRpXTwGAwWCgQYMGrF+/3ra6mNVqZf369QwcONDhMU2aNGHhwoVYrVZbqcPhw4cpW7asw0T2rnNpf+qQvTJ1QH+75/XCjUSuxUsdkhCiaFu3bh09evTg8uXL6HQ6vvzyS3eHJIQoAnI1z6wju3btcnkFsDfeeIOZM2cyd+5cDhw4QL9+/YiLi6N3795A6qou6QeI9evXj+joaAYPHszhw4dZtWoVY8eOZcCAAXn1aRQKiYmJdO7cmc6dO5OYkJC5Qe81oLk93+z+czfwTDFnbieEEEVAcnIy7733Hm3btuXy5cvUqVPnrvu5LoTIPy71zP7666+2QvyXX36ZKlWqcPDgQd555x1+/vln2rZt69LFu3TpwpUrV3j//fe5ePEi9erVY82aNbZBYadPn7b1wAKEhITw66+/MmTIEO6//37Kly/P4MGDGTZsmEvXLexSUlJYunQpAN98McX+xZBGdrWySim83+rHouOOB80JIURhdu7cOZ577jk2b94MQJ8+fZg8ebKtxEAIIXLidDL73Xff8corrxAYGMi1a9f49ttvmThxIq+99hpdunRh37591KxZ0+UABg4cmGVZwYYNGzLta9y4MX/99ZfL1ymqVnz8C1A5dWPwXggMtuuVVQkJlEiXyJrCwtDILwEhRBGwdetWOnbsSFRUFD4+PsycOZOuXbu6OywhRBHjdJnBlClTGDduHFFRUURERBAVFcX06dPZu3cvM2bMyFUiK3J2NSF1MFyQ6QK6EqXsEtmMYhb+TKXvF6DJpo0QQhQWFStWxGq1Ur9+fXbt2iWJrBAiV5zumT127BidO3cG4JlnnkGn0zF+/HgqVKiQb8EVF0opeq3plW2bpz9oj0ab+W+Pa/G3a2XvrVxKElkhRKF248YN/P1Tl9oOCQnh999/595778XT09PNkQkhiiqne2YTEhJsiwxoNBqMRiNly5bNt8CKk4TkBA5Gp5YK1AisgadH5h/qWSWpB9NNyeVnlOlOhBCF188//0yVKlVYsWKFbV/dunUlkRVC3BGXBoB9++23+Pj4AKmjT+fMmUNQUJBdm0GDBuVddMXQ3MfnEnst1un2By7E0CQf4xFCiDtlNpsZPnw4EydOBGD69On873//c3NUQoi7hdPJbMWKFZk5c6Ztu0yZMsyfP9+ujUajkWQ2D3h7p85W8HCjRhh02fdY/HdeklkhROF14sQJunbtyvbt2wF4/fXXGTdunJujEkLcTZxOZk+ePJmPYRRfSikSku3nkvXy8iI2NhZ9SjIz396Z7fEHLji/3JsQQhSkZcuW8eKLL3Ljxg0CAgKYM2cOTz31lLvDEkLcZVxeAUzkHaUUPX/pSeSVSACsFit9XuqDTqvj66+/RmNNyfb4eHMyJ67GFUCkQgjhmt27d/Pss88C0KhRIxYtWkSlSpXcHJUQ4m4kyawbJSQn2BJZgPtL3s/3878HYNq0aeS0QO+BCzdRKv/iE0KI3Kpfvz79+vXDx8eHjz/+uEDWchdCFE+SzBYSG8I3YEwxsohFTh/z3/kb+RiREEK4ZunSpTRt2pQyZVLnx542bZpMFyiEyHdOT80l8pdJZ3L5h/7+81IvK4Rwv4SEBF599VU6d+5M9+7dSUlJLZGSRFYIURCkZ7YIk2RWCOFuhw4dIjw8nD179qDRaGjUqBFK6p+EEAUoVz2zx44d47333uO5557j8uXLAPzyyy/s378/T4MTWbOkWDmUbsEEIYQoaN9//z0NGjRgz549lCpVijVr1vDxxx+j00k/iRCi4LiczG7cuJE6derw999/s2zZMmJjUyf4//fffxk1alSeB1isZdO7cfRyLOYUK75G+aUhhChY8fHxvPzyy/To0YO4uDhatmxJZGQkbdq0cXdoQohiyOVk9p133uGjjz5i3bp1GAy3x9s/+uij/PXXX3kaXLFmtcKstlm+nFZicG9Zv4KKSAghALBarWzduhWNRsOoUaP47bffKFeunLvDEkIUUy536+3du5eFCxdm2h8cHExUVFSeBFVceXl5pZZtKIXXgsdJjj5++0W9l13b/bdmMqhZ1rcgQxRCFGNKKTQaDT4+PkRERHD58mVatWrl7rCEEMWcyz2zAQEBXLhwIdP+3bt3U758+TwJqrjSaDSUKlWKUgHeaC7ty/ii3WZaz2zNMtIzK4TIX7GxsfTq1YtJkybZ9tWpU0cSWSFEoeByMtu1a1eGDRvGxYsX0Wg0tsdNQ4cOpWfPnvkRo8jAalUcuJXM1pIyAyFEPtq7dy8NGzZk3rx5vPvuu1y6dMndIQkhhB2Xk9mxY8dSo0YNQkJCiI2NpVatWjRv3pyHH36Y9957Lz9iLDaSkpIYMGAAAwYNISk568FfZ67FczMpGYNOS5VS3gUYoRCiuFBKMXPmTB588EEOHjxIuXLl+PXXXyldurS7QxNCCDsu18waDAZmzpzJyJEj2bdvH7GxsdSvX5/q1avnR3zFSnJyMtOnTwfgs+G+GLL4U2PfuVuDv4J98DAnFVR4QohiIiYmhr59+7JoUeqKhI8//jjz5s2jVKlSbo5MCCEyczmZ3bJlC02bNqVixYpUrFgxP2ISOdh//gYoxdCVn3Nk+mF3hyOEuItYLBYaN27Mf//9h4eHB2PHjmXo0KFotbJgpBCicHL5p9Ojjz5K5cqVGTFiBP/9919+xCRycORyLMYUM8GnbyeyprAwNCaTG6MSQtwN9Ho9L730EiEhIWzatIm3335bElkhRKHm8k+o8+fP8+abb7Jx40Zq165NvXr1GD9+PGfPns2P+Io1heN1zU9ExdltV9+6hUrfL5B10IUQuXLjxg2OHDli2x4yZAh79+7l4YcfdmNUQgjhHJeT2aCgIAYOHMjWrVs5duwYnTt3Zu7cuYSGhvLoo4/mR4zFklLwU/THmfanWBWnrtons1qTSRJZIUSu/PPPP9SvX5/27dtz82bqEtkajQZ/f383RyaEEM65o2dHlStX5p133uHTTz+lTp06bNy4Ma/iKvYsypOo5CoABIX4oLs1GuzctQQsKQqDTh77CSFyTynFlClTePjhhzlx4gRms5lz5865OywhhHBZrjOirVu30r9/f8qWLUu3bt2oXbs2q1atysvYirUV10bZPn76zTBbz+vxqFgAQgNlSi4hRO5cu3aNZ555htdffx2LxcLTTz/N7t27qVGjhrtDE0IIl7k8m8Hw4cNZtGgR58+f57HHHmPKlCk89dRTeHl55XywyJbJZOLEiRNYYm+y5stLaIGg8l7ojR62NsevpJYYVCop77cQwnV//fUXXbt25dSpUxgMBiZMmMCAAQOkVEkIUWS5nMxu2rSJt956i/DwcIKCgvIjpmJLq9USGhqK5WYMWs0VAJ5+vZbdL5m0wV+hQdIzK4Rw3ZgxYzh16hRVq1Zl8eLFNGjQwN0hCSHEHXE5md26dWt+xCGykLGvJC2ZlZ5ZIURuzJo1iw8++IBx48bh5yfLYQshij6nktkVK1bwxBNPoNfrWbFiRbZt//e//+VJYMWR2Wzm3XffxWpOomJKO3Qe+kxt0pJZWcZWCOGMLVu2sHbtWsaMGQNAmTJl+Oqrr9wclRBC5B2nktmOHTty8eJFgoOD6dixY5btNBoNKSkpeRVbsWOxWPj8888BmPBi20zJbKIlhXPXEwAILenN5QKPUAhRVFitVsaNG8fIkSNJSUkhLCws25/fQghRVDmVzFqtVocfi4KV1ivrb9ITYNJLMiuEcOjy5cs8//zzrF27FoAePXrQunVrN0clhBD5w+WpuebNm0dSUlKm/WazmXnz5uVJUMVWDn8opCWzlUt6oRITCyIiIUQRs2HDBurVq8fatWsxmUx89913zJs3Dx8fH3eHJoQQ+cLlZLZ3797cuHEj0/6bN2/Su3fvPAmqWFIKZrXJvF9/e6DXiag4UIrB/zeeI02aFmBwQoiiYNKkSbRq1YoLFy5Qs2ZNduzYwYsvvijTbgkh7mouJ7NKKYc/GM+ePSvLH96J5AS4tD/z/nTv9fErcRhTzJQ5c9i2zxQWhsZkKogIhRCFXLVq1bBarbzwwgvs2LGD++67z90hCSFEvnN6aq769euj0WjQaDS0atUKne72oSkpKZw4cYLHH388X4Is7pRSqIQEzl64imeK2ba/+tYteAQGSq+LEMXY9evXCQgIAKBDhw7s2LGDBx54wL1BCSFEAXI6mU0bBRsZGUnbtm3t6q8MBgOhoaE8++yzeR5gcaKUo32KU926k7B7N6MzvKY1mSSRFaKYSk5O5oMPPmDGjBns3LmTihUrAkgiK4QodpxOZkeNGgVAaGgoXbp0wdPTM9+CKq70OiPvdp5s+7hsVX88UpJI2L07U1spLxCi+Dp37hzdunVj06ZNACxdupQ33njDzVEJIYR7uLwCWK9evfIjDgFoNRrKBoYC0Puzpph89aiEBNvrXZ8YRUAJP/4Y2hKN9MoKUSytWbOG559/nqioKHx8fJg5cyZdu3Z1d1hCCOE2TiWzgYGBHD58mKCgIEqUKJFtEhUdHZ1nwRVneqMHGo0Gla72INHDQPmygWi9ZClbIYobi8XC+++/z6effgpAvXr1iIiIoHr16m6OTAgh3MupZHbSpEn4+vraPpYewfxhTlGs+mcuAC+YG6MzeHKyx/N2bSoHyTK2QhRHU6ZMsSWyAwYM4PPPP5dyLyGEwMlkNn1pwQsvvJBfsRR75hT4ZWfqwhMWy5eoBEXSgQMAXCldiSQPA1VKycTnQhRHAwYMYMWKFQwaNIhOnTq5OxwhhCg0XJ5ndteuXezdu9e2/X//93907NiRESNGYDabszlSZEcpxSNzrmf5+uft3wCNhirSMytEsWA2m5kxYwYpKSkAmEwmNm7cKImsEEJk4HIy27dvXw4fTp20//jx43Tp0gUvLy+WLFnC22+/necBFhfx8fH8eykZgAolq+GVoS725NV4QMoMhCgOTp48SbNmzejXrx9jx4617ZcSLyGEyMzlZPbw4cPUq1cPgCVLltCiRQsWLlzInDlz+PHHH/M6vmJpyFOTM/3SSkq2otNqqFBCpuMS4m72008/Ub9+fbZv305AQAD333+/u0MSQohCLVfL2VqtVgB+++03nnzySQBCQkKIiorK2+iEnYolvdB5uHzLhBBFQFJSEoMGDeKZZ57h+vXrNGrUiMjISJ566il3hyaEEIWay5nRAw88wEcffcT8+fPZuHEj7dq1A+DEiROULl06zwMUt1UJksFfQtyNjh07RpMmTfjyyy8BGDp0KJs2baJSpUpujkwIIQo/lxdNmDx5Mt27d2f58uW8++67VKtWDUhdgebhhx/O8wCLC09PT7a9FMBP0R+j9zA4bFM1WOplhbgbxcbGsm/fPgIDA5k3b56tk0AIIUTOXE5m77//frvZDNKMHz8eDw+PPAmqONJqtdxfWscuXY0s27SoXqoAIxJC5CellK02vm7duixevJiwsDBCQkLcHJkQQhQtLiezaXbu3MmBW3Og1qpVi7CwsDwLqrhRStG6dTue8k7At5rjNv4mPQ0rBxZsYEKIfHH48GF69OjB1KlTefDBBwGkNlYIIXLJ5WT28uXLdOnShY0bNxIQEADA9evXeeSRR1i0aBGlSknvoSuUUqTcTOGvv3Zw1EvD8EoJGPWZZyxoeU8p9DL4S4gib+HChfTt25fY2Fhee+01/vrrL5lySwgh7oDL2dFrr71GbGws+/fvJzo6mujoaPbt20dMTAyDBg3KjxjvWkopTnx8goODDgIQFa/sX781awRAq5oyuE6Ioiw+Pp6XX36Z7t27ExsbS8uWLVm+fLkkskIIcYdc7plds2YNv/32GzVr1rTtq1WrFtOmTaNNmzZ5GtzdLj4+nvij8bbth0N0GHSpa60rq5XDHZ+xvdakWskCj08IkTcOHDhAeHg4+/btQ6PR8P777zNy5EgZZyCEEHnA5WTWarWi1+sz7dfr9bb5Z4XrTgz1pZynkZlXUntpTnbrDmfPAHC5dCVq+Pu6MzwhRC7t37+fBx98kPj4eEqXLs3ChQt59NFH3R2WEELcNVwuM3j00UcZPHgw58+ft+07d+4cQ4YMoVWrVnkaXHHibdDYPW40HzoEwFnvIC6N/1oeRQpRRNWqVYtHH32UVq1aERkZKYmsEELkMZd7ZqdOncr//vc/QkNDbVPInDlzhtq1a7NgwYI8D/Bu5unpSeiw0NSPddGgMrcZ/OgQNtcqU7CBCSHuyP79+6lUqRI+Pj5oNBp++OEHTCaTlBUIIUQ+cDmZDQkJYdeuXaxfv942NVfNmjVp3bp1ngd3t/Pw8MCnZuqqXh4nr0FK5jb1KwVS0sdYwJEJIXJDKcV3333Ha6+9RqdOnZg3bx4ajQYfH1m9Twgh8otLyezixYtZsWIFZrOZVq1a8dprr+VXXOKWVjWC3R2CEMIJN2/e5NVXX2XhwoUAREVFkZSUhKenp5sjE0KIu5vTyexXX33FgAEDqF69OiaTiWXLlnHs2DHGjx+fn/Hd1SwWC1d/u5r6cWXl8Ga0lim5hCj0IiMjCQ8P58iRI3h4eDB27FiGDh2KVitzQwshRH5z+ift1KlTGTVqFIcOHSIyMpK5c+cyffr0/Iztrmc2m7mw4AIXFlzAnAIqxX6Q1/EyVQkpJ6t+CVFYKaX46quvaNSoEUeOHCEkJIRNmzbx9ttvSyIrhBAFxOmftsePH6dXr1627W7dupGcnMyFCxfyJbBiKd0AsF5thnN4xASZxUCIQuzatWuMHj2apKQkOnTowO7du3n44YfdHZYQQhQrTpcZJCUl4e3tbdvWarUYDAYSEhLyJbDiRik4taEk3J+6nehhoE1tmcVAiMIsMDCQ77//nr179/L666/LH59CCOEGLg0AGzlyJF5eXrZts9nMxx9/jL+/v23fxIkT8y66YkSlaDBfv70YRclAf2qV9XNjREKIjJRSfPnll5QrV45OnToB0Lp1a5nNRQgh3MjpZLZ58+YcujWRf5qHH36Y48eP27alVyLvtKpVWt5PIQqRa9eu8eKLL7J8+XJ8fX1p3Lgx5cuXd3dYQghR7DmdzG7YsCEfwxAZyZRcQhQef//9N126dOHUqVMYDAbGjh1LuXLl3B2WEEIIcrGcrSgYDSqVcHcIQhR7VquVCRMm0LRpU06dOkXVqlXZtm0bAwcOlCcnQghRSLi8ApjIO0ajkUqvV0r92OO63Ws6D/k7Qwh3Sk5O5plnnuHnn38GIDw8nJkzZ+LnJ7XsQghRmEgy60Y6nQ7fer6gFFEz5FYIUZjodDqqVauG0WhkypQp9OnTR3pjhRCiEJLuv0LAaAFLupkMhBDuYbVauX79um37008/ZdeuXfTt21cSWSGEKKSkO9CN0pazNeg0WJSv/GUhhBtduXKFnj17cvPmTf744w/0ej0Gg4FatWq5OzQhhBDZyFX+tHnzZnr06EHjxo05d+4cAPPnz2fLli15GtzdTClF84ebc2HBBU7NOY9FqZwPEkLki40bN1KvXj3WrFnDrl272L17t7tDEkII4SSXk9kff/yRtm3bYjKZ2L17N0lJSQDcuHGDsWPH5nmAd6v4+Hj2/LsHAFOIJyZ5hClEgUtJSeHDDz/k0Ucf5fz589SsWZPt27fz4IMPujs0IYQQTnI5mf3oo4+YMWMGM2fORK+/XefZpEkTdu3alafBFRf3vhWKRqNBSUIrRIG5ePEibdu25f3338dqtfLCCy+wY8cOateu7e7QhBBCuMDlmtlDhw7RvHnzTPv9/f3tBk6IHKQvK9BoUCh21RvivniEKGZ69uzJ+vXr8fLy4quvvqJnz57uDkkIIUQuuNwzW6ZMGY4ePZpp/5YtW6hSpUqugpg2bRqhoaF4enry0EMPsX37dqeOW7RoERqNho4dO+bqum5libfbtGoNxPqGABAU4oPOIMPBhMhPX3zxBY0bN2bnzp2SyAohRBHmcsb0yiuvMHjwYP7++280Gg3nz5/n+++/Z+jQofTr18/lABYvXswbb7zBqFGj2LVrF3Xr1qVt27Zcvnw52+NOnjzJ0KFDadasmcvXLBQyDPhKX2Lw9JthMg2QEHksOjqaH374wbZdo0YNtm7dSo0aNdwYlRBCiDvlcpnBO++8g9VqpVWrVsTHx9O8eXOMRiNDhw7ltddeczmAiRMn8sorr9C7d28AZsyYwapVq5g1axbvvPOOw2NSUlLo3r07H3zwAZs3by565Q1KYfzhGeZ39mJEqZJoPTR2JQaSyAqRt9auXcvrr79ObGwsoaGhtlIp+V4TQoiiz+VkVqPR8O677/LWW29x9OhRYmNjqVWrFj4+Pi5f3Gw2s3PnToYPH27bp9Vqad26NX/++WeWx40ZM4bg4GBeeuklNm/enO01kpKSbDMuAMTExACpc7xaLBaXY3ZV2jXsrmWOQ39lH8/cp2dcqD/6BL2txKBkORNKk4LFYs332IRzHN5DUSQkJyczatQoxo8fD8D9999PyZIl5V4WQfJ9WLTJ/Sv6CvoeunKdXC+akBeTiUdFRZGSkkLp0qXt9pcuXZqDBw86PGbLli189913REZGOnWNTz75hA8++CDT/rVr1+Ll5eVyzLm1bt0628ceKUm0z6KdZ/Wz/PJL9iUWwj3S30NR+F25coWJEydy4MABAJ544gl69+7N0aNHHdb9i6JBvg+LNrl/RV9B3cP4+PicG93icjL7yCOPZPto7vfff3f1lE67efMmzz//PDNnziQoKMipY4YPH84bb7xh246JiSEkJIQ2bdrg5+eXX6HaWCwW1q1bx2OPPXZ7KjNzHMmRimUHk7lx+QZetUra2rdu3QpjgG++xyWc5/AeikJt9erVDBs2jOjoaPz8/Jg2bRq+vr5yD4sw+T4s2uT+FX0FfQ/TnqQ7w+Vktl69enbbFouFyMhI9u3bR69evVw6V1BQEB4eHly6dMlu/6VLlyhTpkym9seOHePkyZN06NDBts9qTX0cr9PpOHToEFWrVrU7xmg0YjQaM51Lr9cX6DeU3fWUnrhkeH5JPBBP6cklbrfTFWxcwnkF/TUjcu/8+fNER0fToEEDFi9eTMWKFVm9erXcw7uA3MOiTe5f0VdQ99CVa7iczE6aNMnh/tGjRxMbG+vSuQwGAw0aNGD9+vW26bWsVivr169n4MCBmdrXqFGDvXv32u177733uHnzJlOmTCEkJMSl6wsh7h5KKdtTo1dffRWTycRzzz2H0WiUOj0hhLiL5dlkpj169GDWrFkuH/fGG28wc+ZM5s6dy4EDB+jXrx9xcXG22Q169uxpGyDm6elJ7dq17f4FBATg6+tL7dq1MRgMefXpCCGKkOXLl/PAAw/YZjbRaDS88MILDp/KCCGEuLvkegBYRn/++Seenp4uH9elSxeuXLnC+++/z8WLF6lXrx5r1qyxDQo7ffo0Wq0sICCEyCwpKYlhw4YxZcoUACZMmMCHH37o5qiEEEIUJJeT2WeeecZuWynFhQsX+Oeffxg5cmSughg4cKDDsgKADRs2ZHvsnDlzcnVNIUTRduzYMbp06cLOnTsBGDp0KO+//76boxJCCFHQXE5m/f397ba1Wi333nsvY8aMoU2bNnkWmBBCZGXJkiW8/PLLxMTEULJkSebOnUu7du3cHZYQQgg3cCmZTUlJoXfv3tSpU4cSJUrkfIAQQuSxb775hr59+wLQpMn/s3ffcU1d7x/AP0lIIGxBZMhUBNwoiqt1VBQ3WOseoKhVceKeOOpeuLWKOOqus9a6UFtEXAguEBeOKqBV2YGs8/uDH/drZMhMRJ/365WX5txz733uPSF5cnPOuS2wf/9+WFtbazgqQgghmlKszqgCgQDt27eveLeP/ZIwBkgzIRIAm73EqOpXFTwt6hNMSFH9+OOPsLGxwfTp03Hp0iVKZAkh5BtX7G4GderUwdOnT+Hg4FAe8XzdGAO2ewIvr0Eo4GFgAxHW21cCX0L3hyekMBEREWjWrBmAnPmp79+/DwMDurkIIYSQEkzN9csvv2DSpEk4efIkEhISkJqaqvIghZBlAi+vcU/fGtUHGKClpCnFCMmPRCLBsGHD0Lx5c5XBnpTIEkIIyVXkK7Pz58/HxIkT0alTJwBAt27dVG5rmzthuUKhKPsov0Ly8Q+weMMR1P4nDs0rdy3DGX8J+TrExsaiV69euHfvHng8HhISEjQdEiGEkC9QkZPZefPmYcSIEbh48WJ5xvPNyGYCbJmVMx2Z+xBPCPhiGKU8gZaoiYYjI0Tzdu3ahZEjRyIzMxPm5ubYs2cP2rZtq+mwCCGEfIGKnMwyxgAArVq1KrdgvmXfhU+FUJYOHq+/pkMhRGMyMjIwevRorkuBh4cHfvvtN+4mKoQQQsinivXj9sfdCkjZEiikoLNLvnU3b97Ezp07wefzsWDBApW7ARJCCCH5KdZsBk5OTp9NaN+/f1+qgAgh365WrVphxYoVcHNzo1+BCCGEFEmxktl58+bluQMYIYSUVFpaGiZNmoQpU6agevXqAICAgAANR0UIIaQiKVYy26dPH1SpUqW8YiGEfENu376NXr164eHDh7hz5w6uXLlCXZkIIYQUW5H7zNKHDCGkLDDGsHnzZjRp0gQPHz6EtbU1VqxYQe8xhBBCSqTYsxmQsiESiVCtywi4fRBCiy/UdDiEqEVKSgqGDx+OgwcPAgC6dOmCHTt2wNTUVMOREUIIqaiKnMwqlcryjOObIxQKYVavLVq9M+HKxA0bgicWazAqQspPfHw82rVrhydPnkBLSwtLly7FhAkT6IosIYSQUilWn1lSdpRKhgzp/+6WZnX6D1SysaEPdvLVqlq1KipVqgQ7OzscOHAATZrQDUIIIYSUHiWzGpIqyYbbw+d4yF7B0aIueGIdSmTJVyc5ORn6+vrQ0tKCSCTCkSNHoK+vj0qVKmk6NEIIIV+JYt00gZSdt+9TsfPEVKz9YyK0U+KhJaSmIF+X69evo0GDBggMDOTKbGxsKJElhBBSpiiDUqePBtGlZ/3v//XvrKOrsuSrwRjDqlWr0KJFCzx79gwHDx5ERkaGpsMihBDylaJkVl0YA0I6cE8zs2Tc/3k0UQT5Srx//x5eXl6YOHEi5HI5evbsiZs3b0JPT0/ToRFCCPlKUTKrLrJMIPFuzv8t6uKdTKGyWKylo4GgCCk7V65cgaurK/744w9oa2tj06ZNOHDgAN01kBBCSLmiAWCaMPg0Mq/HqxRRNwNSkaWkpKBTp05ISUlBjRo1cPDgQbi6umo6LEIIId8ASmY1gcdTmZaLkIrOyMgIa9aswdmzZ7F582YYGBhoOiRCCCHfCEpmNSQzW/b5SoR8wf755x9oaWmhefPmAAAfHx8MGjSIfmX4BigUCshk6n0Pk8lk0NLSQlZWFhQKuhhQ0VD7VXzl0YYikQh8ful7vFIyqyFZCj68mwwHAAhTrmg4GkKKTqFQYPHixQgMDISlpSWio6NRuXJlANRd5mvHGENiYiKSk5M1sm8LCwu8fPmSXmcVELVfxVcebcjn8+Hg4ACRSFSq7VAyqyHZjA8P194AAOE/VzUcDSFFk5SUhAEDBuD8+fMAAA8PD4jpFszfjNxEtkqVKtDV1VVrUqJUKpGeng59ff0yuZJD1Ivar+Ir6zZUKpV4/fo1EhISYGtrW6r3E0pmNSQjWwaaOp5UJBcuXEC/fv2QlJQEXV1dbNy4ET4+PpoOi6iJQqHgEllTU1O171+pVEIqlUJHR4eSoQqI2q/iK482NDMzw+vXryGXyyEUCku8HUpmNSRNIsXzNw8AAApGE82SL5dSqcS8efOwYMECMMZQp04dHDx4EDVr1tR0aESNcvvI6urqajgSQsjXIrd7gUKhoGS2IkpNz8CGo/4AgJ+c62g4GkIKxuPxEBMTA8YYhg4dijVr1lBC8w2j/o6EkLJSVu8nlMxqiCwzi/u/Vo3q4FG/Q/KFUSqV4PP54PF42LZtG3r37o2ffvpJ02ERQgghKqjjioZkSOXc/6usW01XO8gXQy6XY/r06ejTpw/Y/3eBMTIyokSWEELIF4mSWQ3JzJJ/vhIhavby5Uu0bt0aS5YswaFDh/DPP/9oOiRCKjwej4djx45pOowvXnBwMNq3b6/pML4aUqkU9vb2uHnzpqZDKXeUzGoAYwzNkqhbAfmy/Pnnn3B1dUV4eDgMDQ1x8OBBtGrVStNhEVJqvr6+4PF44PF4EAqFcHBwwJQpU5CVlfX5lSuQ3GP8+PHdd99pPKaiJPJZWVmYPXs2AgMD8yz7999/IRKJUKdO3vElz549A4/HQ3R0dJ5lrVu3xvjx41XKoqKi0LNnT5ibm0NHRwc1atTAsGHD8PDhw6IeUrExxjBnzhxYWlpCLBbDw8MDjx49KnQdhUKB2bNnw8HBAWKxGNWrV+cG4eZKSkqCr68vrKysoKuriw4dOqhsVyQSYdKkSZg6dWq5HduXgpJZDZBLlagkF3DPtYTUDERzZDIZJk+ejC5duuD9+/dwc3PDrVu30LNnT02HRkiZ6dChAxISEvD06VOsXr0aW7ZsyTdxquhCQkKQkJDAPU6cOFHibanzLm+///47DA0N0aJFizzLduzYgV69eiE1NRXXrl0r8T5OnjyJpk2bIjs7G3v27EFsbCx+++03GBkZYfbs2aUJv1DLli3D2rVrsXnzZly7dg16enrw9PQs9MvU0qVLsWnTJqxfvx6xsbFYunQpli1bhnXr1gHISZC9vb3x9OlTHD9+HFFRUbCzs4OHhwcyMjK47fTv3x+XL1/G/fv3y+34vgSURWmATKFUeU79ZYkm9e3bFytWrAAAjB07FuHh4ahevbqGoyIVAWMMmVK52h4SqYL7PyvmlIba2tqwsLCAjY0NvL294eHhgXPnznHL3717h759+6Jq1arQ1dVF3bp1sW/fPpVttG7dGmPHjsWUKVNgYmICCwsLzJ07V6XOo0eP0LJlS+jo6KBWrVoq+8h19+5d/PDDDxCLxTA1NcXw4cORnp7OLff19YW3tzcWLVoEc3NzGBsbY/78+ZDL5Zg8eTJMTExgbW2NkJCQPNs2NjaGhYUF9zAxMQGQM6Bz/vz5sLa2hra2NlxdXXH69GluvdwrnAcOHECrVq2go6ODPXv2AAC2bduGmjVrQkdHBy4uLti4cSO3nlQqxejRo2FpaQkdHR3Y2dlh8eLFAAB7e3sAQPfu3SEQCFCvXr0C22f//v3o2rVrnnLGGEJCQjBw4ED069cPwcHBBW6jMJmZmRg8eDA6deqEEydOwMPDAw4ODmjSpAlWrFiBLVu2lGi7n8MYQ1BQEGbNmgUvLy/Uq1cPu3btwuvXrwu9Yn3lyhV4eXmhc+fOsLe3x08//YT27dvj+vXrAHJeZ1evXsWmTZvQuHFjODs7Y9OmTZBIJCqv20qVKqFFixbYv39/uRzfl4JmM9CATKkcAr4WOroNgv3z06WaW42Q0ho3bhz+/vtvbN26Fd7e3poOh1QgEpkCteac0ci+Y+Z7QldUso+we/fu4cqVK7Czs+PKsrKy4ObmhqlTp8LQ0BB//vknBg4ciOrVq8Pd3Z2rt3PnTgQEBODatWuIiIiAr68vWrRogXbt2kGpVOLHH3+Eubk5rl27hpSUlDw/c2dkZMDT0xPNmjXDjRs38ObNGwwdOhSjR4/Gjh07uHoXLlyAtbU1/vnnH4SHh8PPzw9XrlxBy5Ytce3aNRw4cAA///wz2rVrB2tr688e85o1a7By5Ups2bIFDRo0wPbt29GtWzfcv38fNWrU4OpNmzYNK1euRIMGDbiEds6cOVi/fj0aNGiAqKgoDBs2DHp6evDx8cHatWtx4sQJHDx4ELa2tnj58iVevnwJALhx4waqVKmCkJAQtG/fHpmZmQXGd/nyZQwcODBP+cWLF5GZmQkPDw9UrVoVzZs3x+rVq6Gnp/fZY/7YmTNn8N9//2HKlCn5Ljc2Ni5w3REjRuC3334rdPsffxn5WHx8PBITE+Hh4cGVGRkZoUmTJoiIiECfPn3yXa958+b49ddf8fDhQzg5OeH27du4fPkyVq1aBQDIzs4GAOjo6HDr8Pl8aGtr4/Llyxg6dChX7u7ujrCwsELjr+gomdWADKkSWgIhOjfyQavM6FLfk5iQ4sjOzkZ0dDSaNGkCAPj+++/x7NmzYn84EFKRnDx5Evr6+pDL5cjOzgafz8f69eu55VWrVsWkSZO452PGjMGZM2dw8OBBlWS2Xr16XPeEGjVqYP369QgNDUW7du1w/vx5PHjwAGfOnIGVlRUAYNGiRejYsSO3/t69e5GVlYVdu3Zxf3Pr169H165dsXTpUpibmwMATExMsHbtWvD5fDg7O2PZsmXIzMzEjBkzAADTp0/HkiVLcPnyZZWEqG/fvhAI/teN7bfffoO3tzdWrFiBqVOncnWXLl2KixcvIigoCBs2bODqjx8/Hj/++CP3PDAwECtXruTKHBwcEBMTgy1btsDHxwcvXrxAjRo18N1334HH46l8QTAzMwPwv6vFqamp+bZNcnIyUlJSuHP2seDgYPTp0wcCgQB16tRBtWrVcOjQIfj6+ua7rYLk9iV1cXEp1noAMH/+fJXXRnEkJiYCANeuuczNzbll+Zk2bRpSU1Ph4uICgUAAhUKBhQsXon///gByjsPW1hbTp0/Hli1boKenh9WrV+Pff/9FQkKCyrasrKzw/PnzEsVfUVAyqwEZ2TSTAdGMp0+folevXoiNjcXNmze5u3hRIktKQiwUIGa+p1r2pVQqkZaaBgNDA/D5fIiFgs+v9JE2bdpg06ZNyMjIwOrVq6GlpYUePXpwyxUKBRYtWoSDBw/i1atXkEqlyM7OznODkE9/Kre0tMSbN28AALGxsbCxsVFJypo1a6ZSPzY2FvXr11f5m2vRogWUSiXi4uK4pKd27doqtww1NzdXGQAlEAhgamrK7TvX6tWrVa4CWlpaIjU1Fa9fv87TH7VFixa4ffu2SlmjRo24/2dkZODJkyfw8/PDsGHDuHK5XA4jIyMAOV0i2rVrB2dnZ3To0AFdunQp9owEEokEgOpVRiAnyT1y5AguX77MlQ0YMADBwcHFTmaL2y3lY1WqVEGVKlVKvH5JHDx4EHv27MHevXtRu3ZtREdHY/z48bCysoKPjw+EQiGOHDkCPz8/mJiYQCAQwMPDAx07dsxzrGKxuNCr4l8DSmY1ICNbDiVTIunDCzzOzoKtUvn5lQgppd9//x1+fn5ITU2FiYkJEhIS6Ja0pFR4PF6Jf+ovLqVSCblIAF2RVonuC6+npwdHR0cAwPbt21G/fn0EBwfDz88PALB8+XKsWbMGQUFBqFu3LvT09DB+/HhIpVKV7XzaLYzH40FZDu/h+e2nKPu2sLDgjjNXQVdE8/Nxkp370/nWrVu5X3Jy5V79bdiwIeLj4/HXX3/h/Pnz6NWrFzw8PPD7778XeZ+mpqbg8Xj48OGDSnnuVeyP980Yg1Kp5H5+NzQ0BACkpKTk2W5ycjKXdDs5OQEAHjx4kOcLxueUppuBhYUFgJyZBywtLbnypKQkuLq6Fri9yZMnY9q0adyV9Lp16+L58+dYvHgxfHx8AABubm6Ijo5GSkoKpFIpzMzM0KRJE5UvJADw/v177ir514oGgGlAulQOmTwbCw/5ofvTh9y3UkLKQ1ZWFvz9/dGzZ0+kpqaiefPmiI6Oxg8//KDp0AjRCD6fjxkzZmDWrFnc+294eDi8vLwwYMAA1K9fH9WqVSv2dE01a9bEy5cvVX7mvXr1ap46t2/fVhlxHh4eznUnKA+GhoawsrJCeHi4Snl4eDhq1apV4Hrm5uawsrLC06dP4ejoqPJwcHBQ2X7v3r2xdetWHDhwAIcPH8b79+8B5CTlCoWi0PhEIhFq1aqFmJgYlfLg4GBMnDgR0dHR3OP27dv4/vvvsX37dgA53TEqV66MyMhIlXVTU1Px+PFjLolt3749KleujGXLluUbQ3JycoHxzZ8/XyWG/B4FcXBwgIWFBUJDQ1Viu3btWqFJdWZmZp4vbQKBIN8vTkZGRjAzM8OjR49w8+ZNeHl5qSy/d+8eGjRoUOC+vgaUzGpABt0wgajJo0eP0KxZM2708bRp03Dp0iXY2NhoODJCNKtnz54QCARcf9EaNWrg3LlzuHLlCmJjY/Hzzz8jKSmpWNv08PCAk5MTfHx8cPv2bYSFhWHmzJkqdfr37w8dHR34+Pjg3r17uHjxIsaMGYOBAwfm6VdZliZPnoylS5fiwIEDiIuLw7Rp0xAdHY1x48YVut68efOwePFirF27Fg8fPsTdu3cREhLCDURatWoV9u3bhwcPHuDhw4c4dOgQLCwsuAFV9vb2CA0NRWJiYqEJo6enp0p3gujoaNy6dQtDhw5FnTp1VB59+/bFzp07IZfnfJYGBARg0aJF2LNnD548eYLr16+jf//+MDMz4/r66unpYdu2bfjzzz/RrVs3nD9/Hs+ePcPNmzcxZcoUjBgxosDYqlSpkieZ//RREB6Ph/Hjx+OXX37BiRMncPfuXQwaNAhWVlYqA27btm2r0oe7a9euWLhwIf788088e/YMR48exapVq9C9e3euzqFDh3Dp0iVueq527drB29s7TzePsLCwr/5mFNTNQANSJNLPVyKkDPz222+Ijo5G5cqVsXv3bnTo0EHTIRHyRdDS0sLo0aOxbNkyjBw5ErNmzcLTp0/h6ekJXV1dDB8+HN7e3vn+fF0QPp+Po0ePws/PD+7u7rC3t8fatWtV/u50dXVx5swZjBs3Do0bN4auri569OjBJYflZezYsUhJScHEiRPx5s0b1KpVCydOnFCZySA/Q4cOha6uLpYvX47JkydDT08PdevW5WZpMDAwwLJly/Do0SMIBAI0btwYp06d4q4qrly5EgEBAdi6dSssLS3x7NmzfPfj5+eHRo0aISUlBUZGRggODkatWrXyHbDVvXt3jB49GqdOnUK3bt0wZcoU6OvrY+nSpXjy5AlMTEzQokULXLx4EWLx/25Q5OXlhStXrmDx4sXo168fUlNTYWNjgx9++AG//PJLyU5sEUyZMgUZGRkYPnw4kpOT8d133+H06dMqfYSfPHmC//77j3u+bt06zJ49G6NGjcKbN29gZWWFn3/+GXPmzOHqJCQkICAggOvCMGjQoDzz5UZERCAlJeWrvx05j5WmV3QFlJqaCiMjI6SkpHB9bcqTTCbDqVOn0MmjFYTLc0Z5rmv0N2RHX2Hi9i4AgMRXz2FuZVvusZCS4dqwU6cKN42aXC7HlClTMHHiRFStWlXT4WhMRW7DL0VWVhbi4+Ph4OCQZ6COOiiVSqSmpsLQ0LBEfWaJZhWl/Xr27ImGDRti+vTpao7u69W7d2/Ur1+fmwWjNMrjb7Cw95Xi5Gv0jqABHzLpyiwpHw8ePICPjw83B6GWlhZWrVr1TSeyhJCKYfny5dDX19d0GF8NqVSKunXrYsKECZoOpdxRNwMNSM6Ugv5cSVnbtWsXRo4ciczMTNjY2JTrz2aEEFLW7O3tMWbMGE2H8dUQiUSYNWuWpsNQC7oyqwEfMujKLCk7GRkZGDx4MHx8fJCZmYm2bdti9OjRmg6LEEIIUQtKZjUgWSKDgK+FtvV6wdekMvXhIyV2//59uLu7Y8eOHeDz+Zg/fz7OnDnDzW1ICCGEfO2om4EGvM+QQUugi+7Nfkarfx7Q7WxJiRw/fhx9+/aFRCKBpaUl9u3bh1atWmk6LEIIIUStKJnVgJQsKQDdz9YjpDB16tSBUChEy5YtsWvXLrXfbpEQQgj5ElAyqwEKJYOSKfEh/Q1eSaV0O1tSZG/evOGS1urVq+Pq1atwdnamqYoIIYR8s+gTUENk8mwE7u2PDk8e0O1syWcxxrB582bY29vj3LlzXHnNmjUpkSWEEPJNo09BQr5wKSkp6NOnD0aOHAmJRIK9e/dqOiRCCCHki0HJLCFfsMjISLi5ueHgwYPQ0tLCihUrEBwcrOmwCCEV3OzZszF8+HBNh/HViImJgbW1NTIyMjQdyjeJkllCvkCMMaxbtw7NmzfHkydPYGdnh7CwMEycOJG6FRBSAomJiRgzZgyqVasGbW1t2NjYoGvXrggNDS3yNnbs2AFjY+M85a1btwaPx+Me5ubm6NmzJ54/f16GR1C4Z8+egcfjITo6+rN1ExMTsWbNGsycOTPPsoiICAgEAnTu3DnPskuXLoHH4yE5OTnPMnt7ewQFBamUXbx4EZ06dYKpqSn09fXRtGlTTJo0Ca9evSrqYRVbVlYW/P39uX326NEDSUlJha6TlJQEX19fWFlZQVdXFx06dMCjR49U6vz888+oXr06xGIxzMzM4OXlhQcPHnDLa9WqhaZNm2LVqlXlclykcPSpqBFM0wGQL9yFCxcwduxYSKVSeHt7IyoqCk2bNtV0WIRUSM+ePYObmxsuXLiA5cuX4+7duzh9+jTatGkDf3//MtnHsGHDkJCQgNevX+P48eN4+fIlBgwYUCbbLmvbtm1D8+bNYWdnl2dZcHAwxowZg3/++QevX78u8T62bNkCDw8PWFhY4PDhw7h37x5WrlyJlJQUrFy5sjThF2rChAn4448/cOjQIfz99994/fo1fvzxxwLrM8bg7e2Np0+f4vjx44iKioKdnR08PDxUrrK6ubkhJCQEsbGxOHPmDBhjaN++PRQKBVdn8ODB2LRpE+RyebkdHykA+8akpKQwACwlJUUt+5NKpezYsWNMmv6BsUBDxgINWe0pe5i1qSNDTlbLUpKS1BILKRmuDaVSte532LBhbM2aNUypVKp1v18jTbXh10QikbCYmBgmkUj+V6hUMpadrpaHQpLKPrx5xRSS1JyyYvxddOzYkVWtWpWlp6fnWfbhwwfu/ytXrmR16tRhurq6zNramo0cOZKlpaUxxhi7ePEi956d+wgMDGSMMdaqVSs2btw4le3u3r2b6erqqpRdunSJNW7cmIlEImZhYcGmTp3KZDIZtzwrK4uNGTOGmZmZMW1tbdaiRQt2/fp1bvn79+9Zv379WOXKlZmOjg5zdHRk27dvZ4yxPLG1atWqwPNRu3Zttn79+jzlaWlpTF9fnz148ID17t2bLVy4UGV57jn4+JzlsrOzY6tXr2aMMfby5UsmEonY+PHjueUKhYJ9+PCB+7c8JCcnM6FQyA4dOsSVxcbGMgAsIiIi33Xi4uIYAHbv3j2VWM3MzNjWrVsL3Nft27cZAPb48WOuLDs7m2lra7Pz58+XwdF8eT5uw7KS7/vK/ytOvkZTc2kAU8jhYF4L/757jDo6Yujp6Wk6JKJhjDFs2rQJvXr1QuXKlQEAv/76q4ajIuQzZJnAIiu17IoPwPjjghmvAdHn3zvfv3+P06dPY+HChfm+137cbYDP52Pt2rVwcHDA06dPMWrUKEyZMgUbN25E8+bNERQUhDlz5iAuLg4AoK+vX+A+Dx48iCZNmnBlr169QqdOneDr64tdu3bhwYMHGDZsGHR0dDB37lwAwJQpU3D48GHs3LkTdnZ2WLZsGTw9PfH48WOYmJhg9uzZiImJwV9//YXKlSvj8ePH3Gw4169fh7u7O86fP4/atWsXeDOe9+/fIyYmBo0aNcqz7ODBg3BxcYGzszMGDBiA8ePHY/r06eDxeJ89zx87dOgQpFIppkyZku/y/Lpq5OrYsSPCwsIKXG5nZ4f79+/nuywyMhIymQweHh5cmYuLC2xtbREREZHvr1vZ2dkAAB0dHa6Mz+dDW1sbly9fxtChQ/Osk5GRgZCQEDg4OMDGxoYrF4lEcHV1RVhYGNq2bVvgMZCyR8msBvC1hOj9/Th4Nx2OdleK/0ZBvi7v3r2Dr68vTp48iVOnTuHEiRPUL5aQMvL48WMwxuDi4vLZuuPHj+f+b29vj19++QUjRozAxo0bIRKJYGRkBB6Pl+/tojdu3Iht27aBMYbMzEw4OTnhzJkzKsttbGywfv168Hg8uLi44PXr15g6dSrmzJkDiUSCTZs2YceOHejYsSMAYOvWrTh37hyCg4MxefJkvHjxAg0aNOASUXt7e277ZmZmAABTU9NCb2f94sULMMZgZZX3S0hwcDDXNaJDhw5ISUnB33//jdatW3/23H3s0aNHMDQ0hKWlZbHWA3K6QBQ2XWVht39PTEyESCTKkyybm5sjMTEx33Vyk93p06djy5Yt0NPTw+rVq/Hvv/8iISFBpe7GjRsxZcoUZGRkwNnZGefOncvzpcHKykqtfaVJDkpmNUhbKKZE9ht35coV9OnTBy9fvoS2tjY6d+5MrwlScQh1c66QqoFSqURqWhoMDQxyvuwJi3YXRcaKPkbh/PnzWLx4MR48eIDU1FTI5XJkZWUhMzMTurqF769///7cgKqkpCQsWrQI7du3R2RkJAwMDBAbG4tmzZqp/H23aNEC6enp+Pfff5GcnAyZTIYWLVpwy4VCIdzd3REbGwsAGDlyJHr06IFbt26hffv28Pb2RvPmzYt8fAC4RPHjK5EAEBcXh+vXr+Po0aMAAC0tLfTu3RvBwcHFTmYZYyV+H6tatWqJ1ispoVCII0eOwM/PDyYmJhAIBPDw8EDHjh3zvHb69++Pdu3aISEhAStWrECvXr0QHh6uci7FYjEyMzPVegyEBoBpBGMMaZJkpEmSi/VGS74eSqUSS5cuRcuWLfHy5UvUqFEDV69exciRIymZJRUHj5fzU7+6HkLd//2/iH8nNWrUAI/HUxl5np9nz56hS5cuqFevHg4fPozIyEhs2LABACCVSj+7HyMjIzg6OsLR0REtWrRAcHAwHj16hAMHDhQpzqLo2LEjnj9/jgkTJuD169do27YtJk2aVKxt5HZj+vDhg0p5cHAw5HI5rKysoKWlBS0tLWzatAmHDx9GSkoKAMDQ0BAAuOcfS05OhpGREQDAyckJKSkpea5sFvUY9fX1C3zUrl27wHUtLCwglUrzzLaQlJRU6NVqNzc3REdHIzk5GQkJCTh9+jTevXuHatWqqdQzMjJCjRo10LJlS/z+++948OABl/znev/+PXeVnKgPJbMawGTZmL6rB6bv6gEJJbPfnHfv3qFz586YNm0aFAoF+vbti8jISLi6umo6NEK+OiYmJvD09MSGDRvynQM0N/GJjIyEUqnEypUr0bRpUzg5OeUZzS8SiVRGrxdGIBAA+N+V0Jo1ayIiIkLlAkZ4eDgMDAxgbW2N6tWrQyQSITw8nFsuk8lw48YN1KpViyszMzODj48PfvvtNwQFBXF963N/7v5cfNWrV4ehoSFiYmK4Mrlcjl27dmHlypWIjo7mHrdv34aVlRX27dsHIOeLAZ/PR2RkpMo2nz59ipSUFDg5OQEAfvrpJ4hEIixbtizfGPKb2ivXtm3bVGL49HHq1KkC13Vzc4NQKFSZbi0uLg4vXrxAs2bNCj0vQE6yamZmhkePHuHmzZvw8vIqsC5jDIwxrs9trnv37qFBgwaf3RcpW9TNgBA1EwgEiIuLg46ODtatWwc/Pz+6GktIOdqwYQNatGgBd3d3zJ8/H/Xq1YNcLse5c+ewadMmxMbGwtHRETKZDOvWrUPXrl0RHh6OzZs3q2zH3t4e6enpCA0NRf369aGrq8t1P8jMzOT6ZSYlJWHBggXQ0dFB+/btAQCjRo1CUFAQxowZg9GjRyMuLg6BgYEICAgAn8+Hnp4eRo4cicmTJ8PExAS2trZYtmwZMjMz4efnBwCYM2cO3NzcULt2bWRnZ+PkyZOoWbMmAKBKlSoQi8U4ffo0rK2toaOjw10p/Rifz4eHhwcuX74Mb29vAMDJkyfx4cMH+Pn55VmnR48eCA4OxogRI2BgYIChQ4di4sSJ0NLSQt26dfHy5UtMnToVTZs25bo82NjYYPXq1Rg9ejRSU1MxaNAg2NraIi4uDkeOHIGBgUGB03OVppuBkZER/Pz8EBAQABMTExgaGmLMmDFo1qyZyuAvFxcXLF68GN27dweQM2DNzMwMtra2uHv3LsaNGwdvb2+u7Z4+fYoDBw6gffv2MDMzw7///oslS5ZALBajU6dO3HafPXuGV69eqQxAI2pSVtMrVBRfwtRc9Sfv4KZPueZchykyMtQSCymZspjWSaFQqEyxFRkZye7cuVMW4ZEioKm5Sq+wKXTUobTTAr1+/Zr5+/szOzs7JhKJWNWqVVm3bt3YxYsXuTqrVq1ilpaWTCwWM09PT7Zr1648U1GNGDGCmZqa5pmaCx9Ni1WpUiXWqlUrduHCBZUYPjc1l0QiYWPGjGGVK1fOd2quBQsWsJo1azKxWMxMTEyYl5cXe/r0Kbd869atzMbGhvH5/EKn5jp16hSrWrUqdy67dOnCOnXqlG/da9euMQDs9u3bXIyBgYHMxcWFicVi5uDgwIYPH87evn2bZ91z584xT09PVqlSJaajo8OcnJzYxIkT2evXrwuMrbQkEgkbNWoUq1SpEtPV1WXdu3dnCQkJKnUAsJCQEO75mjVrmLW1NRMKhczW1pbNmjWLZWdnc8tfvXrFOnbsyKpUqcKEQiGztrZm/fr1Yw8ePFDZ7qJFi5inp2e5HZumfclTc/EY+7Z+505NTYWRkRFSUlK4/j/lSSaT4dSpU+jk0QrC5TkTVLdhm3Fpfj8AwDXnOmh06xr4nxlcQDSHa8NOnQodSVuQpKQkDBgwAD/++CNGjhxZDhGSzyltG5KcOyvFx8fDwcEhz+AhdVAqlUhNTYWhoSHN9lFKjDE0adIEEyZMQN++fdWyz6+9/aRSKWrUqIG9e/eqDOL7mpRHGxb2vlKcfO3re0VVAAZi+jD9Vly4cAH169fH+fPnMWvWLKSlpWk6JELIN47H4+HXX3+lO1WVoRcvXmDGjBlfbSL7paM+sxpgTMnsV0+hUGD+/PlYsGABGGOoXbs2Dh48CAMDA02HRgghcHV1pUGnZSh3JguiGZTMaoCxLp32r9nr16/Rv39/XLp0CQDg5+eHtWvXfnaeSkIIIYQUH2VVGlBJTxdNnHJGSWpBPROOE/VIT09Ho0aNkJCQAD09PWzZsgX9+/fXdFiEEELIV4uSWQ0wM9bDwDZTAQCifyZoOBpSlvT19eHv749Dhw7h4MGD3LyLhBBCCCkfNABMA4x0qc/s1+Tff//Fo0ePuOfTpk3D1atXKZElhBBC1ICSWQ0w1NZCtkyCbJmEbmdbwf35559wdXVFjx49uDv9CAQCjUxdRAghhHyLKJnVADFfgYnbu2Di9i50O9sKSiaTYfLkyejSpQvevXsHoVCI9+/fazosQggh5JtDyawGUDeDiu358+do2bIlVqxYAQAYM2YMrly5UqrbMBJCNIfH4+HYsWNFrn/p0iXweDwkJyeXW0zqNnv2bAwfPlzTYXw1YmJiYG1tjYyMDE2H8k34IpLZDRs2wN7eHjo6OmjSpAmuX79eYN2tW7fi+++/R6VKlVCpUiV4eHgUWv9LIVcouf8b6lAyW1EdP34crq6uuHr1KoyMjHD48GGsXbsW2tramg6NEFIAX19feHt7F7g8ISEBHTt2LNN9zp07t8B5XKOiotC7d29YWlpCW1sbdnZ26NKlC/744w+u69mzZ8/A4/G4h0gkgqOjI3755ReV7mlz584Fj8dDhw4d8uxn+fLl4PF4aN26daGxJiYmYs2aNZg5c2aeZRERERAIBOjcuXOeZYUl9fb29ggKClIpCwsLQ+fOnWFqagpdXV3UqlULEydOxKtXrwqNrzSysrLg7+8PU1NT6Ovro0ePHkhKSip0naSkJPj6+sLKygq6urro0KGDyrgIAGjdurVK+/B4PIwYMYJbXqtWLTRt2hSrVq0ql+MiqjSezB44cAABAQEIDAzErVu3UL9+fXh6euLNmzf51r906RL69u2LixcvIiIiAjY2Nmjfvn25/jGUhdRsBQCAMUDnK7yV37dAqVRixYoVSE5ORuPGjREVFYUff/xR02ERQkrJwsJCbV9Ijx8/jqZNmyI9PR07d+5EbGwsTp8+je7du2PWrFlISUlRqX/+/HkkJCTg0aNHmDdvHhYuXIjt27er1LG0tMTFixfx77//qpRv374dtra2n41p27ZtaN68Oezs7PIsCw4OxpgxY/DPP//g9euSTyW5ZcsWeHt7w8LCAocPH0ZMTAw2b96MlJQUrFy5ssTb/ZwJEybgjz/+wKFDh/D333/j9evXhb5vM8bg7e2Np0+f4vjx44iKioKdnR08PDzyXGUdNmwYEhISuMeyZctUlg8ePBibNm2iO62pA9Mwd3d35u/vzz1XKBTMysqKLV68uEjry+VyZmBgwHbu3Fmk+ikpKQwAS0lJKVG8xSWVStmxY8fYoxevmHKOIft99Hq2cshJBoABYNec6zBFRoZaYiElk9uGUqmUvXjxgs2YMYNlZ2drOixSDB+3ISkZiUTCYmJimEQi0cj+FQoF+/DhA1MoFMVe18fHh3l5eRW4HAA7evQo9zw8PJzVr1+faWtrMzc3N3b06FEGgEVFRTHGGLt48SIDwM6fP8/c3NyYWCxmzZo1Yw8ePGCMMRYSEsK9x+c+QkJCWHp6OjM1NWXdu3cvMBalUskYYyw+Pl5ln7natm3LRo0axT0PDAxk9evXZ126dGG//PKLyjFUrlyZjRw5krVq1arQ81O7dm22fv36POVpaWlMX1+fPXjwgPXu3ZstXLhQZXnuefjw4UOede3s7Njq1asZY4y9fPmSiUQiNnLkyHzbL7/1y0JycjITCoXs0KFDXFlsbCwDwCIiIvJdJy4ujgFg9+7d48oUCgUzMzNjW7du5cpatWrFxo0bV+j+s7Ozmba2Njt//nzpDuQLUZq/wYIU9r5SnHxNo/PMSqVSREZGYvr06VwZn8+Hh4cHIiIiirSNzMxMyGQymJiY5Ls8Ozsb2dnZ3PPU1FQAOQN4ZDJZKaIvmtx9vEuTwI5pI1FWE4CEW85XSiGTycBXQyyk+A4fPozbt2+jadOmkMlksLCwwNy5cwFALa8fUjZy24rarORkMhkYY1AqlVAqc7pNMcYgkUs+s2bZkcgl0JLlfGyJtcTg8XhFWo8xxsVekNzjSk1NRdeuXdGxY0f89ttveP78OQICAlTq5G5n5syZWL58OczMzDBq1CgMGTIEYWFh6NmzJ+7evYszZ87g7NmzAAAjIyOcPn0a7969w6RJkwqN5eNYP97fzZs3ERkZiQEDBqi0AZDTlWLatGnc52lwcDD69euncnz5ef/+PWJiYtCwYcM8dfbv3w8XFxfUqFED/fr1Q0BAAKZOncqd9/xizO84Dh48CKlUirFjx+bbDoaGhgXG16lTJ1y+fLnAc2VnZ4e7d+/mu+zGjRuQyWT44YcfuO07OTnB1tYWV65cgbu7e551cmelEYlEKjFpa2sjLCwMQ4YM4cr27NmD3377DRYWFujSpQtmzZqlcqdHLS0tuLq64p9//kGbNm0KPIaKIve19rm/peJQKpVgjEEmk0EgEKgsK877tUaT2f/++w8KhQLm5uYq5ebm5njw4EGRtjF16lRYWVnBw8Mj3+WLFy/GvHnz8pSfPXtWrbcXvXw1Eg3zKecBOHP2LJhIpLZYyOdJpVKEhITgr7/+AgAsWLBAwxGRsnDu3DlNh1BhaWlpwcLCAunp6ZBKpQByksv2f7bXSDxnO5+FWEtcpLoymQxyuZy7mJEfiUSC1NRU7if8FStWQEdHB9bW1vD398e4ceOQkZGB1NRUZGZmAgCmT5+OBg0aAABGjx6N3r17482bN9DR0YFQKASPx+M+Z2QyGZd0WVlZcbHcunUL3bp14+LYtm0bOnTogPT0dADAd999Bz6fD6k058KHj48PvL29ufWzs7OhUCjQsmVLpKSk4K+//oKrqysOHTqEU6dOYc+ePYUee2xsLBhjMDAwyFNn69at6NGjB1JTU9G8eXMkJyfjr7/+wnfffQcA3HlIS0sD/5Puc0qlEllZWUhNTcX9+/dhYGAACwsLpKWlFdpWn1q1ahWysrIKXK6lpVXgscXHx0MkEoHP56vUqVy5Mp4/f57velZWVrC2tsaUKVOwevVq6OrqYuPGjfj333/x77//cut4e3tjzJgxsLCwwP379zFv3jzcv38fu3fvVtmemZkZHj9+XOhrr6IpbhsWRiqVQiKR4J9//snTHSP39VUUFfoOYEuWLMH+/ftx6dKlAuf1nD59OvetGsi5Mpvbz9bQ0LDcY5TJZDh37hwcXOoAz3LK+DwBTBoao9FDBQQAPNu3B1+NiTUp3KNHj9C/f39ER0cDAAICAlCzZk20a9cOQiEN3quIcv8OqQ1LLisrCy9fvoS+vj73fpt7lVQTDAwMoCss2vumUCiElpZWoe/5YrEYhoaGePHiBerXr48qVapwy1q2bAkA0NPTg6GhIZegNm3alNtm9erVAeScpypVqkBbWxsCgUBln7nnzcDAgCtv1qwZbt26BQBwdnaGSCSCoaEh9PX1AQD79u1DzZo1IZPJcO/ePYwbNw6LFy/G4sWLAYDbj6mpKQYMGIBDhw4hKSkJTk5OaN68OQ4dOlTosecmoWZmZip14uLicOvWLRw/fpwr7927N/bv349OnToBAHcePj6ej7ero6MDQ0NDCIVCbj8GBgZFvqIOoFSf02KxON9tCAQCaGtrF7jtI0eOYNiwYXBwcIBAIEDbtm3RoUMHMMa4dcaOHcvVb9asGapVq4Z27drh7du33GsByDlemUymlnyjvDHGkJaWVuw2LExWVhbEYjFatmyZJ48rzhcAjSazlStXhkAgyDOyMCkpCRYWFoWuu2LFCixZsgTnz59HvXr1Cqynra2db8d+oVCo1g+1TNn/LskLtUSoMcwBQUESLhY+fcB+Efbt24fhw4cjPT0dlStXxu7du9G2bVucOnVK7a8ZUvaoDUtOoVCAx+OBz+dziYmeSA/X+l1Ty/6VSiX3Qcrn84vVzSB3tPmnVw8/lntcudv8uG7u/3Pr5D7X1tbm/v/xT6QFbSf3roCPHj1C06ZNAeQkXB/fLfDTfdjZ2XHLa9eujfj4eMyePRvz5s2Djo6Oyn78/PzQpEkT3L9/H0OGDCkwjo/lJu0pKSkqv5KGhIRALpfD2tqaK2OMQVtbGxs2bICRkRGMjY0B5Fyp+7SrX3JyMoyNjcHn8+Hs7IyUlBQkJibC0NCw0Hb4VMeOHREWFlbgcjs7O9y/fz/fZVZWVpBKpUhNTeViBXJyDEtLywLjaNy4MaKjo5GSkgKpVAozMzM0adIEjRo1KnCdZs2aAQCePn2KGjVqcOUfPnxA9erVi3XMX6rcrgWf+1sqjtzXaH7vzcV5r9bo2RWJRHBzc0NoaChXplQqERoayr0w8rNs2TIsWLAAp0+fRqNGjdQRaqmlSGg045du4sSJ6NevH9LT09GyZUtER0fnO90NISQHj8eDrlBXbQ+xlpj7f1ldGfqUs7Mz7t69qzLW4saNG8XejkgkgkKhUClr3749TExMsHTp0hLHJxAIIJfLua4eH6tduzZq166Ne/fuqfSXLUz16tVhaGiImJgYrkwul2PXrl1YuXIloqOjucft27dhZWWFffv2AQBq1KgBPp+PyMhIlW0+ffoUKSkpXBL+008/QSQSYe3atfnGUNh8vdu2bVOJ4dPHqVOnClzXzc0NQqFQJceIi4vDixcvCs0xchkZGcHMzAyPHj3CzZs34eXlVWDd3F/yLC0tVcrv3bvHdUUh5Ufj3QwCAgLg4+ODRo0awd3dHUFBQcjIyMDgwYMBAIMGDULVqlW5n1SWLl2KOXPmYO/evbC3t0diYiIAQF9fn/tZ5kuUlkUDT750TZo0AY/Hw8yZMxEYGAgtLY3/eRBCykhKSgqXcOQyNTWFjY2NSlm/fv0wc+ZMDB8+HNOmTcOLFy+4G6QUJ4G2t7dHfHw8oqOjYW1tDQMDA+jr62Pbtm3o3bs3OnfujLFjx6JGjRpIT0/H6dOnASDPIJh3794hMTERcrkcd+/exZo1a9CmTZsCf7a+cOECZDKZypXIwuQOur58+TI3F+/Jkyfx4cMH+Pn5wcjISKV+jx49EBwcjBEjRsDAwABDhw7FxIkToaWlhbp16+Lly5eYOnUqmjZtiubNmwMAbGxssGrVKowZMwZZWVnw8fGBvb09/v33X+zatQv6+voFTs9VmpvRGBkZwc/PDwEBATAxMYGhoSHGjBmDZs2acVfGAcDFxQWLFy9G9+7dAQCHDh2CmZkZbG1tcffuXYwbNw7e3t5o3z6nf/iTJ0+wd+9edOrUCaamprhz5w4mTJiAli1bqvxS/OzZM7x69arAMT2kDJXJ3AqltG7dOmZra8tEIhFzd3dnV69e5Za1atWK+fj4cM/t7OzyTHkCgAUGBhZpX5qammvavnAmnW3G1v8cqjI1180aTjQ1lwYlJiaqPI+Njc1Th6Z1qvioDUuvok/Nld/nhp+fH2Ms/6m56tWrx0QiEXNzc2N79+5lALipt/KbkioqKooBYPHx8YwxxrKysliPHj2YsbExNzVXrhs3brCffvqJValShWlpaTFTU1Pm6enJ9u/fn2dqrtyHQCBg1tbWbNiwYezNmzfctnKn5irIuHHjPjs116lTp1jVqlW5c9ulSxfWqVOnfOteu3aNAWC3b99mjOW8LgIDA5mLiwsTi8XMwcGBDR8+nL19+1ZlPYVCwY4ePcrat2/PKlWqxHR0dJiLiwubNGkSe/36daHxlYZEImGjRo1ilSpVYrq6uqx79+4sISFBpc6n7bNmzRpmbW3NhEIhs7W1ZbNmzVKZjvHFixesZcuWzMTEhGlrazNHR0c2efLkPHnFokWLmKenZ7kdm7p9yVNz8Rj76FYi34DU1FQYGRkhJSVFbQPATp06hbPvKyEo/if8+mY/smUSTNzeBQBws4YTGkRH0QAwNcvIyMDo0aPx119/ITo6utA+2rlt2KlTJ+pvWUFRG5ZeVlYW4uPj4eDgUOCA2/KUO21WcftcloU9e/Zg8ODBSElJ4QYVfU0YY2jSpAkmTJiAvn37lss+NNl+miCVSlGjRg3s3bsXLVq00HQ4ZaI82rCw95Xi5Gtf/yvqC5FKfWa/GPfv34e7uzt27NiBt2/fqvSnIoSQXbt24fLly4iPj8exY8cwdepU9OrV66tMZIGc7hO//vor3amqDL148QIzZsz4ahLZLx11ClSTVOozq3GMMYSEhGD06NGQSCSwtLTE3r17P3vfckLItyUxMRFz5sxBYmIiLC0t0bNnTyxcuFDTYZUrV1dXuLq6ajqMr4ajoyMcHR01HcY3g5JZNUnNom+8mpSeno4RI0Zgz549AHJGFe/evVtlLklCCAGAKVOmYMqUKZoOgxBSRNTNQE3oyqxm/fLLL9izZw8EAgEWLVqEv/76ixJZQggh5CtAV2bVQKEEMqUKgO5YqzGzZs1CZGQkAgMDuVsxEkIIIaTioyuzapCpOm82+DwBjOsYoqWeHgT5r0JKKTU1FStXrkTuZB36+vo4d+4cJbKEEELIV4auzKpBphz4eKptoZYIzv7Vsfn/b2dLytatW7fQu3dvPH78GEDOnb0IIYQQ8nWiK7NqIJExHBLN03QYXz3GGNavX49mzZrh8ePHsLW1pWlRCCGEkK8cXZlVA5lMitr855AptTUdylcrOTkZfn5+OHLkCADAy8sL27dvh4mJiYYjI4QQQkh5oiuzapD5yaxc2TIJboy7DbeHcchUKjUT1Ffk5s2baNCgAY4cOQKhUIigoCAcPXqUEllCCCHkG0DJrBrkd/MvpVQJybd1J+Fyo1Qq8e+//8LBwQHh4eEYN24ceDze51ckhJBvRFxcHCwsLJCWlqbpUL4affr0wcqVKzUdBgEls2ohoYuvZU6h+N8UEe7u7jh69Chu3bqFxo0bazAqQsiXRqFQoHnz5vjxxx9VylNSUmBjY4OZM2eqlB8+fBg//PADKlWqBLFYDGdnZwwZMgRRUVFcnR07doDH43EPfX19uLm5cd2c1KV169YYP358kepOnz4dY8aMgYGBQZ5lLi4u0NbWRmJiYp5l9vb2CAoKylM+d+7cPHcMS0xMxJgxY1CtWjVoa2vDxsYGXbt2Lfdbhh86dAguLi7Q0dFB3bp1cerUqc+us2HDBtSsWZNr4127dqksv3//Pnr06AF7e3vweLx8z8GsWbOwcOFCpKSklNWhkBKiZFYNMuX/u0rIGINUnqXBaCq+K1euoFatWrh9+zZX1qVLFxgbG2suKELIF0kgEGDHjh04ffo0dwdAABgzZgxMTEwQGBjIlU2dOhW9e/eGq6srTpw4gbi4OOzduxfVqlXD9OnTVbZraGiIhIQEJCQkICoqCp6enujVqxfi4uLUdmxF9eLFC5w8eRK+vr55ll2+fBkSiQQ//fQTdu7cWeJ9PHv2DG5ubrhw4QKWL1+Ou3fv4vTp02jTpg38/f1LEX3hrly5gr59+8LPzw9RUVHw9vaGt7c37t27V+A6mzZtwvTp0zF37lzcv38f8+bNg7+/P/744w+uTmZmJqpVq4YlS5bAwsIi3+3UqVMH1atXx2+//Vbmx0WKiX1jUlJSGACWkpKilv1JpVI2YPlBxgINWfasyqyaeW0GgHvcrOHEFBkZaomlolMoFGzp0qVMIBAwAKxTp05q2a9UKmXHjh1jUqlULfsjZY/asPQkEgmLiYlhEomEK1MqlUyRkaGWhywtjb17/ZrJ0tKYIiODKZXKYsW/Zs0aVqlSJfb69Wt27NgxJhQKWXR0NLc8IiKCAWBr1qzJd/2P9xcSEsKMjIxUlisUCiYUCtnBgwe5svfv37OBAwcyY2NjJhaLWYcOHdjDhw9V1vv9999ZrVq1mEgkYnZ2dmzFihUqyzds2MAcHR2ZtrY2q1KlCuvRowdjjDEfHx+VzxIALD4+Pt/Yly9fzho1apTvMl9fXzZt2jT2119/MScnpzzL7ezs2OrVq/OUBwYGsvr163PPO3bsyKpWrcrS09Pz1P3w4QNTKBTcv2WpV69erHPnziplTZo0YT///HOB6zRr1oxNmjRJpSwgIIC1aNEi3/oFnQPGGJs3bx777rvvihd0BVUebZjf+0qu4uRrNJuBGuQOAMuSA3z+/055Q7EYYurbWSRv376Fj48P/vrrLwA5fZW2bNmi4agI+bYxiQRxDd3Uus+k///X+VYkeLq6RV5vzJgxOHr0KAYOHIi7d+9izpw5qF+/Prd837590NfXx6hRo/Jdv7B++AqFgvuZumHDhly5r68vHj16hBMnTsDQ0BBTp05Fp06dEBMTA6FQiMjISPTq1Qtz585F7969ceXKFYwaNQqmpqbw9fXFzZs3MXbsWOzevRvNmzfH+/fvERYWBgBYs2YNHj58iDp16mD+/PkAADMzs3zjCwsLQ6NGjfKUp6Wl4dChQ7h27RpcXFyQkpKCsLAwfP/99585m6rev3+P06dPY+HChdDT08uz3NjYGMoCBjvv2bMHP//8c6Hb/+uvvwqMKSIiAgEBASplnp6eOHbsWIHby87Oho6OjkqZWCzG9evXIZPJIBQKC43nY+7u7li4cCGys7OhrU0zFmkKJbNqkPX/3QzEQh7Gd1uFbJkE++rNwM6N2TRQqQjCwsLQp08fvH79Gjo6Oli7di2GDh1K544QUmQ8Hg+bNm1CzZo1UbduXUybNk1l+cOHD1GtWjVoaf3vY3HVqlWYM2cO9/zVq1cwMjICkNPnVl9fHwAgkUggFArx66+/onr16gDAJbHh4eFo3rw5gJzEzcbGBseOHUPPnj2xatUqtG3bFrNnzwYAODk5ISYmBsuXL4evry9evHgBPT09dOnSBQYGBrCzs0ODBg0AAEZGRhCJRNDV1S3wZ/Bcz58/zzeZ3b9/P2rUqIHatWsDyLlIEBwcXOxk9vHjx2CMwcXFpVjrAUC3bt3QpEmTQutUrVq1wGWJiYkwNzdXKTM3N8+3/28uT09PbNu2Dd7e3mjYsCEiIyOxbds2yGQy/Pfff7C0tCxy/FZWVpBKpUhMTISdnV2R1yNli5JZNfh0ai5toRgCbQElY0Vw+fJltG7dGkqlEs7Ozjh48CDq1aun6bAIIQB4YjGcb0WqZV9KpRKpaWkwNDAAn88HTywu9ja2b98OXV1dxMfH499//4W9vX2h9YcMGYJu3brh2rVrGDBgAHd7bAAwMDDArVu3AOT0rzx//jxGjBgBU1NTdO3aFbGxsdDS0lJJ1ExNTeHs7IzY2FgAQGxsLLy8vFT22aJFCwQFBUGhUKBdu3aws7NDtWrV0KFDB3To0AHdu3eHbjGuSAM5yfanVyJzz8eAAQO45wMGDECrVq2wbt26fAeKFYSVYmYeAwODYu2rLMyePRuJiYlo2rQpGGMwNzeHj48Pli1bBj6/eEOJxP//OszMzCyPUEkR0QAwNaDZDEquWbNmaNOmDQYOHIibN29SIkvIF4TH44Gvq6u+h1jM/b+4FwOuXLmC1atX4+TJk3B3d4efn59KElajRg08ffoUMpmMKzM2Noajo2O+Vwb5fD4cHR3h6OiIevXqISAgAK1bt8bSpUtLfkI/kZsw79u3D5aWllzXiOTk5GJtp3Llyvjw4YNKWUxMDK5evYopU6ZAS0sLWlpaaNq0KTIzM7F//36unqGhYb6j9ZOTk7mr1DVq1ACPx8ODBw+KfYx79uyBvr5+oY/crhX5sbCwQFJSkkpZUlJSoVerxWIxtm/fjszMTDx79gwvXryAvb09DAwMCuyqUZD3798DKLiLB1EPSmbVIHee2Qwpw4TgTpi280coshWFr/QNCw8Ph0QiAZAzEvmPP/7Arl27uJ/0CCGkODIzM+Hr64uRI0eiTZs2CA4OxvXr17F582auTt++fZGeno6NGzeWeD8CgYB776pZsybkcjmuXbvGLX/37h3i4uJQq1Ytrk54eLjKNsLDw+Hk5ASBQAAA0NLSgoeHB5YtW4Y7d+7g2bNnuHDhAgBAJBKpTFNYkAYNGiAmJkalLDg4GC1btsTt27cRHR3NPQICAhAcHMzVc3Z2RmRk3qvvt27dgpOTEwDAxMQEnp6e2LBhAzIyMvLULSz57tatm8r+83vk10UiV7NmzfJM/XXu3Dk0a9aswHVyCYVCWFtbQyAQYP/+/ejSpUuxr8zeu3cP1tbWqFy5crHWI2WszIakVRDqns0gLTOLuUz9nSnnGLD65lrcqNNGQfVYjLMLi3F2odkM/p9cLmeBgYGMx+MVOhJV3WgkfMVHbVh6hY06VofSjKQeO3Ysc3R0ZBkfvddu3ryZ6evrq8wAMHHiRCYQCNiECRNYWFgYe/bsGYuIiGADBgxgPB6P+9wICQlhhoaGLCEhgSUkJLCnT5+yLVu2MIFAwObNm8dtz8vLi9WqVYuFhYWx6Oho1qFDB+bo6Mi9DiMjIxmfz2fz589ncXFxbMeOHUwsFrOQkBDGGGN//PEHW7NmDYuKimLPnj1jGzduZHw+n927d48xxtiwYcNY48aNWXx8PHv79m2B5+bEiROsSpUqTC6XM8Zy/h7MzMzYpk2b8tSNiYlhALh9hIeHMz6fz3755RcWExPD7t69y2bMmMG0tLTY3bt3ufWePHnCLCwsWK1atdjvv//OHj58yGJiYtiaNWuYi4tLuc1mEB4ezrS0tNiKFStYbGwsCwwMZEKhUCW2adOmsYEDB3LP4+Li2O7du9nDhw/ZtWvXWO/evZmJiYnKayE7O5tFRUWxqKgoZmlpySZNmsSioqLYo0ePVPbv4+PDhgwZUqbH9KX6kmczoGS2nL16l8Zcpv7O0qcbcImstakjc9/oSsnsR16/fs1at27NnaMhQ4Zwb7yaRolQxUdtWHoVNZm9dOkSEwgELCwsLM+y9u3bsx9++EFl2q0DBw6w1q1bMyMjIyYUCpm1tTXr168fu3r1KlcnJCREZUosbW1t5uTkxBYuXKjyvpU7NZeRkRETi8XM09OzwKm5hEIhs7W1ZcuXL+eWhYWFsVatWrFKlSoxsVjM6tWrxw4cOMAtj4uLY02bNmVisbjQqblkMhmzsrJip0+f5vbJ5/NZYmJivvVr1qzJJkyYwD0/c+YMa9GiBatUqRIzNTVlrVu3Zn///Xee9V6/fs38/f2ZnZ0dE4lErGrVqqxbt27s4sWL5ZbMMsbYwYMHmZOTExOJRKx27drszz//VFnu4+PDWrVqxT2PiYlhrq6uTCwWM0NDQ+bl5cUePHigsk58fHyeqc8AqGxHIpEwIyMjFhERUebH9CX6kpNZHmPf1j1VU1NTYWRkhJSUFBgaGpb7/mJffcCP6y7gJn8w9Bfn3EZw5ZCTONh4NkKCcn6Ocr4VCX4xO/R/Tc6ePYsBAwbg7du30NPTw+bNm1UGJWiaTCbDqVOn0KlTp2JN2UK+HNSGpZeVlYX4+Hg4ODjkO5iovCmVSqSmpsLQ0LDYPwWTnDtenThxAmfOnNHI/r/G9tu0aROOHj2Ks2fPajoUtSiPNizsfaU4+RrNZlDOUrNyOsx++pVh1n7qMyuXyxEYGIjFixeDMYZ69erhwIEDJZrehRBCSMF+/vlnJCcnIy0tTe2zB3ythEIh1q1bp+kwCCiZLXcpkpyRsXKmDSDnymwlSx1UC5cCAIQuziWaYuZr8ObNG2zevBmMMfz8889YvXo1N80JIYSQsqOlpYWZM2dqOoyvytChQzUdAvl/lMyWs9T/T2b5PMDWzBkA4DnMESm/5yy32Lntm51v1srKCrt27UJaWhr69Omj6XAIIYQQUgFRMlvOkv8/mRULeZjyY86UL2JdMf43a9+3k8jKZDLMmjUL3333Hbp27QoA6Ny5s4ajIoQQQkhF9nX0wv6CpUrkn6/0DXjx4gVatWqFZcuWwdfXt9iTfhNCCCGE5IeS2XKWkiX7fKWv3IkTJ+Dq6oqIiAgYGRlh69atMDY21nRYhBBCCPkKUDeDciZX5ExjkCljmLOnHwDAe/pVTYakNlKpFFOnTkVQUBAAoHHjxjhw4AAcHBw0GxghhBBCvhqUzJY3xqCLbDAGvE9P+v+ir39q38zMTLRu3Ro3btwAAEyYMAFLliyBSCTScGSEEEII+ZpQN4PyxBiGPxmFSJ2Rmo5E7XR1ddGgQQNUqlQJx48fx6pVqyiRJYR8U3x9feHt7c09b926NcaPH6+xeL4U9vb23C925S00NBQ1a9aEQkFzu5cFqVSKatWq4ebNm5oORQUls+VJlgm7zHuajkJtsrKy8P79e+55UFAQoqOj0a1bNw1GRQghQGJiIsaNGwdHR0fo6OjA3NwcLVq0wKZNm5CZmamWGI4cOYIFCxaU6TY/TZhz8Xg87qGlpQVbW1sEBAQgOzu7TPdfmB07duQ7PuLGjRsYPny4WmKYMmUKZs2aBYFAoFIukUhgYmKCypUr53tOeDwejh07lqc8v/P9+PFjDB48GNbW1tDW1oaDgwP69u1b7gnfhg0bYG9vDx0dHTRp0gTXr18vtL5MJsP8+fNRvXp16OjooH79+jh9+rRKncWLF6Nx48YwMDBAlSpV4O3tjbi4OG65SCTCxIkTMXXq1HI5ppKiZFZNtrvu5f4vVarvzURdHj9+jObNm6NXr17cN2CxWAxbW1sNR0YI+dY9ffoUDRo0wNmzZ7Fo0SJERUUhIiICU6ZMwcmTJ3H+/PkC15XJym4Qr4mJiVrvvhUSEoKEhATEx8dj48aN2L17N3755Re17b8gZmZm0FXDLdwvX76MJ0+eoEePHnmWHT58GLVr14aLi0u+SWtR3bx5E25ubnj48CG2bNmCmJgYHD16FC4uLpg4cWIpoi/cgQMHEBAQgMDAQNy6dQv169eHp6cn3rx5U+A6s2bNwpYtW7Bu3TrExMRgxIgR6N69O6Kiorg6f//9N/z9/XH16lWcO3cOMpkM7du3R0ZGBlenX79+uHz5Mu7fv19ux1ds7BuTkpLCALCUlJTy31l2OmOBhowFGrKlB8IYAAaANQqqx2KcXViMswtLS/6v/OMoZ/v27WMGBgYMADM1NWVxcXGaDqlMSaVSduzYMSaVSjUdCikhasPSk0gkLCYmhkkkEq5MqVQyaZZcLY+sTCl7m/Qfy8qUMmmWnCmVyiLH7unpyaytrVl6enq+yz/eFgC2ceNG1rVrV6arq8sCAwOZXC5nQ4YMYfb29kxHR4c5OTmxoKAglW3I5XI2YcIEZmRkxExMTNjkyZPZoEGDmJeXF1enVatWbNy4cdzzrKwsNnHiRGZlZcV0dXWZu7s7u3jxIrc8JCSEGRkZsdOnTzMXFxemp6fHPD092evXrxljjAUGBnKfK7mP3PUBsKNHj6rE6Ofnxzp16qRStnHjRlatWjUmFAqZk5MT27Vrl8ry58+fs27dujE9PT1mYGDAevbsyRITE7nl0dHRrHXr1kxfX58ZGBiwhg0bshs3brCLFy/miW3q1KlMoVAwOzs7tnr1apVzvnXrVubt7c3EYjFzdHRkx48fV4nj+PHjzNHRkWlra7PWrVuzHTt2MADsw4cP+TUpY4wxf39/9tNPP+W7rHXr1mzz5s1s06ZNrF27dnmW53f+GGPMx8eHa1OlUslq167N3NzcmEKhyFO3sNhKy93dnfn7+3PPFQoFs7KyYosXLy5wHUtLS7Z+/XqVsh9//JH179+/wHXevHnDALC///6bKRQK9uHDB6ZQKFibNm3YrFmzSn0c+b2v5CpOvkYDwNSEFTDoS6ylo+ZIyo5EIsH48ePx66+/AgC+++477Nu3D9bW1hqOjBCiDnKpEr+O+1sj+x6+phWE2oLP1nv37h13RVZPTy/fOp/ehXHu3LlYsmQJgoKCoKWlBaVSCWtraxw6dAimpqa4cuUKhg8fDktLS/Tq1QsAsHLlSuzYsQPbt29HzZo1sXLlShw9ehQ//PBDgbGNHj0aMTEx2L9/P6ysrHD06FF06NABd+/eRY0aNQDkDKZdsWIFdu/eDT6fjwEDBmDSpEnYs2cPJk2ahNjYWKSmpiIkJARAztXf/Dx8+BAXLlyAr68vV3b06FGMGzcOQUFB8PDwwMmTJ7mfy9u0aQOlUgkvLy/o6+vj77//hlwuh7+/P3r37o1Lly4BAPr3748GDRpg06ZNEAgEiI6OhlAoRPPmzREUFIQ5c+YgLi4OSqUSSqWywHMxb948LFu2DMuXL8e6devQv39/PH/+HCYmJoiPj8dPP/2EcePGYejQoYiKisKkSZMK3FausLAw9OvXL0/5kydPEBERgSNHjoAxhgkTJuD58+ews7P77DY/Fh0djfv372Pv3r3g8/P+0F3YFJSLFi3CokWLCt1+TExMvr9uSqVSREZGYvr06VwZn8+Hh4cHIiIiCtxednY2dHRUcw6xWIzLly8XuE5KSs4tnj59Xbm7uyMsLKzQ+NWJklk1YAzQupoOi0o5fyj2OlUBxAPI+yZaUcTFxaFXr164c+cOeDweZsyYgblz50JLi15ShJAvx+PHj8EYg7Ozs0p55cqVkZWVBQDw9/fH0qVLuWX9+vXD4MGDVerPmzeP+7+DgwMiIiJw8OBBLpkNCgrC9OnT8eOPPwIANm/ejDNnzhQY14sXLxASEoIXL17AysoKADBp0iScPn0aISEhXKIjk8mwefNmVK9eHUBOAjx//nwAgL6+PsRiMbKzs2FhYZFnH3379oVAIIBcLkd2dja6dOmikgCtWLECvr6+GDVqFAAgICAAV69exYoVK9CmTRuEhobi7t27iI+Ph42NDQBg165dqF27Nm7cuIHGjRvjxYsXmDx5MlxcXACAS8IBwMjICDweDxYWFlAqlUhNTS3wfPj6+qJv374AchK9tWvX4vr16+jQoQO2bNkCZ2dnLF++HADg7OyMe/fuYeHChQVuDwCeP3/OnduPbd++HR07dkSlSpUAAJ6enggJCcHcuXML3d6nHj16BADcsRfHiBEjuNdOQfKLHQD+++8/KBQKmJubq5Sbm5vjwYMHBW7P09MTq1atQsuWLVG9enWEhobiyJEjBQ6OUyqVGD9+PFq0aIE6deqofBmxsrLC8+fPC41fnSjzUAM504aORBuzem2HVtZLfL96iaZDKhXGGPr37487d+7AzMwMe/bsQbt27TQdFiFEzbREfAxf00ot+1IqlUhLS4WBgSH4fD60RKUb8nH9+nUolUr0798/zwCgRo0a5am/YcMGbN++HS9evIBEIoFUKoWrqyuAnKtXCQkJaNKkCVdfS0sLjRo1KvBXubt370KhUMDJyUmlPDs7G6amptxzXV1dLpEFAEtLy0L7RX5s9erV8PDwgEKhwOPHjxEQEICBAwdi//79AIDY2Ng8A7FatGiBNWvWcMttbGy4RBYAatWqBWNjY8TGxqJx48YICAjA0KFDsXv3bnh4eKBnz54q8RZVvXr1uP/r6enB0NCQO864uDg0btxYpb67u/tntymRSPJciVQoFNi5cyd3jAC4q91z5szJ9wprQQpq26IwMTEp8Cp6eVmzZg2GDRsGFxcX8Hg8VK9eHYMHD8b27dvzre/v74979+7le+VWLBarbeBkUVAyq2bNb6xG7rVYccOG4InFGo2nJHg8HoKDgzF9+nQEBwfD0tJS0yERQjSAx+MV6af+sqBU8qCVLYBQW1CshMPR0RE8Hk9lRDYAVKtWDUDOh/KnPu2OsH//fkyaNAkrV65Es2bNYGBggOXLl+PatWslOJIc6enpEAgEiIyMzDPSXl9fn/u/UChUWcbj8YqcRFlYWMDR0RFAztXMtLQ09O3bF7/88gtXXlpz585Fv3798Oeff+Kvv/5CYGAg9u/fj+7duxdrO/kdZ2HdEoqicuXK+PDhg0rZmTNn8OrVK/Tu3VulXKFQIDQ0lLswY2BgwP3E/rHk5GQYGRkBAPdF5MGDB2jQoEGxYitNN4PKlStDIBAgKSlJpTwpKSnfK/S5zMzMcOzYMWRlZeHdu3ewsrLCtGnTuL+Fj40ePRonT57EP//8k2/Xwffv38PMzKzQ+NWJZjNQM97/vwnVCL8Muz2/VZhuBvfv38dvv/3GPa9fvz5OnTpFiSwh5ItmamqKdu3aYf369SojsosjPDwczZs3x6hRo9CgQQM4OjriyZMn3HIjIyNYWlqqJLdyuRyRkZEFbrNBgwZQKBR48+YNHB0dVR6FJSSfEolERZ5DNTdplkgkAICaNWsiPDw8z7HWqlWLW/7y5Uu8fPmSWx4TE4Pk5GSuDpCT1E2YMAFnz57Fjz/+yPXfLU5shXF2ds4zzVXuDXkK06BBA8TExKiUBQcHo0+fPoiOjlZ59OnTB8HBwSr7/LT9FAoFbt++zSWxrq6uqFWrFlauXJlv4p2cnFxgbCNGjMgTw6ePgroZiEQiuLm5ITQ0lCtTKpUIDQ1Fs2bNPntedHR0ULVqVcjlchw+fBheXl7cMsYYRo8ejaNHj+LChQsF3rHz3r17xU7gyxNdmVUTqSwLy46OwuqMRBy0swNfLK4QiSxjDDt27IC/vz/kcjmcnJyK9PMOIYR8KTZu3IgWLVqgUaNGmDt3LurVqwc+n48bN27gwYMHcHNzK3T9GjVqYNeuXThz5gwcHBywe/du3LhxQ+WDfty4cViyZAlq1KgBFxcXrFq1qtBkxsnJCf3798egQYOwcuVKNGjQAG/fvkVoaCjq1auHzp07F+nY7O3tcebMGcTFxcHU1BRGRkbcVc7k5GQkJiZCqVTi0aNHmD9/PpycnFCzZk0AwOTJk9GrVy80aNAAHh4e+OOPP3DkyBFuqjIPDw/UrVsX/fv3R1BQEORyOUaNGoVWrVqhUaNGkEgkmDx5Mn766Sc4ODjg33//xY0bN7ipsOzt7ZGeno7Q0FDUrVsXcrkchoaGRTquj/38889YtWoVpk6dCj8/P0RHR2PHjh0ACh934unpiZ07d3LP3759iz/++AMnTpxAnTp1VOoOGjQI3bt3x/v372FiYoKAgAD4+fnBxcUF7dq1Q0ZGBtatW4cPHz5g6NCh3L5DQkLg4eGB77//HjNnzoSLiwvS09Pxxx9/4OzZs/j77/wHSJa2m0FAQAB8fHzQqFEjuLu7IygoCBkZGSp9vQcNGoSqVati8eLFAIBr167h1atXcHV1xatXrzB37lwolUpMmTKFW8ff3x979+7F8ePHYWBggMTERAA5X9i0tbW5emFhYWU+Z3KplHpehQpGE1NzSWebsZVDTnLTk9ys4cQUGRnlv/9SSktLYwMHDuTibteuHUtKStJ0WGpH0zpVfNSGpVfYFDrq8PG0QCXx+vVrNnr0aObg4MCEQiHT19dn7u7ubPny5Szjo/dj5DMlU1ZWFvP19WVGRkbM2NiYjRw5kk2bNo3Vr1+fqyOTydi4ceOYoaEhMzY2ZgEBAZ+dmksqlbI5c+Ywe3t7JhQKmaWlJevevTu7c+cOY+x/U3N97OjRo+zjj+43b96wdu3aMX19/TxTc+U+eDwes7S0ZL1792ZPnjxR2V5ppubKzs5mffr0YTY2NkwkEjErKys2evRoldfIiBEjmKmp6Wen5vr0nBsZGbGQkBDu+adTc23atIkBKPT1+O7dO6ajo8MePHjAGGNsxYoVzNjYON/3gezsbGZsbMzWrFnDle3Zs4e5ubkxAwMDZm5uzjp16sRu376dZ924uDg2aNAgZmVlxUQiEbOzs2N9+/Zlt27dKjC2srBu3Tpma2vLRCIRc3d3Z1evXlVZ3qpVK+bj48M9v3TpEqtZsybT1tZmpqambODAgezVq1cq6+CT6dRyHyEhIdzf4OXLl5mxsTHLzMws9TGU1dRcvP8P/puRmpoKIyMjpKSklOgbYrFIM4BFVpAptbHuVQgmbu8CALhZwwkNoqPAV8Ok0SV1584d9OrVC3FxceDz+ViwYAGmTZtWrL5qXwuZTIZTp06hU6dOefp1kYqB2rD0srKyEB8fDwcHhzyDatQhdzS8oaHhN/k+VNGVdfstXLgQmzdvVukCkZ/JkycjNTUVW7ZsKfU+v3W5bTh8+HC4urpixowZpd5mYe8rxcnX6B2B5LFt2za4u7sjLi4OVatWxaVLlzBjxgz6ACGEEKIRGzduxI0bN/D06VPs3r0by5cvh4+Pz2fXmzlzJuzs7Eo9mIzkkEqlqFu3LiZMmKDpUFRQn1mSR0pKCrKzs9GxY0fs2rULlStX1nRIhBBCvmGPHj3CL7/8gvfv38PW1hYTJ05UmTO3IMbGxmVyBZHkEIlEmDlz5hd3cYuSWQIgZ+Rt7g0PAgICYGtrix49enxxL1hCCCHfntWrV2P16tWaDoN8oShT+cYxxrBhwwY0atQI6enpAHJGaPbs2ZMSWUIIIYR88ShbURMeeDDRN4eVUIgvZUKu5ORk9OzZE6NHj8bt27dV5tgjhBBCCKkIKJlVE5FQB/P778UZx5oQfwFXPG/cuIGGDRvi8OHDEAqFWL16NcaOHavpsAghhBBCioX6zKrBlzT3GWMMa9aswZQpUyCTyWBvb4+DBw/mue81IYQQQkhFoPlLhF85xgBFtupp1m5QH7x87geuDr/88gsmTJgAmUyGH3/8EVFRUZTIEkIIIaTComS2HDHG8Dy0Mp78YQ6pPBvLjoxCs4zHMNy8XmO3sh02bBhsbW2xfv16/P777zA2NtZIHIQQQgghZYGS2XLEJFmQ/CfK+T9T4sXbOKS/yIQ6b7qmVCpx7tw57rmFhQXi4uLg7++vsYSaEEK+BZcuXQKPx0NycnK+y589ewYej4fo6Gi1xlWR+Pr6wtvbu9A6rVu3xvjx40u9r9DQUNSsWRMKhaLU2yI5N1iwt7fHzZs3y31flMx+xf777z907doV7du3x8GDB7lyTdyKkhBCNOXt27cYOXIkbG1toa2tDQsLC3h6eiI8PJyrw+PxcOzYMbXGZWNjg4SEBNSpU6dc95ObNOf3uHr1arnuuyKZMmUKZs2aBYFAoFIukUhgYmKCypUrIzs7O896Bb128kvEHz9+jMGDB8Pa2hra2tpwcHBA3759yz3h27BhA+zt7aGjo4MmTZrg+vXrhdaXyWSYP38+qlevDh0dHdSvXx+nT58usP6SJUvA4/FUvlSIRCJMmjQJU6dOLavDKBAls1+psLAwuLq64tSpU9DW1kZmZqamQyKEEI3o0aMHoqKisHPnTjx8+BAnTpxA69at8e7dO43GJRAIYGFhwd2wprydP38eCQkJKg83Nze17PtLd/nyZTx58gQ9evTIs+zw4cOoXbs2XFxcSvWF5+bNm3Bzc8PDhw+xZcsWxMTE4OjRo3BxccHEiRNLEX3hDhw4gICAAAQGBuLWrVuoX78+PD098ebNmwLXmTVrFrZs2YJ169YhJiYGI0aMQI8ePXDnzp08dW/cuIEtW7agXr16eZb1798fly9fxv3798v0mD5FyexXRqlUYtGiRWjTpg1evXoFJycnXL9+Hb6+vpoOjRDylcrIyCjwkZWVVeS6EomkSHWLIzk5GWFhYVi6dCnatGkDOzs7uLu7Y/r06ejWrRsAwN7eHgDQvXt38Hg87vmTJ0/g5eUFc3Nz6Ovro3Hjxjh//rzK9rOzszF16lTY2NhAW1sbjo6OBc7ZnZmZiY4dO6JFixZITk7O080gt1tCaGgoGjVqBF1dXTRv3hxxcXEq2/nll19QpUoVGBgYYOjQoZg2bRpcXV0/ey5MTU1hYWGh8hAKhQCAuXPnwtXVFbt374a9vT2MjIzQp08fpKWlcev//vvvqFu3LsRiMUxNTeHh4aHSHtu2bUPNmjWho6MDFxcXbNy4kVv27NkzVKpUCQcPHsT3338PsViMxo0b4+HDh7hx4wYaNWoEfX19dOzYEW/fvs0T+7x582BmZgZDQ0OMGDECUqm0wOPMzs7GpEmTULVqVejp6aFJkya4dOlSoedm//79aNeuXb6/XAYHB2PAgAEYMGBAiedjZ4zB19cXNWrUQFhYGDp37ozq1avD1dUVgYGBOH78eIm2WxSrVq3CsGHDMHjwYNSqVQubN2+Grq4utm/fXuA6u3fvxowZM9CpUydUq1YNI0eORMeOHbF+/XqVeunp6ejfvz+2bt2KSpUq5dlOpUqV0KJFC+zfv7/Mj+tjlMx+Rd68eYMOHTpg5syZUCgUGDBgACIjI/P9tkQIIWVFX1+/wMenV7qqVKlSYN2OHTuq1LW3t+eWGRoawtraGoaGhiWK7dixY/n+RAzkXFkCgJCQECQkJHDP09PT0alTJ4SGhiIqKgodOnRA165d8eLFC27dQYMGYd++fVi7di1iY2OxZcsW6Ovr59lHcnIy2rVrx41jKGzw7cyZM7Fy5UrcvHkTWlpaGDJkCLdsz549WLhwIZYuXYrIyEjY2tpi06ZNxTonBXny5AmOHTuGkydP4uTJk/j777+xZMkSAEBCQgL69u2LIUOGIDY2FpcuXcKPP/7IjQHZs2cP5syZg4ULFyI2NhaLFi3C7NmzsXPnTpV9zJs3D7NmzcKtW7egpaWFfv36YcqUKVizZg3CwsLw+PFjzJkzR2Wd0NBQbp/79u3DkSNHMG/evAKPY/To0YiIiMD+/ftx584d9OzZEx06dMCjR48KXCcsLAyNGjXK95xERESgV69e6NWrF8LCwvD8+fMin9Nc0dHRuH//PiZOnJjv3TULez0sWrSo0L8xfX19ldfkx6RSKSIjI+Hh4cGV8fl8eHh4ICIiosB9Zmdn50nsxWJxnm4p/v7+6Ny5s8r2P+Xu7o6wsLACl5cJ9o1JSUlhAFhKSkq570vx4S2LcXZhd2vWYyuHnGTImXKWvfnwplz298cffzAATCwWs+3btzOlUlku+/nWSKVSduzYMSaVSjUdCikhasPSk0gkLCYmhkkkkjzLct/b8nt06tRJpa6urm6BdVu1aqVSt3LlyvnWK67ff/+dVapUieno6LDmzZuz6dOns9u3b+c5hqNHj352W7Vr12br1q1jjDEWFxfHALBz587lW/fixYsMAIuNjWX16tVjPXr0YNnZ2dzy+Ph4BoBFRUWp1D9//jxX588//2QAuPPepEkT5u/vr7KfFi1asPr16xcYc+5+xGIx09PTU3nkCgwMZLq6uiw1NZUrmzx5MmvSpAljjLHIyEgGgD179izffVSvXp3t3btXpWzBggWsWbNmjDHGnjx5wgCwX3/9lVu+b98+BoCFhoZyZYsXL2bOzs7ccx8fH2ZiYsIyMjK4sk2bNjF9fX2mUCgYY4y1atWKjRs3jjHG2PPnz5lAIGCvXr1SiaVt27Zs+vTpBZ4jIyMjtmvXrjzlM2bMYN7e3txzLy8vFhgYqFKnoNeOj48P8/LyYowxduDAAQaA3bp1q8AYCvLu3Tv26NGjQh8ymSzfdV+9esUAsCtXrqiUT548mbm7uxe4z759+7JatWqxhw8fMoVCwc6ePcvEYjETiUTced+3bx+rU6cO99r8uB0+tmbNGmZvb5/vfgp7XylOvkY3TVAjfR0jSLSK9xNZcXTp0gUrV66Ep6cnateuXW77IYSQj6Wnpxe47NPBNIX10/v0itWzZ8+4/yuVSqSmphb7yiyQ02e2c+fOCAsLw9WrV/HXX39h2bJl2LZtW6FdsNLT0zF37lz8+eefSEhIgFwuh0Qi4a6CRUdHQyAQoFWrVoXuv127dnB3d8eBAwfynI/8fPxrmqWlJYCc82Zra4u4uDiMGjVKpb67uzsuXLjw2e0eOHAANWvWLHC5vb09DAwMVPad217169dH27ZtUbduXXh6eqJ9+/b46aefUKlSJWRkZODJkyfw8/PDsGHDuPXlcjmMjIwKPDZzc3MAQN26dVXKPn2N1K9fH7q6utzzZs2aIT09HS9fvoSdnZ1K3bt370KhUMDJyUmlPDs7G6ampgUeu0QiyXMlUqFQYOfOnVizZg1XNmDAAEyaNAlz5szJ9wprQVgpZjEyMTGBiYlJidcviTVr1mDYsGFwcXEBj8dD9erV4evri5CQEADAy5cvMW7cOJw7d+6zg8rFYnG5j9uhZFZNtIViLPE5gm3uk6Gnp1cm20xISMCYMWOwevVq2NjYAAACAgLKZNuEEFJUxXlPK2ldpVIJhUJR4vdPHR0dtGvXDu3atcPs2bMxdOhQBAYGFprMTpo0CefOncOKFSvg6OgIsViMn376ieuvKS7izW86d+6Mw4cPIyYmRiVxK0huP1YA3BSKSqWySPsqjI2NDRwdHYu039x95+5XIBDg3LlzuHLlCs6ePYt169Zh5syZuHbtGpdobt26FU2aNFHZxqfJe37H9mlZaY41PT0dAoEAkZGRefadX/ePXJUrV8aHDx9Uys6cOYNXr16hd+/eKuUKhQKhoaFo164dAMDAwAApKSl5tpmcnMwl87nJ9YMHD9CgQYNiHdOiRYuwaNGiQuvExMTA1tY2T3nlypUhEAiQlJSkUp6UlAQLC4sCt2dmZoZjx44hKysL7969g5WVFaZOncr1J4+MjMSbN2/QsGFDbh2FQoF//vkH69evR3Z2Nnf+379/DzMzs6IebolQn9kK6ty5c3B1dcXhw4dVvgkTQgj5vFq1aqkMXhIKhXnmFw0PD4evry+6d++OunXrwsLCQuVqcd26daFUKvH3338Xuq8lS5bAx8cHbdu2RUxMTKnidnZ25vr05vr0eXnh8Xho0aIF5s2bh6ioKIhEIhw9ehTm5uawsrLC06dP4ejoqPJwcHAo9X5v376tMjjw6tWr0NfX5y7ifKxBgwZQKBR48+ZNnlgKS94aNGiQp22Cg4PRp08fREdHqzz69OmjMhDM2dkZkZGRKusqFArcvn2bS2JdXV1Rq1YtrFy5Mt9kvaC5iAFgxIgReWL49GFlZZXvuiKRCG5ubggNDeXKlEolQkND0axZswL3mUtHRwdVq1aFXC7HkSNHuH7tbdu2xd27d1ViaNSoEfr378/9YpHr3r17xU7gi4uuzJYzxhiS5XIEnci5YqrrWrobFcjlcsydOxeLFi0CYwx169ZFUFBQGURKCCFfn3fv3qFnz54YMmQI6tWrBwMDA9y8eRPLli2Dl5cXV8/e3h6hoaFo0aIFtLW1UalSJdSoUQNHjhxB165dwePxMHv2bJVExN7eHj4+PhgyZAjWrl2L+vXr4/nz53jz5g169eqlEseKFSugUCjwww8/4NKlS3BxcSnR8YwZMwbDhg1Do0aN0Lx5cxw4cAB37txBtWrVinQuEhMTVcqMjY2LNPf4tWvXEBoaivbt26NKlSq4du0a3r59y3VbmDdvHsaOHQsjIyN06NAB2dnZuHnzJj58+FDqXwylUin8/Pwwa9YsPHv2DIGBgRg9enS+P/M7OTmhf//+GDRoEFauXIkGDRrg7du3CA0NRb169dC5c+d89+Hp6akyWO3t27f4448/cOLEiTzzAA8aNAjdu3fH+/fvYWJigoCAAPj5+cHFxQXt2rVDRkYG1q1bhw8fPmDo0KEAcr4IhISEwMPDA99//z1mzpwJFxcXpKen448//sDZs2cL/FJU2m4GAQEB8PHxQaNGjeDu7o6goCBkZGRg8ODBKsdUtWpVLF68GEBOe7969Qqurq549eoV5s6dC6VSiXHjxgHIuRr96XnR09ODqalpnvKwsDAsWLCgxPEXyWd71X5l1DkATP7+DXPVEasMXKi7sT7LkGZ8fuV8vHz5kn3//ffctoYPH84yMzPLOGryKRo8VPFRG5ZeYQM11EGhULAPHz5wg0+KKisri02bNo01bNiQGRkZMV1dXebs7MxmzZql8v554sQJ5ujoyLS0tJidnR1jLGfgVJs2bZhYLGY2NjZs/fr1eQa5SCQSNmHCBGZpaclEIhFzdHRk27dvZ4z9b0DXhw8fuPpjxoxhlpaWLC4ursABYB/Xj4qKYgBYfHw8VzZ//nxWuXJlpq+vz4YMGcLGjh3LmjZtWuA5yN1Pfo99+/YxxnIGgH06iGz16tXcuYiJiWGenp7MzMyMaWtrMycnJ24gXK49e/YwV1dXJhKJWKVKlVjLli3ZkSNHGGP/GwAWGRnJ1c/veENCQpiRkRH3PHcQ1Zw5c5ipqSnT19dnw4YNY1lZWVydT9tEKpWyOXPmMHt7eyYUCpmlpSXr3r07u3PnToHn6N27d0xHR4c9ePCAMcbYihUrmLGxcb7vGdnZ2czY2JitWbNG5djd3NyYgYEBMzc3Z506dcozyJCxnEGDgwYNYlZWVkwkEjE7OzvWt2/fEg0MK45169YxW1tbJhKJmLu7O7t69arK8latWjEfHx/u+aVLl1jNmjWZtrY2MzU1ZQMHDmQvX74s9G8wvwFgV65cYcbGxgXmKmU1AIzHmBrvrfoFSE1NhZGREVJSUko0kKBY+/r3GYxs/vcTSzWLOjD4RYgrgy5DV6hbyJp5RUdHw8PDA+/evYO+vj62bt2KPn36lHXIJB8ymQynTp1Cp06d8vQpIxUDtWHpZWVlIT4+Hg4ODhq5i+DHA8CKM/DmW9CuXTtYWFhg9+7dmg6lQBWh/SZPnozU1FRs2bJF06F8kUrShr1790b9+vUxY8aMfJcX9r5SnHyNuhmUI7nsf98TFg/6HWlm73FCsLZE23JycoKlpSVsbW1x4MAB1KhRo6zCJIQQUkFkZmZi8+bN8PT0hEAgwL59+3D+/HmcO3dO06FVeDNnzsTGjRuhVCq/2IS7IpFKpahbty4mTJhQ7vuiZFZdWotxgrcWKEaX2YSEBJibm4PP50NXVxenTp2CmZmZRq6KEEII0Twej4dTp05h4cKFyMrKgrOzMw4fPlzopPWkaIyNjQu8gkiKTyQSYdasWWrZFyWz5Uyk9f+JpwA5PZSK6MSJE/D19cXEiRMxc+ZMAMh35CYhhJBvh1gsznNLXUK+dXQdvRzp6elhld+fWOX3J7R1ijYfoVQqRUBAALy8vPDhwwecPHkScrm8nCMlhBBCCKmYKJlVm89flo2Pj8f333+P1atXAwDGjx+Pv//+G1padAGdEEIIISQ/lCWpydnUIKCQQdRHjhzBkCFDkJKSAmNjY+zYsUNlDkRCCCGEEJIXJbPlKCsrC5v+yulMrls7CxACLiYuEGupdjl4/fo1+vXrh+zsbDRt2hT79+/Pc79pQgghhBCSFyWz5UihUOD+i2sAgEbKegCAnR12cvejzmVlZYWgoCA8efIEixYtonkwCSGEEEKKiJJZDTl48CAcHBzQuHFjADn3XiaEEEIIIcVDA8DKUX43V5NIJBgxYgR69+6N3r17IyUlRQOREUIIUQcej4djx45pOgxCvmpfRDK7YcMG2NvbQ0dHB02aNMH169cLrX/o0CG4uLhAR0cHdevWxalTp9QUafFIWLbK82rSavjh+x+wZcsW8Hg89O3bF3p6ehqKjhBCvg2+vr7g8Xjg8XgQCoVwcHDAlClTkJWVpenQCCFlQOPJ7IEDBxAQEIDAwEDcunUL9evXh6enJ968eZNv/StXrqBv377w8/NDVFQUvL294e3tjXv37qk58uKxj/kBoRNCcefOHZiZmeH06dNYuHAhTbtFCCFq0KFDByQkJODp06dYvXo1tmzZgsDAQE2HRQgpAxpPZletWoVhw4Zh8ODBqFWrFjZv3gxdXV1s37493/pr1qxBhw4dMHnyZNSsWRMLFixAw4YNsX79ejVHXjy//xqEjIwMtG7dGrdv30b79u01HRIhhJSJjIyMAh+fXv0srK5EIilS3ZLQ1taGhYUFbGxs4O3tDQ8PD5w7dw4A8O7dO/Tt2xdVq1aFrq4u6tati3379qms37p1a4wdOxZTpkyBiYkJLCwsMHfuXJU6jx49QsuWLaGjo4NatWpx2//Y3bt38cMPP0AsFsPU1BTDhw9Heno6t9zX1xfe3t5YtGgRzM3NYWxsjPnz50Mul2Py5MkwMTGBtbU1QkJCSnQeCPkaafSyoFQqRWRkJKZPn86V8fl8eHh4ICIiIt91IiIiEBAQoFLm6elZYJ+k7OxsZGf/7+f+1NRUAIBMJoNMJivlERRO8dH2eTweZs6ciZkzZ0IgEJT7vknZyW0rarOKi9qw9GQyGRhjUCqVUCqVKsv09fULXK9jx444efIk97xKlSrIzMzMt26rVq1w4cIF7rm9vT3++++/PPUUCkWxYmeMcbEDwL1793DlyhXY2dlBqVQiMzMTDRs2xOTJk2FoaIhTp05h4MCBcHBwgLu7O7ednTt3YsKECYiIiEBERASGDBmCZs2aoV27dlAqlfjxxx9hbm6OiIgIpKSkcJ9VuecsIyMDnp6eaNq0Ka5du4Y3b95g+PDh8Pf355JTxhguXLiAqlWr4tKlSwgPD8ewYcMQHh6Oli1bIiIiAgcPHsTPP/+Mtm3bwtrauljnQlNyx5B83A6kYimPNlQqlWCMQSaTQSAQqCwrzvu1RpPZ//77DwqFAubm5irl5ubmePDgQb7rJCYm5ls/MTEx3/qLFy/GvHnz8pSfPXsWurq6JYy8aORp77H+51CkS1Jw3/AqGjVqhDNnzpTrPkn5ye8qC6lYqA1LTktLCxYWFkhPT4dUKi3yenK5nLuIUNy6+Q2iBVDk7eWSyWT4888/YWhoCLlcjuzsbPD5fCxduhSpqakwMDDAsGHDuPqDBg3Cn3/+iT179sDFxYWLrVatWhg/fjwAwNvbG+vWrcNff/2FJk2a4MKFC3jw4AEOHjwIS0tLAMCMGTPQs2dPSCQSpKamYufOnZBIJFi3bh309PRga2uLuKPHMwAAF4tJREFUJUuWoG/fvpg5cyaqVKkCmUwGY2NjLFiwAHw+Hz/99BOWLVuGtLQ0+Pv7AwBGjRqFpUuX4ty5c+jRo0exzoWmpaWlaToEUkpl2YZSqRQSiQT//PMP5HK5yrKCvvTm56vvsDl9+nSVK7mpqamwsbFB+/btYWhoWK77VsjlSG72HOERzzGq20zoiMWfX4l8cWQyGc6dO4d27drRHMAVFLVh6WVlZeHly5fQ19eHjo6OyrLCkkuBQKBSv6ALD0DOL3Pij94n4+Pjuf8zxpCWlgYDA4NCrwTnRygUonXr1ti4cSMyMjIQFBQELS0tDBgwAEDOld7Fixfj0KFDePXqFaRSKbKzs2FoaMh9TmhpaaFevXoqnxtVq1ZFSkoKDA0N8eLFC9jY2MDZ2Zlb3rZtWwCAWCyGoaEhnj17BldXVy7ZBcBd1X39+jUcHR0hFApRp04dGBsbc3UsLS1Ru3ZtlX2bmpoiPT293D/HysrH7ffpXOukYiiPNszKyoJYLOa653ysOF9aNZrMVq5cGQKBAElJSSrlSUlJsLCwyHcdCwuLYtXX1taGtrZ2nnKhUFjuH2pCoRCmttWhdS8OOmIxfYhWcOp4zZDyRW1YcgqFAjweD3w+H3y+6nALAwODIm+npHVzf6rX19fPs//P4fF40NfXh5OTEwAgJCQE9evXR0hICPz8/LBs2TKsXbsWQUFBqFu3LvT09DB+/HjIZDKVfYlEIpXnfD4fjDHw+Xzuw/3T5bn/FqfOp/spqCx33xVB7s/Sua8hUvGURxvmvubze28uznu1Rl9RIpEIbm5uCA0N5cqUSiVCQ0PRrFmzfNdp1qyZSn0g56fDguoTQgghH+Pz+ZgxYwZmzZoFiUSC8PBweHl5YcCAAahfvz6qVauGhw8fFmubNWvWxMuXL5GQkMCVXb16NU+d27dvqwxiCw8PB5/PV7miSwgpHo1/PQoICMDWrVuxc+dOxMbGYuTIkcjIyMDgwYMB5PRd+niA2Lhx43D69GmsXLkSDx48wNy5c3Hz5k2MHj1aU4dACCGkgunZsycEAgE2bNiAGjVq4Ny5c7hy5QpiY2Px888/5/kF8HM8PDzg5OQEHx8f3L59G2FhYZg5c6ZKnf79+0NHRwc+Pj64d+8eLl68iDFjxmDgwIF5xoIQQopO431me/fujbdv32LOnDlITEyEq6srTp8+zf1hv3jxQuVydvPmzbF3717MmjULM2bMQI0aNXDs2DHUqVNHU4dACCGkgtHS0sLo0aOxbNkyREVF4enTp/D09ISuri6GDx8Ob2/vYt2hkc/n4+jRo/Dz84O7uzvs7e2xdu1adOjQgaujq6uLM2fOYNy4cWjcuDF0dXXRo0cPrFq1qjwOkZBvBo8VNFz0K5WamgojIyOu0355k8lkOHXqFDp16kR99SooasOKj9qw9LKyshAfHw8HB4c8AzXUQalUIjU1FYaGhtTnsgKi9qv4yqMNC3tfKU6+Rq8oQgghhBBSYVEySwghhBBCKixKZgkhhBBCSIVFySwhhBBCCKmwKJklhBBSZN/YmGFCSDkqq/cTSmYJIYR8Vu4sEMW5XzohhBRGKpUCyLntdWlofJ5ZQgghXz6BQABjY2O8efMGQM6cqWV1f/aiUCqVkEqlyMrKoqmdKiBqv4qvrNtQqVTi7du30NXVhZZW6dJRSmYJIYQUiYWFBQBwCa06McYgkUggFovVmkSTskHtV/GVRxvy+XzY2tqWenuUzBJCCCkSHo8HS0tLVKlSBTKZTK37lslk+Oeff9CyZUu68UUFRO1X8ZVHG4pEojK5ykvJLCGEkGIRCASl7uNWkn3K5XLo6OhQMlQBUftVfF9yG1LHFUIIIYQQUmFRMksIIYQQQiosSmYJIYQQQkiF9c31mc2doDc1NVUt+5PJZMjMzERqauoX18eEFA21YcVHbVjxURtWbNR+FZ+62zA3TyvKjRW+uWQ2LS0NAGBjY6PhSAghhBBCSGHS0tJgZGRUaB0e+8buTahUKvH69WsYGBioZa671NRU2NjY4OXLlzA0NCz3/ZGyR21Y8VEbVnzUhhUbtV/Fp+42ZIwhLS0NVlZWn52+65u7Msvn82Ftba32/RoaGtIfcAVHbVjxURtWfNSGFRu1X8Wnzjb83BXZXDQAjBBCCCGEVFiUzBJCCCGEkAqLktlypq2tjcDAQGhra2s6FFJC1IYVH7VhxUdtWLFR+1V8X3IbfnMDwAghhBBCyNeDrswSQgghhJAKi5JZQgghhBBSYVEySwghhBBCKixKZgkhhBBCSIVFyWwZ2LBhA+zt7aGjo4MmTZrg+vXrhdY/dOgQXFxcoKOjg7p16+LUqVNqipQUpDhtuHXrVnz//feoVKkSKlWqBA8Pj8+2OSl/xf07zLV//37weDx4e3uXb4Dks4rbhsnJyfD394elpSW0tbXh5ORE76caVNz2CwoKgrOzM8RiMWxsbDBhwgRkZWWpKVryqX/++Qddu3aFlZUVeDwejh079tl1Ll26hIYNG0JbWxuOjo7YsWNHuceZL0ZKZf/+/UwkErHt27ez+/fvs2HDhjFjY2OWlJSUb/3w8HAmEAjYsmXLWExMDJs1axYTCoXs7t27ao6c5CpuG/br149t2LCBRUVFsdjYWObr68uMjIzYv//+q+bISa7itmGu+Ph4VrVqVfb9998zLy8v9QRL8lXcNszOzmaNGjVinTp1YpcvX2bx8fHs0qVLLDo6Ws2RE8aK33579uxh2trabM+ePSw+Pp6dOXOGWVpasgkTJqg5cpLr1KlTbObMmezIkSMMADt69Gih9Z8+fcp0dXVZQEAAi4mJYevWrWMCgYCdPn1aPQF/hJLZUnJ3d2f+/v7cc4VCwaysrNjixYvzrd+rVy/WuXNnlbImTZqwn3/+uVzjJAUrbht+Si6XMwMDA7Zz587yCpF8RknaUC6Xs+bNm7Nt27YxHx8fSmY1rLhtuGnTJlatWjUmlUrVFSIpRHHbz9/fn/3www8qZQEBAaxFixblGicpmqIks1OmTGG1a9dWKevduzfz9PQsx8jyR90MSkEqlSIyMhIeHh5cGZ/Ph4eHByIiIvJdJyIiQqU+AHh6ehZYn5SvkrThpzIzMyGTyWBiYlJeYZJClLQN58+fjypVqsDPz08dYZJClKQNT5w4gWbNmsHf3x/m5uaoU6cOFi1aBIVCoa6wyf8rSfs1b94ckZGRXFeEp0+f4tSpU+jUqZNaYial9yXlM1pq3+NX5L///oNCoYC5ublKubm5OR48eJDvOomJifnWT0xMLLc4ScFK0oafmjp1KqysrPL8URP1KEkbXr58GcHBwYiOjlZDhORzStKGT58+xYULF9C/f3+cOnUKjx8/xqhRoyCTyRAYGKiOsMn/K0n79evXD//99x++++47MMYgl8sxYsQIzJgxQx0hkzJQUD6TmpoKiUQCsVistljoyiwhpbBkyRLs378fR48ehY6OjqbDIUWQlpaGgQMHYuvWrahcubKmwyElpFQqUaVKFfz6669wc3ND7969MXPmTGzevFnToZEiuHTpEhYtWoSNGzfi1q1bOHLkCP78808sWLBA06GRCoiuzJZC5cqVIRAIkJSUpFKelJQECwuLfNexsLAoVn1SvkrShrlWrFiBJUuW4Pz586hXr155hkkKUdw2fPLkCZ49e4auXbtyZUqlEgCgpaWFuLg4VK9evXyDJipK8ndoaWkJoVAIgUDAldWsWROJiYmQSqUQiUTlGjP5n5K03+zZszFw4EAMHToUAFC3bl1kZGRg+PDhmDlzJvh8utb2pSsonzE0NFTrVVmArsyWikgkgpubG0JDQ7kypVKJ0NBQNGvWLN91mjVrplIfAM6dO1dgfVK+StKGALBs2TIsWLAAp0+fRqNGjdQRKilAcdvQxcUFd+/eRXR0NPfo1q0b2rRpg+joaNjY2KgzfIKS/R22aNECjx8/5r6IAMDDhw9haWlJiayalaT9MjMz8ySsuV9MGGPlFywpM19UPqP2IWdfmf379zNtbW22Y8cOFhMTw4YPH86MjY1ZYmIiY4yxgQMHsmnTpnH1w8PDmZaWFluxYgWLjY1lgYGBNDWXhhW3DZcsWcJEIhH7/fffWUJCAvdIS0vT1CF884rbhp+i2Qw0r7ht+OLFC2ZgYMBGjx7N4uLi2MmTJ1mVKlXYL7/8oqlD+KYVt/0CAwOZgYEB27dvH3v69Ck7e/Ysq169OuvVq5emDuGbl5aWxqKiolhUVBQDwFatWsWioqLY8+fPGWOMTZs2jQ0cOJCrnzs11+TJk1lsbCzbsGEDTc1Vka1bt47Z2toykUjE3N3d2dWrV7llrVq1Yj4+Pir1Dx48yJycnJhIJGK1a9dmf/75p5ojJp8qThva2dkxAHkegYGB6g+ccIr7d/gxSma/DMVtwytXrrAmTZowbW1tVq1aNbZw4UIml8vVHDXJVZz2k8lkbO7cuax69epMR0eH2djYsFGjRrEPHz6oP3DCGGPs4sWL+X625babj48Pa9WqVZ51XF1dmUgkYtWqVWMhISFqj5sxxniM0fV8QgghhBBSMVGfWUIIIYQQUmFRMksIIYQQQiosSmYJIYQQQkiFRcksIYQQQgipsCiZJYQQQgghFRYls4QQQgghpMKiZJYQQgghhFRYlMwSQgghhJAKi5JZQggBsGPHDhgbG2s6jBLj8Xg4duxYoXV8fX3h7e2tlngIIURdKJklhHw1fH19wePx8jweP36s6dCwY8cOLh4+nw9ra2sMHjwYb968KZPtJyQkoGPHjgCAZ8+egcfjITo6WqXOmjVrsGPHjjLZX0Hmzp3LHadAIICNjQ2GDx+O9+/fF2s7lHgTQopKS9MBEEJIWerQoQNCQkJUyszMzDQUjSpDQ0PExcVBqVTi9u3bGDx4MF6/fo0zZ86UetsWFhafrWNkZFTq/RRF7dq1cf78eSgUCsTGxmLIkCFISUnBgQMH1LJ/Qsi3ha7MEkK+Ktra2rCwsFB5CAQCrFq1CnXr1oWenh5sbGwwatQopKenF7id27dvo02bNjAwMIChoSHc3Nxw8+ZNbvnly5fx/fffQywWw8bGBmPHjkVGRkahsfF4PFhYWMDKygodO3bE2LFjcf78eUgkEiiVSsyfPx/W1tbQ1taGq6srTp8+za0rlUoxevRoWFpaQkdHB3Z2dli8eLHKtnO7GTg4OAAAGjRoAB6Ph9atWwNQvdr566+/wsrKCkqlUiVGLy8vDBkyhHt+/PhxNGzYEDo6OqhWrRrmzZsHuVxe6HFqaWnBwsICVatWhYeHB3r27Ilz585xyxUKBfz8/ODg4ACxWAxnZ2esWbOGWz537lzs3LkTx48f567yXrp0CQDw8uVL9OrVC8bGxjAxMYGXlxeePXtWaDyEkK8bJbOEkG8Cn8/H2rVrcf/+fezcuRMXLlzAlClTCqzfv39/WFtb48aNG4iMjMS0adMgFAoBAE+ePEGHDh3Qo0cP3LlzBwcOHMDly5cxevToYsUkFouhVCohl8uxZs0arFy5EitWrMCdO3fg6emJbt264dGjRwCAtWvX4sSJEzh48CDi4uKwZ88e2Nvb57vd69evAwDOnz+PhIQEHDlyJE+dnj174t27d7h48SJX9v79e5w+fRr9+/cHAISFhWHQoEEYN24cYmJisGXLFuzYsQMLFy4s8jE+e/YMZ86cgUgk4sqUSiWsra1x6NAhxMTEYM6cOZgxYwYOHjwIAJg0aRJ69eqFDh06ICEhAQkJCWjevDlkMhk8PT1hYGCAsLAwhIeHQ19fHx06dIBUKi1yTISQrwwjhJCvhI+PDxMIBExPT497/PTTT/nWPXToEDM1NeWeh4SEMCMjI+65gYEB27FjR77r+vn5seHDh6uUhYWFMT6fzyQSSb7rfLr9hw8fMicnJ9aoUSPGGGNWVlZs4cKFKus0btyYjRo1ijHG2JgxY9gPP/zAlEplvtsHwI4ePcoYYyw+Pp4BYFFRUSp1fHx8mJeXF/fcy8uLDRkyhHu+ZcsWZmVlxRQKBWOMsbZt27JFixapbGP37t3M0tIy3xgYYywwMJDx+Xymp6fHdHR0GAAGgK1atarAdRhjzN/fn/Xo0aPAWHP37ezsrHIOsrOzmVgsZmfOnCl0+4SQrxf1mSWEfFXatGmDTZs2cc/19PQA5FylXLx4MR48eIDU1FTI5XJkZWUhMzMTurq6ebYTEBCAoUOHYvfu3dxP5dWrVweQ0wXhzp072LNnD1efMQalUon4+HjUrFkz39hSUlKgr68PpVKJrKwsfPfdd9i2bRtSU1Px+vVrtGjRQqV+ixYtcPv2bQA5XQTatWsHZ2dndOjQAV26dEH79u1Lda769++PYcOGYePGjdDW1saePXvQp08f8Pl87jjDw8NVrsQqFIpCzxsAODs748SJE8jKysJv/9fe/YU0vcZxHH8fC9FiXoyS2oV1oROhrH45yyACCSoqxCGOFLqREMMWZqIXZg0pslChCAzCoJImdaO0tOjC0glhxQr6s2Vp2U2QQTFQFNu5ODiapqEHzjnb+bwun9/z/H7fZ7v57OF5frtxA5/Px5EjRyL6XLp0idbWVj5+/MjY2BgTExNs3Lhx3nqfP3/O4OAgJpMpon18fJx3794t4hMQkVigMCsiMWX58uWkpqZGtA0PD7Nv3z7Kyso4ffo0ZrOZvr4+SkpKmJiY+GUoO3XqFEVFRXg8Hrq6ujh58iRut5v8/HyCwSClpaU4nc5Z41JSUuaszWQy8ezZM+Li4li9ejWJiYkAfP/+/bfzMgyDoaEhurq6ePDgAYWFhezcuZPbt2//duxc9u/fTygUwuPxYLPZ6O3tpbm5OXw9GAzicrmw2+2zxiYkJMx53/j4+PB3cPbsWfbu3YvL5aK+vh4At9vN8ePHaWxsJCcnB5PJxPnz53n8+PG89QaDQTZv3hzxI2Laf+WQn4j88xRmRSTmPX36lB8/ftDY2BhedZzenzkfq9WK1WqloqKCAwcOcPXqVfLz8zEMg1evXs0Kzb8TFxf3yzFJSUlYLBa8Xi87duwIt3u9XrKzsyP6ORwOHA4HBQUF7N69m69fv2I2myPuN70/dWpqat56EhISsNvttLW1MTg4SHp6OoZhhK8bhoHf71/wPGeqra0lNzeXsrKy8Dy3bdvG4cOHw31mrqzGx8fPqt8wDNrb20lOTiYpKelv1SQisUMHwEQk5qWmpjI5OcnFixd5//49169fp6WlZc7+Y2NjlJeX09PTw4cPH/B6vQwMDIS3D1RXV9Pf3095eTk+n4+3b9/S0dGx4ANgP6uqqqKhoYH29nb8fj81NTX4fD6OHj0KQFNTEzdv3uTNmzcEAgFu3brFqlWrfvlHD8nJySQmJtLd3c3nz5/59u3bnM8tLi7G4/HQ2toaPvg1ra6ujmvXruFyuXj58iWvX7/G7XZTW1u7oLnl5OSQmZnJmTNnAEhLS+PJkyfcu3ePQCDAiRMnGBgYiBizdu1aXrx4gd/v58uXL0xOTlJcXMyKFSvIy8ujt7eXoaEhenp6cDqdfPr0aUE1iUjsUJgVkZi3YcMGmpqaaGhoYN26dbS1tUW81mqmJUuWMDo6ysGDB7FarRQWFrJnzx5cLhcAmZmZPHz4kEAgwPbt29m0aRN1dXVYLJZF1+h0Ojl27BiVlZWsX7+e7u5uOjs7SUtLA/7aonDu3DmysrKw2WwMDw9z9+7d8Erzz5YuXcqFCxe4fPkyFouFvLy8OZ+bm5uL2WzG7/dTVFQUcW3Xrl3cuXOH+/fvY7PZ2Lp1K83NzaxZs2bB86uoqODKlSuMjIxQWlqK3W7H4XCwZcsWRkdHI1ZpAQ4dOkR6ejpZWVmsXLkSr9fLsmXLePToESkpKdjtdjIyMigpKWF8fFwrtSL/Y3+EQqHQv12EiIiIiMhiaGVWRERERKKWwqyIiIiIRC2FWRERERGJWgqzIiIiIhK1FGZFREREJGopzIqIiIhI1FKYFREREZGopTArIiIiIlFLYVZEREREopbCrIiIiIhELYVZEREREYlafwIoFd9jFe2zrAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves for all models and the stacking ensemble on the test dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot ROC curves for individual models using the test dataset\n",
    "for name, model in best_models.items():\n",
    "    y_pred_proba = model.predict_proba(X_test_external)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test_external, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc_score(y_test_external, y_pred_proba):.2f})')\n",
    "\n",
    "# Plot ROC curve for the stacking ensemble on the test dataset\n",
    "fpr_stacking, tpr_stacking, _ = roc_curve(y_test_external, y_pred_stacking)\n",
    "plt.plot(fpr_stacking, tpr_stacking, linestyle='--', color='black', label=f'Stacking Ensemble (AUC = {auc_stacking:.2f})')\n",
    "\n",
    "# Plot diagonal line (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "\n",
    "# Set plot properties\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Logistic Regression - Test Data')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
